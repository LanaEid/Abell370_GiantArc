{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "IMPORTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np \n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "import numpy\n",
    "from matplotlib.pyplot import *\n",
    "#import numpy as np\n",
    "#import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as colors\n",
    "from astropy.visualization import astropy_mpl_style\n",
    "from astropy.visualization import make_lupton_rgb\n",
    "from astropy.utils.data import get_pkg_data_filename\n",
    "from astropy.io import fits\n",
    "from astropy.modeling.models import Sersic2D\n",
    "from astropy.cosmology import FlatLambdaCDM\n",
    "from skimage import img_as_float\n",
    "import imageio\n",
    "from pathlib import Path\n",
    "from PIL import Image\n",
    "from astropy import wcs\n",
    "from astropy.wcs import WCS\n",
    "import matplotlib.gridspec as gridspec\n",
    "from astropy.coordinates import Angle,SkyCoord\n",
    "import astropy.coordinates as coord\n",
    "import math\n",
    "from scipy import ndimage\n",
    "from astropy.convolution import discretize_model\n",
    "import astropy.units as u\n",
    "from scipy.stats import norm\n",
    "from scipy.interpolate import RectBivariateSpline #bivariate spline approximation interpolation over a rectangular mesh grid\n",
    "#import photutils\n",
    "from photutils.detection import find_peaks\n",
    "from astropy.table import Table\n",
    "from astropy.stats import sigma_clipped_stats\n",
    "from astropy.nddata import NDData\n",
    "from photutils.psf import extract_stars\n",
    "from astropy.visualization import simple_norm\n",
    "from photutils.psf import EPSFBuilder\n",
    "from astropy.visualization import simple_norm\n",
    "from photutils.psf import epsf_stars\n",
    "import photutils.psf.epsf_stars\n",
    "from photutils.psf import EPSFStar\n",
    "import photutils\n",
    "from astropy import convolution\n",
    "from astropy.convolution import convolve\n",
    "from astropy.nddata import Cutout2D\n",
    "from astropy.utils.data import download_file\n",
    "from astropy.wcs import WCS\n",
    "from photutils.isophote import EllipseGeometry, Ellipse, build_ellipse_model\n",
    "from photutils.aperture import EllipticalAperture\n",
    "import aplpy\n",
    "from photutils.datasets import make_noise_image\n",
    "import astropy.table\n",
    "from astropy.io import ascii\n",
    "import pandas\n",
    "\n",
    "matplotlib.style.use(astropy_mpl_style)\n",
    "cosmo = FlatLambdaCDM(H0=70, Om0=0.3)#would need Ode0=0.7 if using LambdaCDM instead\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#chi_squared for each\n",
    "chi2_0 = 9.849849e+10\n",
    "chi2_1 = 1.067151e+11\n",
    "chi2_2 = 1.128767e+11\n",
    "chi2_3 = 1.091188e+11\n",
    "chi2_4 = 9.951028e+10\n",
    "chi2_5 = 9.232762e+10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #saving gif to \n",
    "\n",
    "# #need to output source reconstructions as png images, with labels, in order\n",
    "\n",
    "# #slide 36\n",
    "# reg_0 = fits.open('/mnt/c/Users/lana-/Desktop/PixSrcTests/redo_arc/pixsrc_out/redo_arc_redo_arc_0_mps.fits')[0]\n",
    "# figure(figsize=(25,25))\n",
    "# imshow(reg_0.data,origin='lower',cmap='gray')\n",
    "# xlim(0,325)\n",
    "# ylim(0,300)\n",
    "# title('non-PSF',fontsize=40,color='orange')\n",
    "# savefig('/mnt/c/Users/lana-/Desktop/source_reg/reg_0.png',bbox_inches='tight')\n",
    "\n",
    "# #slide 62\n",
    "# reg_0 = fits.open('/mnt/c/Users/lana-/Desktop/PixSrcTests/reg_tests/reg_test_1/pixsrc_out/arc0_814_arc_source_814_0_mps.fits')[0]\n",
    "# figure(figsize=(25,25))\n",
    "# imshow(reg_0.data,origin='lower',cmap='gray')\n",
    "# xlim(0,325)\n",
    "# ylim(0,300)\n",
    "# title('grid: 1 5 & noise: 100 & regstrength: 2 & regorder: 2',fontsize=40,color='orange')\n",
    "# savefig('/mnt/c/Users/lana-/Desktop/source_reg/reg_1.png',bbox_inches='tight')\n",
    "\n",
    "# #slide 63\n",
    "# reg_0 = fits.open('/mnt/c/Users/lana-/Desktop/PixSrcTests/reg_tests/reg_test_2/pixsrc_out/arc0_814_arc_source_814_0_mps.fits')[0]\n",
    "# figure(figsize=(25,25))\n",
    "# imshow(reg_0.data,origin='lower',cmap='gray')\n",
    "# xlim(0,325)\n",
    "# ylim(0,300)\n",
    "# title('grid: 1 5 & noise: 100 & regstrength: 2 & regorder: 1',fontsize=40,color='orange')\n",
    "# savefig('/mnt/c/Users/lana-/Desktop/source_reg/reg_2.png',bbox_inches='tight')\n",
    "\n",
    "# #slide 64\n",
    "# reg_0 = fits.open('/mnt/c/Users/lana-/Desktop/PixSrcTests/reg_tests/reg_test_3/pixsrc_out/arc0_814_arc_source_814_0_mps.fits')[0]\n",
    "# figure(figsize=(25,25))\n",
    "# imshow(reg_0.data,origin='lower',cmap='gray')\n",
    "# xlim(0,325)\n",
    "# ylim(0,300)\n",
    "# title('grid: 1 5 & noise: 100 & regstrength: 2 & regorder: 0',fontsize=40,color='orange')\n",
    "# savefig('/mnt/c/Users/lana-/Desktop/source_reg/reg_3.png',bbox_inches='tight')\n",
    "\n",
    "# #slide 68\n",
    "# reg_0 = fits.open('/mnt/c/Users/lana-/Desktop/PixSrcTests/reg_tests/reg_test_7/pixsrc_out/arc0_814_arc_source_814_0_mps.fits')[0]\n",
    "# figure(figsize=(25,25))\n",
    "# imshow(reg_0.data,origin='lower',cmap='gray')\n",
    "# xlim(0,325)\n",
    "# ylim(0,300)\n",
    "# title('grid: 1 5 & noise: 1 & regstrength: 10 & regorder: 2',fontsize=40,color='orange')\n",
    "# savefig('/mnt/c/Users/lana-/Desktop/source_reg/reg_4.png',bbox_inches='tight')\n",
    "\n",
    "# #slide 74\n",
    "# reg_0 = fits.open('/mnt/c/Users/lana-/Desktop/PixSrcTests/Tests/test4/pixsrc_out/arc0_814_arc_source_814_0_mps.fits')[0]\n",
    "# figure(figsize=(25,25))\n",
    "# imshow(reg_0.data,origin='lower',cmap='gray')\n",
    "# xlim(0,325)\n",
    "# ylim(0,300)\n",
    "# title('grid: 1 5 & noise: 0.1 & regstrength: -25 & regorder: 2',fontsize=40,color='orange')\n",
    "# savefig('/mnt/c/Users/lana-/Desktop/source_reg/reg_5.png',bbox_inches='tight')\n",
    "\n",
    "# #slide 75\n",
    "# reg_0 = fits.open('/mnt/c/Users/lana-/Desktop/PixSrcTests/reg_tests/reg_test_1/pixsrc_out/arc0_814_arc_source_814_0_mps.fits')[0]\n",
    "# figure(figsize=(25,25))\n",
    "# imshow(reg_0.data,origin='lower',cmap='gray')\n",
    "# xlim(0,325)\n",
    "# ylim(0,300)\n",
    "# title('grid: 1 5 & noise: 50 & regstrength: -5 & regorder: 2',fontsize=40,color='orange')\n",
    "# savefig('/mnt/c/Users/lana-/Desktop/source_reg/reg_6.png',bbox_inches='tight')\n",
    "\n",
    "\n",
    "# #data\n",
    "# #takes all images and stores them as image_list\n",
    "# image_path = Path('/mnt/c/Users/lana-/Desktop/source_reg')\n",
    "# images = list(image_path.glob('*.png'))\n",
    "# image_list = []\n",
    "# for file_name in images:\n",
    "#     image_list.append(imageio.imread(file_name))\n",
    "# # print(len(image_list))\n",
    "# imageio.mimwrite('/mnt/c/Users/lana-/Desktop/source_reg/sources_reg.gif', image_list, fps=0.5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#now make four RGBs to flip through in gif form for AAS\n",
    "\n",
    "#data\n",
    "#takes all images and stores them as image_list\n",
    "image_path = Path('/mnt/c/Users/lana-/Desktop/ARC_RESULTS/rgb/data')\n",
    "images = list(image_path.glob('*.png'))\n",
    "image_list = []\n",
    "for file_name in images:\n",
    "    image_list.append(imageio.imread(file_name))\n",
    "print(len(image_list))\n",
    "imageio.mimwrite('/mnt/c/Users/lana-/Desktop/ARC_RESULTS/data.gif', image_list, fps=0.5)\n",
    "\n",
    "#model arc no PSF\n",
    "#takes all images and stores them as image_list\n",
    "image_path = Path('/mnt/c/Users/lana-/Desktop/ARC_RESULTS/rgb/model')\n",
    "images = list(image_path.glob('*.png'))\n",
    "image_list = []\n",
    "for file_name in images:\n",
    "    image_list.append(imageio.imread(file_name))\n",
    "print(len(image_list))\n",
    "imageio.mimwrite('/mnt/c/Users/lana-/Desktop/ARC_RESULTS/model.gif', image_list, fps=0.5)\n",
    "\n",
    "#source reconstruction\n",
    "#takes all images and stores them as image_list\n",
    "image_path = Path('/mnt/c/Users/lana-/Desktop/ARC_RESULTS/rgb/mps')\n",
    "images = list(image_path.glob('*.png'))\n",
    "image_list = []\n",
    "for file_name in images:\n",
    "    image_list.append(imageio.imread(file_name))\n",
    "print(len(image_list))\n",
    "imageio.mimwrite('/mnt/c/Users/lana-/Desktop/ARC_RESULTS/mps.gif', image_list, fps=0.5)\n",
    "\n",
    "#residuals\n",
    "#takes all images and stores them as image_list\n",
    "image_path = Path('/mnt/c/Users/lana-/Desktop/ARC_RESULTS/rgb/residuals')\n",
    "images = list(image_path.glob('*.png'))\n",
    "image_list = []\n",
    "for file_name in images:\n",
    "    image_list.append(imageio.imread(file_name))\n",
    "print(len(image_list))\n",
    "imageio.mimwrite('/mnt/c/Users/lana-/Desktop/ARC_RESULTS/residuals.gif', image_list, fps=0.5)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#now make four RGBs to flip through in gif form for AAS\n",
    "\n",
    "#data\n",
    "aplpy.make_rgb_cube(['/mnt/c/Users/lana-/Desktop/ARC_RESULTS/red/arc_source_814_arc_source_814_0_data.fits','/mnt/c/Users/lana-/Desktop/ARC_RESULTS/green/arc_source_606_arc_source_606_0_data.fits','/mnt/c/Users/lana-/Desktop/ARC_RESULTS/blue/arc_source_435_arc_source_435_0_data.fits'],'/mnt/c/Users/lana-/Desktop/ARC_RESULTS/data_rgb_cube.fits')\n",
    "aplpy.make_rgb_image('/mnt/c/Users/lana-/Desktop/ARC_RESULTS/data_rgb_cube.fits','/mnt/c/Users/lana-/Desktop/ARC_RESULTS/data_arc_rgb_cube.png', vmin_r=0.,vmin_g=0.,vmin_b=0.,vmax_r=125.,vmax_g=125.,vmax_b=125.)\n",
    "#model arc no PSF\n",
    "aplpy.make_rgb_cube(['/mnt/c/Users/lana-/Desktop/ARC_RESULTS/red/arc_source_814_arc_source_814_0_lensedmpsnobo.fits','/mnt/c/Users/lana-/Desktop/ARC_RESULTS/green/arc_source_606_arc_source_606_0_lensedmpsnobo.fits','/mnt/c/Users/lana-/Desktop/ARC_RESULTS/blue/arc_source_435_arc_source_435_0_lensedmpsnobo.fits'],'/mnt/c/Users/lana-/Desktop/ARC_RESULTS/lensedmpsnobo_rgb_cube.fits')\n",
    "aplpy.make_rgb_image('/mnt/c/Users/lana-/Desktop/ARC_RESULTS/lensedmpsnobo_rgb_cube.fits','/mnt/c/Users/lana-/Desktop/ARC_RESULTS/lensedmpsnobo_arc_rgb_cube.png', vmin_r=0.,vmin_g=0.,vmin_b=0.,vmax_r=125.,vmax_g=125.,vmax_b=125.)\n",
    "#source reconstruction\n",
    "aplpy.make_rgb_cube(['/mnt/c/Users/lana-/Desktop/ARC_RESULTS/red/arc_source_814_arc_source_814_0_mps.fits','/mnt/c/Users/lana-/Desktop/ARC_RESULTS/green/arc_source_606_arc_source_606_0_mps.fits','/mnt/c/Users/lana-/Desktop/ARC_RESULTS/blue/arc_source_435_arc_source_435_0_mps.fits'],'/mnt/c/Users/lana-/Desktop/ARC_RESULTS/mps_rgb_cube.fits')\n",
    "aplpy.make_rgb_image('/mnt/c/Users/lana-/Desktop/ARC_RESULTS/mps_rgb_cube.fits','/mnt/c/Users/lana-/Desktop/ARC_RESULTS/mps_arc_rgb_cube.png', vmin_r=0.,vmin_g=0.,vmin_b=0.,vmax_r=125.,vmax_g=125.,vmax_b=125.)\n",
    "#residuals\n",
    "aplpy.make_rgb_cube(['/mnt/c/Users/lana-/Desktop/ARC_RESULTS/red/arc_source_814_arc_source_814_0_residuals.fits','/mnt/c/Users/lana-/Desktop/ARC_RESULTS/green/arc_source_606_arc_source_606_0_residuals.fits','/mnt/c/Users/lana-/Desktop/ARC_RESULTS/blue/arc_source_435_arc_source_435_0_residuals.fits'],'/mnt/c/Users/lana-/Desktop/ARC_RESULTS/residuals_rgb_cube.fits')\n",
    "aplpy.make_rgb_image('/mnt/c/Users/lana-/Desktop/ARC_RESULTS/residuals_rgb_cube.fits','/mnt/c/Users/lana-/Desktop/ARC_RESULTS/residuals_arc_rgb_cube.png', vmin_r=0.,vmin_g=0.,vmin_b=0.,vmax_r=125.,vmax_g=125.,vmax_b=125.)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make four gifs\n",
    "\n",
    "#takes all images and stores them as image_list\n",
    "image_path = Path('/mnt/c/Users/lana-/Desktop/ARC_RESULTS/data')\n",
    "images = list(image_path.glob('*.png'))\n",
    "image_list = []\n",
    "for file_name in images:\n",
    "    image_list.append(imageio.imread(file_name))\n",
    "print(len(image_list))\n",
    "imageio.mimwrite('/mnt/c/Users/lana-/Desktop/ARC_RESULTS/data.gif', image_list, fps=0.5)\n",
    "\n",
    "#takes all images and stores them as image_list\n",
    "image_path = Path('/mnt/c/Users/lana-/Desktop/ARC_RESULTS/modelarc')\n",
    "images = list(image_path.glob('*.png'))\n",
    "image_list = []\n",
    "for file_name in images:\n",
    "    image_list.append(imageio.imread(file_name))\n",
    "print(len(image_list))\n",
    "imageio.mimwrite('/mnt/c/Users/lana-/Desktop/ARC_RESULTS/modelarc.gif', image_list, fps=0.5)\n",
    "\n",
    "#takes all images and stores them as image_list\n",
    "image_path = Path('/mnt/c/Users/lana-/Desktop/ARC_RESULTS/source')\n",
    "images = list(image_path.glob('*.png'))\n",
    "image_list = []\n",
    "for file_name in images:\n",
    "    image_list.append(imageio.imread(file_name))\n",
    "print(len(image_list))\n",
    "imageio.mimwrite('/mnt/c/Users/lana-/Desktop/ARC_RESULTS/source.gif', image_list, fps=0.5)\n",
    "\n",
    "#takes all images and stores them as image_list\n",
    "image_path = Path('/mnt/c/Users/lana-/Desktop/ARC_RESULTS/residuals')\n",
    "images = list(image_path.glob('*.png'))\n",
    "image_list = []\n",
    "for file_name in images:\n",
    "    image_list.append(imageio.imread(file_name))\n",
    "print(len(image_list))\n",
    "imageio.mimwrite('/mnt/c/Users/lana-/Desktop/ARC_RESULTS/residuals.gif', image_list, fps=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#step 1: include distance ratio D_ls/D_os to the deflections alphax and alphay\n",
    "#the distances here are ANGULAR DIAMETER DISTANCES - will find using astropy.cosmology\n",
    "#because using ratios, will leave them in Mpc\n",
    "\n",
    "#observer\n",
    "z_obs = 0\n",
    "#lens, which here is Abell 370\n",
    "z_lens = 0.375\n",
    "#source galaxy in the arc\n",
    "z_source = 0.7251\n",
    "\n",
    "#distance from observer to source\n",
    "D_os = cosmo.angular_diameter_distance(z=z_source)\n",
    "print(D_os)\n",
    "\n",
    "#distance from lens to source\n",
    "D_ls = cosmo.angular_diameter_distance_z1z2(z1=z_lens, z2=z_source)\n",
    "print(D_ls)\n",
    "\n",
    "#distance factor\n",
    "Dls_over_Dos = D_ls/D_os\n",
    "Dls_over_Dos = Dls_over_Dos.value\n",
    "print(\"Dls_over_Dos = \",Dls_over_Dos)\n",
    "\n",
    "#apply to files to get arrays for this redshift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#parameter 1\n",
    "print(0.43206991039039117*2.5)\n",
    "print(0.43206991039039117*10)\n",
    "#parameter 7\n",
    "print(0.43206991039039117*(-0.2))\n",
    "print(0.43206991039039117*4)\n",
    "#parameter 8\n",
    "print(0.43206991039039117*0)\n",
    "print(0.43206991039039117*4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lensmodel to PixSrc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#need to read in lensmodel start file and turn into what can go into pixsrc input file\n",
    "\n",
    "#make a double for loop eventually\n",
    "\n",
    "print(numpy.log10(Dls_over_Dos))\n",
    "\n",
    "for n in range(101):\n",
    "\n",
    "    print(n)\n",
    "\n",
    "    #gets total number of rows to go through\n",
    "    first_row = numpy.genfromtxt('/mnt/c/Users/lana-/Desktop/fit4/range3d/draw'+str(n)+'-src.start',max_rows=1)\n",
    "    # print(first_row)\n",
    "    init_val = numpy.int((numpy.genfromtxt('/mnt/c/Users/lana-/Desktop/fit4/range3d/draw'+str(n)+'-src.start',max_rows=1))[0])\n",
    "    # print(init_val)\n",
    "    tot_num_rows = 2*init_val+1\n",
    "    # print(tot_num_rows)\n",
    "\n",
    "    panda_read = pandas.read_csv('/mnt/c/Users/lana-/Desktop/fit4/range3d/draw'+str(n)+'-src.start',names=(\"type\",\"co1\",\"co2\",\"co3\",\"co4\",\"co5\",\"co6\",\"co7\",\"co8\",\"co9\",\"co10\",\"co11\"),skiprows=0,sep='\\s+')#,header=None)\n",
    "    #panda_read = pandas.DataFrame(data=panda_read)#,columns=numpy.linspace(0,11,12))\n",
    "    # print(panda_read)\n",
    "    # print(type(panda_read))\n",
    "    #panda_read.loc[row].iat[column]\n",
    "    #select what to change\n",
    "    # print(panda_read[['co2','co5','co7']].iloc[1:(init_val+1)])\n",
    "    #multiply selected columns in specific rows by negative 1 and get rid of -0.0\n",
    "    panda_read.iloc[1:276, [2,5,7]] *= -1\n",
    "    panda_read.iloc[1:276, [2,5,7]] = panda_read.iloc[1:276, [2,5,7]] + 0.0\n",
    "    # print(panda_read)\n",
    "\n",
    "    #now need to scale to the right redshift for pixsrc\n",
    "    panda_read.iloc[1:276, [1]] += numpy.log10(Dls_over_Dos)\n",
    "    panda_read.iloc[1:276, [6,7]] *= Dls_over_Dos\n",
    "\n",
    "    #need integer headers to stay the same\n",
    "    headers = ['']*len(panda_read.columns)\n",
    "    headers[0] = numpy.int(first_row[0])\n",
    "    headers[1] = numpy.int(first_row[1])\n",
    "    headers[2] = numpy.int(first_row[2])\n",
    "\n",
    "    #panda_read.drop(0).to_csv('/mnt/c/Users/lana-/Desktop/A370_arc_red/savehere/draw'+str(n)+'-src.start',index=None,header=headers,sep=' ')\n",
    "    panda_read.drop(0).to_csv('/mnt/c/Users/lana-/Desktop/pixsrc_fit4/draw'+str(n)+'-src.start',index=None,header=headers,sep=' ')\n",
    "\n",
    "    #panda_new = pandas.read_csv('/mnt/c/Users/lana-/Desktop/A370_arc_red/savehere/draw'+str(n)+'-src.start',names=(\"type\",\"co1\",\"co2\",\"co3\",\"co4\",\"co5\",\"co6\",\"co7\",\"co8\",\"co9\",\"co10\",\"co11\"),skiprows=0,sep='\\s+')#,header=None)\n",
    "    # print(panda_read)\n",
    "    # print(n)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#need to read in lensmodel start file and turn into what can go into pixsrc input file\n",
    "#for 2D\n",
    "#make a double for loop\n",
    "\n",
    "print(numpy.log10(Dls_over_Dos))\n",
    "\n",
    "for n in range(100):\n",
    "\n",
    "    print(n)\n",
    "    print('%03i'%n)\n",
    "\n",
    "    #gets total number of rows to go through\n",
    "    first_row = numpy.genfromtxt('/mnt/c/Users/lana-/Desktop/range2d/startfiles/range'+str('%03i'%n)+'.start',max_rows=1)\n",
    "    # print(first_row)\n",
    "    init_val = numpy.int((numpy.genfromtxt('/mnt/c/Users/lana-/Desktop/range2d/startfiles/range'+str('%03i'%n)+'.start',max_rows=1))[0])\n",
    "    # print(init_val)\n",
    "    tot_num_rows = 2*init_val+1\n",
    "    # print(tot_num_rows)\n",
    "\n",
    "    panda_read = pandas.read_csv('/mnt/c/Users/lana-/Desktop/range2d/startfiles/range'+str('%03i'%n)+'.start',names=(\"type\",\"co1\",\"co2\",\"co3\",\"co4\",\"co5\",\"co6\",\"co7\",\"co8\",\"co9\",\"co10\",\"co11\"),skiprows=0,sep='\\s+')#,header=None)\n",
    "    #panda_read = pandas.DataFrame(data=panda_read)#,columns=numpy.linspace(0,11,12))\n",
    "    # print(panda_read)\n",
    "    # print(type(panda_read))\n",
    "    #panda_read.loc[row].iat[column]\n",
    "    #select what to change\n",
    "    # print(panda_read[['co2','co5','co7']].iloc[1:(init_val+1)])\n",
    "    #multiply selected columns in specific rows by negative 1 and get rid of -0.0\n",
    "    panda_read.iloc[1:276, [2,5,7]] *= -1\n",
    "    panda_read.iloc[1:276, [2,5,7]] = panda_read.iloc[1:276, [2,5,7]] + 0.0\n",
    "    # print(panda_read)\n",
    "\n",
    "    #now need to scale to the right redshift for pixsrc\n",
    "    panda_read.iloc[1:276, [1]] += numpy.log10(Dls_over_Dos)\n",
    "    panda_read.iloc[1:276, [6,7]] *= Dls_over_Dos\n",
    "\n",
    "    #need integer headers to stay the same\n",
    "    headers = ['']*len(panda_read.columns)\n",
    "    headers[0] = numpy.int(first_row[0])\n",
    "    headers[1] = numpy.int(first_row[1])\n",
    "\n",
    "    #panda_read.drop(0).to_csv('/mnt/c/Users/lana-/Desktop/A370_arc_red/savehere/draw'+str(n)+'-src.start',index=None,header=headers,sep=' ')\n",
    "    panda_read.drop(0).to_csv('/mnt/c/Users/lana-/Desktop/2D_for_pixsrc/range'+str('%03i'%n)+'.start',index=None,header=headers,sep=' ')\n",
    "\n",
    "    #panda_new = pandas.read_csv('/mnt/c/Users/lana-/Desktop/A370_arc_red/savehere/draw'+str(n)+'-src.start',names=(\"type\",\"co1\",\"co2\",\"co3\",\"co4\",\"co5\",\"co6\",\"co7\",\"co8\",\"co9\",\"co10\",\"co11\"),skiprows=0,sep='\\s+')#,header=None)\n",
    "    # print(panda_read)\n",
    "    # print(n)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    # #now print out the next init_val number of rows\n",
    "    # values_to_change = (numpy.genfromtxt('/mnt/c/Users/lana-/Desktop/A370_arc_red/draw'+str(n)+'-src.start',dtype=('U10',float,float,float,float,float,float,float,float,float,float),skip_header=1,max_rows=init_val)).tolist()\n",
    "    # # print(values_to_change)\n",
    "    # # print(type(values_to_change))\n",
    "\n",
    "    # #now for each column 2 5 7, need to multiply by 1\n",
    "    # values_to_change[:][2] = values_to_change[:][2]*(-1)\n",
    "    # values_to_change[:][5] = values_to_change[:][5]*(-1)\n",
    "    # values_to_change[:][7] = values_to_change[:][7]*(-1)\n",
    "    # #print(type(values_to_change))\n",
    "\n",
    "    # #take file, edit the values, replace them with the things in values_to_change\n",
    "\n",
    "    # # #need to take this and make it a string so can re-add the types of mass functions\n",
    "    # # need_strings = numpy.genfromtxt('/mnt/c/Users/lana-/Desktop/A370_arc_red/draw'+str(n)+'-src.start',skip_header=1,max_rows=init_val,dtype=str)    \n",
    "    # # values_to_change = numpy.array2string(values_to_change)\n",
    "    # # print('wheeee')\n",
    "    # # print(values_to_change)\n",
    "    # # print(type(values_to_change))\n",
    "    # # #need to make new ..string array?\n",
    "    # # # values_to_change[:,0] = need_strings[:,0]\n",
    "    # # changed_vals = need_strings[:,0] + values_to_change[:,1] + values_to_change[:,2] + values_to_change[:,3] + values_to_change[:,4] + values_to_change[:,5] + values_to_change[:,6] + values_to_change[:,7] + values_to_change[:,8] + values_to_change[:,9] + values_to_change[:,10]\n",
    "    # # print(changed_vals)\n",
    "\n",
    "    # #no change values\n",
    "    # no_ch_val = numpy.genfromtxt('/mnt/c/Users/lana-/Desktop/A370_arc_red/draw'+str(n)+'-src.start',skip_header=1+init_val,max_rows=init_val)\n",
    "    # # print(no_ch_val)\n",
    "\n",
    "    # #now need to write out to a new file that is in the format of setlens - could just write the \n",
    "    # total_file = first_row.tolist() + values_to_change + no_ch_val.tolist()\n",
    "    # #print(total_file)\n",
    "\n",
    "    #import pickle\n",
    "\n",
    "    # with open('/mnt/c/Users/lana-/Desktop/A370_arc_red/thing'+str(n)+'.txt','w') as fp:\n",
    "    #     fp.write(str(first_row.tolist())+'\\n')\n",
    "    #     fp.write('\\n'.join(str(values_to_change)))\n",
    "    #     fp.write(str(no_ch_val.tolist()))\n",
    "\n",
    "    # ascii.write(total_file,'confused.csv',  overwrite=True, quotechar=' ')\n",
    "\n",
    "\n",
    "# file_thing = open('/mnt/c/Users/lana-/Desktop/A370_arc_red/draw'+str(n)+'-src.start','r')\n",
    "# #print(file_thing.read()) #this outputs ..the entire thing\n",
    "# #now to figure out how to edit it?\n",
    "# file_thing.read(5) #this is not useful because it just works with the number of characters\n",
    "\n",
    "\n",
    "#work in rows\n",
    "\n",
    "#first line - first value is number of mass models, total lines is that ((value)*2)+1\n",
    "\n",
    "#for that many lines after that, go through and ignore string (0) then count parameters 2 5 7 and multiply them by -1\n",
    "\n",
    "#ignore the next number of lines that say what to vary\n",
    "\n",
    "#output as new file, can write in setlens\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    # test_billion = ascii.read('/mnt/c/Users/lana-/Desktop/A370_arc_red/draw'+str(n)+'-src.start', fast_reader=False, delimiter=',', data_start = 1)\n",
    "    # print(test_billion)\n",
    "    # print(type(test_billion))\n",
    "    # print(test_billion[0][0][1])\n",
    "\n",
    "\n",
    "\n",
    "    # #This gets the first row:\n",
    "    # first_row = ascii.read('/mnt/c/Users/lana-/Desktop/A370_arc_red/draw'+str(n)+'-src.start',format='no_header', fast_reader=False, delimiter=' ', data_start = 0, data_end = 1)\n",
    "\n",
    "    # # This gets the first block\n",
    "    # first_block = ascii.read('/mnt/c/Users/lana-/Desktop/A370_arc_red/draw'+str(n)+'-src.start',format='no_header', fast_reader=False, delimiter=' ', data_start = 1, data_end = first_row['col1'][0]+1)\n",
    "\n",
    "    # # This gets the second block \n",
    "    # second_block = ascii.read('/mnt/c/Users/lana-/Desktop/A370_arc_red/draw'+str(n)+'-src.start',format='no_header', fast_reader=False, delimiter=' ', data_start = first_row['col1'][0]+1)\n",
    "\n",
    "\n",
    "    # # This makes one big table that u can then save!\n",
    "\n",
    "    # #start by renaming columns:\n",
    "    # for i in range(len(first_block.colnames)):\n",
    "    #     col = first_block.colnames[i]\n",
    "    #     first_block.rename_column(col, f'first_block_col_{i+1}')\n",
    "\n",
    "    # for i in range(len(second_block.colnames)):\n",
    "    #     col = second_block.colnames[i]\n",
    "    #     second_block.rename_column(col, f'second_block_col_{i+1}')\n",
    "\n",
    "\n",
    "    # # This makes a new table as a horizontal stack of the tables of the first and second blocks of data\n",
    "    # Table = astropy.table.vstack([first_row,first_block,second_block])\n",
    "\n",
    "    # #This adds table meta data. Here I put the data from the first row. table.meta is just an ordered dictionary (fancy dictionary). \n",
    "    # Table.meta['N'] = first_row['col1'][0]\n",
    "    # Table.meta['Second Number'] = first_row['col2'][0]\n",
    "    # Table.meta['Third Number'] = first_row['col3'][0]\n",
    "\n",
    "\n",
    "    # ascii.write(Table, 'idkman.start', overwrite = True, format = 'txt')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PSF/Noise/FITS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#need to add info to example FITS file of lensed images\n",
    "#https://docs.astropy.org/en/stable/io/fits/usage/headers.html\n",
    "\n",
    "#open two FITS files\n",
    "simple_edit = fits.open('/mnt/c/Users/lana-/Desktop/PixSrcTests/simple_edits.fits')\n",
    "simple_edit_hdu = simple_edit[0].header\n",
    "simplee = fits.open('/mnt/c/Users/lana-/Desktop/PixSrcTests/simple.fits')\n",
    "simplee_hdu = simplee[0].header\n",
    "#copy over header\n",
    "simple_edit[0].header = simplee_hdu\n",
    "simple_edit.writeto('/mnt/c/Users/lana-/Desktop/PixSrcTests/simple_edit2.fits', overwrite=True)\n",
    "\n",
    "\n",
    "#convolve the minitest with a PSF - maybe can use PSF from 814 or something\n",
    "\n",
    "#https://docs.astropy.org/en/stable/api/astropy.convolution.convolve.html#astropy.convolution.convolve\n",
    "\n",
    "#load the minitest model galaxy\n",
    "minitest2 = fits.open('/mnt/c/Users/lana-/Desktop/PixSrcTests/z_test1.fits')[0]\n",
    "#load the psf\n",
    "cross_psf = fits.open('/mnt/c/Users/lana-/Desktop/cross.psf.fits')[0]\n",
    "\n",
    "\n",
    "#convolution of minitest galaxy with psf\n",
    "mini_convolve_psf = convolve(minitest2.data,cross_psf.data)\n",
    "\n",
    "#add noise\n",
    "mini_conv_noise = mini_convolve_psf + make_noise_image(mini_convolve_psf.shape, distribution='gaussian', mean=0.0005, stddev=0.0005, seed=5)\n",
    "\n",
    "fig, ax = subplots(nrows=1, ncols=5, figsize=(20,55), squeeze=True)\n",
    "\n",
    "mini1 = ax[0].imshow(minitest2.data, cmap='viridis', origin='lower')#, norm=simple_norm(minitest2.data,stretch='log',log_a=100))\n",
    "ax[0].set_title('minitest2')\n",
    "# colorbar(mini1,ax=ax[0])\n",
    "\n",
    "mini2 = ax[1].imshow(cross_psf.data, cmap='viridis', origin='lower')#, norm=simple_norm(cross_psf.data,stretch='log',log_a=100))\n",
    "ax[1].set_title('cross_psf')\n",
    "\n",
    "mini3 = ax[2].imshow(mini_convolve_psf, cmap='viridis', origin='lower')#, norm=simple_norm(mini_convolve_psf.data,stretch='log',log_a=100))\n",
    "ax[2].set_title('convolved with psf')\n",
    "\n",
    "mini4 = ax[3].imshow(mini_conv_noise.data, cmap='viridis', origin='lower')#, norm=simple_norm(mini_convolve_psf.data,stretch='log',log_a=100))\n",
    "ax[3].set_title('convolved + noise')\n",
    "\n",
    "mini5 = ax[4].imshow(minitest2.data-mini_conv_noise.data, cmap='viridis', origin='lower')#, norm=simple_norm(minitest2.data-mini_convolve_psf.data,stretch='log',log_a=100))\n",
    "ax[4].set_title('residuals')\n",
    "\n",
    "savefig('/mnt/c/Users/lana-/Desktop/PixSrcTests/z_test11.png',bbox_inches='tight')\n",
    "\n",
    "\n",
    "#set new variable\n",
    "minitest3 = minitest2\n",
    "#open example FITS file with useful header\n",
    "simplee = fits.open('/mnt/c/Users/lana-/Desktop/PixSrcTests/z_test1.fits')\n",
    "simplee_hdu = simplee[0].header\n",
    "#transfer header info\n",
    "minitest3.header = simplee_hdu\n",
    "#coordinate alignment and increment - since my pixels are set by me to 1 arcsecond, need to convert from arcseconds to degrees (1 arcsecond = 1/3600 degrees)\n",
    "minitest3.header['CD1_1'] = -2.7777777777777778e-4\n",
    "minitest3.header['CD1_2'] = 0.0\n",
    "minitest3.header['CD2_1'] = 0.0\n",
    "minitest3.header['CD2_2'] = 2.7777777777777778e-4\n",
    "#reference point x and y - here set to center / origin\n",
    "minitest3.header['CRPIX1'] = 51\n",
    "minitest3.header['CRPIX2'] = 51\n",
    "minitest3.header['CRVAL1'] = 161.25\n",
    "minitest3.header['CRVAL2'] = 58\n",
    "#coordinate type\n",
    "minitest3.header['CTYPE1'] = 'RA--TAN'\n",
    "minitest3.header['CTYPE2'] = 'DEC--TAN'\n",
    "#unit keywords\n",
    "minitest3.header['CUNIT1'] = 'deg     '\n",
    "minitest3.header['CUNIT2'] = 'deg     '\n",
    "minitest3.data = mini_conv_noise.data\n",
    "minitest3.writeto('/mnt/c/Users/lana-/Desktop/PixSrcTests/z_test11.fits', overwrite=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SETTING UP THE CODE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #CO transitions in source\n",
    "# nu_rest_arc_CO_J10 = 115.3/(1+0.7251)\n",
    "# nu_rest_arc_CO_J21 = 230.5/(1+0.7251)\n",
    "# nu_rest_arc_CO_J32 = 345.8/(1+0.7251)\n",
    "# print(nu_rest_arc_CO_J10)\n",
    "# print(nu_rest_arc_CO_J21)\n",
    "# print(nu_rest_arc_CO_J32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Specify the reference position as an astropy SkyCoord object\n",
    "fieldcenter = SkyCoord('02h39m52.9s','-01d34m36.5s')\n",
    "print(fieldcenter)\n",
    "print(fieldcenter.ra.hour)\n",
    "print(fieldcenter.dec.hour)\n",
    "print(fieldcenter.ra.degree)\n",
    "print(fieldcenter.dec.degree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deflection_maps = numpy.load(\"fit0-los1-scale1-defs-z0.725.npy\")\n",
    "print(len(deflection_maps))\n",
    "numpy.load(\"fit0-los1-scale1-defs-z0.725.npy\")\n",
    "#are flattened, need to reshape into 2D array to view them\n",
    "\n",
    "#Catie says:\n",
    "#If you look at the shape of the deflections array its 100 x 1442401 x 2\n",
    "#so 100 maps of 1201 x 1201 pixels and then the 2 is for x & y\n",
    "#So to get the maps of the first model you’d do xmap = defs[0].T[0].reshape(1201,1201), and ymap = defs[0].T[1].reshape(1201,1201)\n",
    "\n",
    "#test\n",
    "xmap = deflection_maps[0].T[0].reshape(1201,1201)\n",
    "ymap = deflection_maps[0].T[1].reshape(1201,1201)\n",
    "# print(xmap)\n",
    "# print(ymap)\n",
    "\n",
    "magnification_maps = numpy.load(\"fit0-los1-scale1-mags-z0.725-signed.npy\")\n",
    "print(len(magnification_maps))\n",
    "numpy.load(\"fit0-los1-scale1-mags-z0.725-signed.npy\")\n",
    "magmap = magnification_maps[0].reshape(1201,1201)\n",
    "# print(magmap)\n",
    "#probably need to reshape this?\n",
    "\n",
    "#Catie says:\n",
    "#It definitely doesn’t save them like the old models did in the .dat files. \n",
    "#I’m not even sure the image/source positions are explicitly calculated in the bayesian analysis\n",
    "#I think the theory actually assumes the source positions are just nuisance parameters and integrates over them. \n",
    "#Sooo I’m not sure how to get around that. You’d have to ask Chuck"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #fix this attempt to plot what I have\n",
    "# print(len(magmap[0]))\n",
    "# #plasma colormap is really pretty, but need a two-color one to show negative and positive magnifications\n",
    "# figure(figsize=(10,10))\n",
    "# imshow(magmap,cmap = \"PiYG\",vmin=-50,vmax=50,origin=\"lower\")\n",
    "# colorbar()\n",
    "# # xlim(0,1201)\n",
    "# # ylim(0,1201)\n",
    "# xlim(200,1000)\n",
    "# ylim(200,1000)\n",
    "# #Invalid shape (1201,) for image data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#step 1: include distance ratio D_ls/D_os to the deflections alphax and alphay\n",
    "#the distances here are ANGULAR DIAMETER DISTANCES - will find using astropy.cosmology\n",
    "#because using ratios, will leave them in Mpc\n",
    "\n",
    "#observer\n",
    "z_obs = 0\n",
    "#lens, which here is Abell 370\n",
    "z_lens = 0.375\n",
    "#source galaxy in the arc\n",
    "z_source = 0.7251\n",
    "\n",
    "#distance from observer to source\n",
    "D_os = cosmo.angular_diameter_distance(z=z_source)\n",
    "print(D_os)\n",
    "\n",
    "#distance from lens to source\n",
    "D_ls = cosmo.angular_diameter_distance_z1z2(z1=z_lens, z2=z_source)\n",
    "print(D_ls)\n",
    "\n",
    "#distance factor\n",
    "Dls_over_Dos = D_ls/D_os\n",
    "Dls_over_Dos = Dls_over_Dos.value\n",
    "print(\"Dls_over_Dos = \",Dls_over_Dos)\n",
    "\n",
    "#apply to files to get arrays for this redshift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set up functions for coordinate system transformations:\n",
    "#world: (RA,Dec) right ascension and declination\n",
    "#pix: pixels\n",
    "#xy: (x,y) in arcseconds relative to the field center; coordinates used in lensmodel\n",
    "\n",
    "#xy coordinates to RA and Dec\n",
    "#Angle https://docs.astropy.org/en/stable/api/astropy.coordinates.Angle.html\n",
    "def xy2world(x,y):\n",
    "    RA_offset = Angle(-x,unit=u.arcsec) / (numpy.cos(fieldcenter.dec.to('radian')))\n",
    "    Dec_offset = Angle(y,unit=u.arcsec)\n",
    "    xy2world_return = SkyCoord(fieldcenter.ra+RA_offset, fieldcenter.dec+Dec_offset)\n",
    "    return xy2world_return\n",
    "    \n",
    "#xy coordinates to pixels\n",
    "def xy2pix(x,y,theWCS):\n",
    "    tmp = xy2world(x,y)\n",
    "    xypix_return = tmp.to_pixel(theWCS)\n",
    "    return xypix_return\n",
    "#what does .to_pixel do?  isn't there a world2pix in astropy already?\n",
    "#what is theWCS?  \n",
    "#is tpm just a placeholder variable?\n",
    "\n",
    "#RA and Dec to xy coordinates\n",
    "def world2xy(coord):\n",
    "    tmp = fieldcenter.spherical_offsets_to(coord)\n",
    "    world2xy_return_1 = -tmp[0].to('arcsec').value\n",
    "    world2xy_return_2 = tmp[1].to('arcsec').value\n",
    "    return world2xy_return_1, world2xy_return_2\n",
    "#is .spherical_offsets_to something you can do with a SkyCoord object?\n",
    "\n",
    "#pixels to xy coordinates\n",
    "def pix2xy(x_pix,y_pix,theWCS):\n",
    "    pix2xy_return = world2xy(wcs.utils.pixel_to_skycoord(x_pix,y_pix,theWCS))\n",
    "    return pix2xy_return\n",
    "#see:\n",
    "#https://docs.astropy.org/en/stable/api/astropy.wcs.utils.pixel_to_skycoord.html\n",
    "#https://docs.astropy.org/en/stable/api/astropy.wcs.utils.skycoord_to_pixel.html\n",
    "\n",
    "\n",
    "\n",
    "#?we also have world2pix and pix2world as functions in astropy already\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#testing coordinate transformations..once again :,D\n",
    "\n",
    "# Read in RGB file\n",
    "RGBfile = 'abell370_RGB.fits'\n",
    "RGB = fits.open(RGBfile)\n",
    "wcs_rgb = WCS(RGBfile)\n",
    "\n",
    "# #Specify the reference position as an astropy SkyCoord object\n",
    "# testpt = SkyCoord('39.98878720deg','-1.55425670deg')\n",
    "# print(testpt)\n",
    "# print(testpt.ra.hour)\n",
    "# print(testpt.dec.hour)\n",
    "# print(testpt.ra.degree)\n",
    "# print(testpt.dec.degree)\n",
    "# testpt2 = SkyCoord(str(testpt.ra.degree)+'deg',str(testpt.dec.degree)+'deg')\n",
    "# convertattempt = world2xy(testpt)\n",
    "# print(type(convertattempt))\n",
    "# try2 = xy2pix(convertattempt[0],convertattempt[1],wcs_rgb)\n",
    "# print(try2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PSF BEGINS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://photutils.readthedocs.io/en/stable/epsf.html\n",
    "#stars_814_isolated_coor is in degrees\n",
    "stars_814_isolated_coor = numpy.loadtxt('/mnt/c/Users/lana-/Desktop/stars_iso_814_coor_ex.txt')\n",
    "stars_606_isolated_coor = numpy.loadtxt('/mnt/c/Users/lana-/Desktop/stars_iso_606_coor_ex.txt')\n",
    "stars_435_isolated_coor = numpy.loadtxt('/mnt/c/Users/lana-/Desktop/stars_iso_435_coor_ex.txt')\n",
    "# print(stars_814_isolated)\n",
    "# print(type(stars_814_isolated))\n",
    "x_stars814 = stars_814_isolated_coor[:,0]\n",
    "y_stars814 = stars_814_isolated_coor[:,1]\n",
    "print(x_stars814)\n",
    "print(y_stars814)\n",
    "x_stars606 = stars_606_isolated_coor[:,0]\n",
    "y_stars606 = stars_606_isolated_coor[:,1]\n",
    "print(x_stars606)\n",
    "print(y_stars606)\n",
    "x_stars435 = stars_435_isolated_coor[:,0]\n",
    "y_stars435 = stars_435_isolated_coor[:,1]\n",
    "print(x_stars435)\n",
    "print(y_stars435)\n",
    "\n",
    "#we start with degrees, which are world coordinates, and we put them in SkyCoord objects to manipulate them\n",
    "#we convert degrees(world) to xy with world2xy\n",
    "#we convert xy to pixels with xy2pix\n",
    "#loop\n",
    "#set up starpoints_x and starpoints_y arrays for F814W filter\n",
    "starpoints_x814 = x_stars814*0.\n",
    "starpoints_y814 = y_stars814*0.\n",
    "for i in range(len(x_stars814)):\n",
    "    for j in range(len(y_stars814)):\n",
    "        #Specify the reference position as an astropy SkyCoord object\n",
    "        testpt = SkyCoord(str(x_stars814[i])+'deg',str(y_stars814[j])+'deg')\n",
    "        # print(testpt)\n",
    "        # print(testpt.ra.hour)\n",
    "        # print(testpt.dec.hour)\n",
    "        # print(testpt.ra.degree)\n",
    "        # print(testpt.dec.degree)\n",
    "        testpt2 = SkyCoord(str(testpt.ra.degree)+'deg',str(testpt.dec.degree)+'deg')\n",
    "        convertattempt = world2xy(testpt)\n",
    "        # print(type(convertattempt))\n",
    "        try2 = xy2pix(convertattempt[0],convertattempt[1],wcs_rgb)\n",
    "        # print(try2)\n",
    "        # print(try2[0])\n",
    "        # print(try2[1])\n",
    "        starpoints_x814[i] = try2[0]\n",
    "        starpoints_y814[j] = try2[1]\n",
    "\n",
    "#set up starpoints_x and starpoints_y arrays for F814W filter\n",
    "starpoints_x606 = x_stars606*0.\n",
    "starpoints_y606 = y_stars606*0.\n",
    "for i in range(len(x_stars606)):\n",
    "    for j in range(len(y_stars606)):\n",
    "        #Specify the reference position as an astropy SkyCoord object\n",
    "        testpt = SkyCoord(str(x_stars606[i])+'deg',str(y_stars606[j])+'deg')\n",
    "        # print(testpt)\n",
    "        # print(testpt.ra.hour)\n",
    "        # print(testpt.dec.hour)\n",
    "        # print(testpt.ra.degree)\n",
    "        # print(testpt.dec.degree)\n",
    "        testpt2 = SkyCoord(str(testpt.ra.degree)+'deg',str(testpt.dec.degree)+'deg')\n",
    "        convertattempt = world2xy(testpt)\n",
    "        # print(type(convertattempt))\n",
    "        try2 = xy2pix(convertattempt[0],convertattempt[1],wcs_rgb)\n",
    "        # print(try2)\n",
    "        # print(try2[0])\n",
    "        # print(try2[1])\n",
    "        starpoints_x606[i] = try2[0]\n",
    "        starpoints_y606[j] = try2[1]\n",
    "\n",
    "#set up starpoints_x and starpoints_y arrays for F814W filter\n",
    "starpoints_x435 = x_stars435*0.\n",
    "starpoints_y435 = y_stars435*0.\n",
    "for i in range(len(x_stars435)):\n",
    "    for j in range(len(y_stars435)):\n",
    "        #Specify the reference position as an astropy SkyCoord object\n",
    "        testpt = SkyCoord(str(x_stars435[i])+'deg',str(y_stars435[j])+'deg')\n",
    "        # print(testpt)\n",
    "        # print(testpt.ra.hour)\n",
    "        # print(testpt.dec.hour)\n",
    "        # print(testpt.ra.degree)\n",
    "        # print(testpt.dec.degree)\n",
    "        testpt2 = SkyCoord(str(testpt.ra.degree)+'deg',str(testpt.dec.degree)+'deg')\n",
    "        convertattempt = world2xy(testpt)\n",
    "        # print(type(convertattempt))\n",
    "        try2 = xy2pix(convertattempt[0],convertattempt[1],wcs_rgb)\n",
    "        # print(try2)\n",
    "        # print(try2[0])\n",
    "        # print(try2[1])\n",
    "        starpoints_x435[i] = try2[0]\n",
    "        starpoints_y435[j] = try2[1]\n",
    "\n",
    "print(starpoints_x814)\n",
    "print(starpoints_y814)\n",
    "print(starpoints_x606)\n",
    "print(starpoints_y606)\n",
    "print(starpoints_x435)\n",
    "print(starpoints_y435)\n",
    "\n",
    "#it works!!  :D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#notes on Sersic source:\n",
    "\n",
    "#src_params contains the parameters to be given to the Sersic source function\n",
    "\n",
    "#src_params: (n, R_eff, e, theta_e)\n",
    "#n: Sersic index\n",
    "#R_eff: effective radius\n",
    "#e: ellipticity\n",
    "#theta_e: position angle\n",
    "\n",
    "#determined ellipticity\n",
    "ell_det = 0.8\n",
    "#determined angle\n",
    "ang_det = (numpy.pi)/10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SELECT STARS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "abell370_color = fits.open('abell370_RGB.fits')\n",
    "\n",
    "# zero_row = abell370_color[0].data\n",
    "# r_file = abell370_color[1].data\n",
    "# g_file = abell370_color[2].data\n",
    "# b_file = abell370_color[3].data\n",
    "\n",
    "# r_file = img_as_float(r_file)\n",
    "# g_file = img_as_float(g_file)\n",
    "# b_file = img_as_float(b_file)\n",
    "\n",
    "# abell370_color.info()\n",
    "abell370_color.close()\n",
    "# Read in RGB file\n",
    "RGBfile = 'abell370_RGB.fits'\n",
    "RGB = fits.open(RGBfile)\n",
    "wcs_rgb = WCS(RGBfile)\n",
    "# Put separate extensions into own R/G/B arrays\n",
    "imr=Image.fromarray(RGB[1].data,mode=None) \n",
    "img=Image.fromarray(RGB[2].data,mode=None)\n",
    "imb=Image.fromarray(RGB[3].data,mode=None)\n",
    "\n",
    "# Merge them back into one image\n",
    "merged=Image.merge(\"RGB\",(imr,img,imb))\n",
    "# Plot it\n",
    "fig = figure(figsize=(15,15))\n",
    "imshow(merged, origin='lower')\n",
    "#out of order so it plots colors easily\n",
    "scatter(starpoints_x435,starpoints_y435,marker='x',s=50,color=\"aqua\")#,alpha=0.5)\n",
    "scatter(starpoints_x606,starpoints_y606,marker='_',s=100,color=\"lime\")#,alpha=0.5)\n",
    "scatter(starpoints_x814,starpoints_y814,marker='|',s=100,color=\"orange\")#,alpha=0.5)\n",
    "\n",
    "print(type(imr))\n",
    "print(imr)\n",
    "print(imr.size)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sci Img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SCIENCE IMAGES\n",
    "#need to replace one at a time, start with F814W\n",
    "sci_im_red = fits.open('/mnt/c/Users/lana-/Desktop/hlsp_frontier_hst_acs-30mas-selfcal_abell370_f814w_v1.0-epoch1_drz.fits')[0]\n",
    "imr = sci_im_red.data\n",
    "# imre=Image.fromarray(sci_im_red[0].data,mode=None)\n",
    "# imree = numpy.array(imr,dtype=float)\n",
    "wcs_rgb = WCS(sci_im_red)\n",
    "#now plot\n",
    "# fig = figure(figsize=(15,15))\n",
    "# imshow(imr, origin='lower')\n",
    "\n",
    "#need to replace one at a time, next F606W\n",
    "sci_im_green = fits.open('/mnt/c/Users/lana-/Desktop/hlsp_frontier_hst_acs-30mas-selfcal_abell370_f606w_v1.0-epoch1_drz.fits')[0]\n",
    "img = sci_im_green.data\n",
    "wcs_rgb = WCS(sci_im_green)\n",
    "#now plot\n",
    "# fig = figure(figsize=(15,15))\n",
    "# imshow(img, origin='lower')\n",
    "\n",
    "#need to replace one at a time, now F435W\n",
    "sci_im_blue = fits.open('/mnt/c/Users/lana-/Desktop/hlsp_frontier_hst_acs-30mas-selfcal_abell370_f435w_v1.0-epoch1_drz.fits')[0]\n",
    "imb = sci_im_blue.data\n",
    "wcs_rgb = WCS(sci_im_blue)\n",
    "#now plot\n",
    "# fig = figure(figsize=(15,15))\n",
    "# imshow(imb, origin='lower')\n",
    "\n",
    "print(imr)\n",
    "print(type(imr))\n",
    "#w,h = imr.size\n",
    "ww,hh = imr.shape\n",
    "print(ww)\n",
    "print(hh)\n",
    "\n",
    "#make sure I'm not overwriting files - figure out how to close them after I get all the info out\n",
    "\n",
    "#no because this starts removing cluster members\n",
    "print(numpy.max(imr))\n",
    "print(numpy.min(imr))\n",
    "\n",
    "\n",
    "#trying to get rid of the overexposed pixels\n",
    "# for i in range(1):\n",
    "#     #imr[numpy.where(imr==numpy.max(imr))] = 0.\n",
    "#     imr[numpy.where(imr>0.05)] = 0.#numpy.nan #0.#maybe change these to numpy.nan so don't mess up the averages?  need to ignore them\n",
    "#     print(numpy.max(imr))\n",
    "#     #green\n",
    "#     img[numpy.where(img>0.05)] = 0.#numpy.nan #0.\n",
    "#     print(numpy.max(img))\n",
    "#     #blue\n",
    "#     imb[numpy.where(imb>0.05)] = 0.#numpy.nan #0.\n",
    "#     print(numpy.max(imb))\n",
    "\n",
    "# for x in range(500):\n",
    "#     for y in range(500):\n",
    "#         imr[y+6400][x+5400] = 0.\n",
    "#         img[y+6400][x+5400] = 0.\n",
    "#         imb[y+6400][x+5400] = 0.\n",
    "\n",
    "\n",
    "\n",
    "print(numpy.max(imr))\n",
    "print(numpy.min(imr))\n",
    "\n",
    "#plot again\n",
    "fig = figure(figsize=(15,15))\n",
    "imshow(imr, origin='lower', norm=simple_norm(imr, 'linear', percent=99.67), vmin=0.)#, cmap='Reds'\n",
    "#plot again\n",
    "fig = figure(figsize=(15,15))\n",
    "imshow(img, origin='lower', norm=simple_norm(img, 'linear', percent=99.67), vmin=0.)#, cmap='Greens'\n",
    "#plot again\n",
    "fig = figure(figsize=(15,15))\n",
    "imshow(imb, origin='lower', norm=simple_norm(imb, 'linear', percent=99.67), vmin=0.)#, cmap='Blues'\n",
    "\n",
    "#factor to convert between pixels in data image instead of RGB image\n",
    "data_factor = 2.\n",
    "\n",
    "#plot again\n",
    "fig = figure(figsize=(15,15))\n",
    "imshow(imr, origin='lower', norm=simple_norm(imr, 'linear', percent=99.67), vmin=0.)#, cmap='Reds'\n",
    "xlim(1600*data_factor,2200*data_factor)\n",
    "ylim(3400*data_factor,3600*data_factor)\n",
    "#plot again\n",
    "fig = figure(figsize=(15,15))\n",
    "imshow(img, origin='lower', norm=simple_norm(img, 'linear', percent=99.67), vmin=0.)#, cmap='Greens'\n",
    "xlim(1600*data_factor,2200*data_factor)\n",
    "ylim(3400*data_factor,3600*data_factor)\n",
    "#plot again\n",
    "fig = figure(figsize=(15,15))\n",
    "imshow(imb, origin='lower', norm=simple_norm(imb, 'linear', percent=99.67), vmin=0.)#, cmap='Blues'\n",
    "xlim(1600*data_factor,2200*data_factor)\n",
    "ylim(3400*data_factor,3600*data_factor)\n",
    "\n",
    "\n",
    "\n",
    "# #this is not working, figure out why\n",
    "# #NOW merge them into one RGB image just out of curiosity\n",
    "# merged = Image.merge(\"RGB\",(imr,img,imb))\n",
    "# #plot it\n",
    "# fig = figure(figsize=(15,15))\n",
    "# imshow(merged, origin='lower')\n",
    "# #out of order so it plots colors easily\n",
    "# scatter(starpoints_x435,starpoints_y435,marker='x',s=50,color=\"aqua\")#,alpha=0.5)\n",
    "# scatter(starpoints_x606,starpoints_y606,marker='_',s=100,color=\"lime\")#,alpha=0.5)\n",
    "# scatter(starpoints_x814,starpoints_y814,marker='|',s=100,color=\"orange\")#,alpha=0.5)\n",
    "\n",
    "\n",
    "print(imr)\n",
    "print(type(imr))\n",
    "print(imb[12000][8000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = figure(figsize=(15,15))\n",
    "imshow(merged, origin='lower')\n",
    "#out of order so it plots colors easily\n",
    "scatter(starpoints_x435,starpoints_y435,marker='x',s=50,color=\"aqua\")#,alpha=0.5)\n",
    "scatter(starpoints_x606,starpoints_y606,marker='_',s=100,color=\"lime\")#,alpha=0.5)\n",
    "scatter(starpoints_x814,starpoints_y814,marker='|',s=100,color=\"orange\")#,alpha=0.5)\n",
    "xlim(1600,2200)\n",
    "ylim(3400,3600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print them to see if they can be used as data\n",
    "print(imr)\n",
    "print(type(imr))\n",
    "print(img)\n",
    "print(imb)\n",
    "\n",
    "#https://stackoverflow.com/questions/384759/how-to-convert-a-pil-image-into-a-numpy-array\n",
    "imr_2_arr = numpy.array(imr,dtype=float) # im_arr.shape: height x width x channel \n",
    "img_2_arr = numpy.array(img,dtype=float)\n",
    "imb_2_arr = numpy.array(imb,dtype=float)\n",
    "print(imr_2_arr)\n",
    "print(type(imr_2_arr))\n",
    "# arr_2_imr = Image.fromarray(imr_2_arr)\n",
    "\n",
    "# Plot it\n",
    "figr = figure(figsize=(15,15))\n",
    "imshow(imr,cmap=\"Reds\",origin='lower')\n",
    "scatter(starpoints_x814,starpoints_y814,marker='x',color=\"orange\")#,alpha=0.25)\n",
    "\n",
    "figg = figure(figsize=(15,15))\n",
    "imshow(img,cmap=\"Greens\",origin='lower')\n",
    "scatter(starpoints_x606,starpoints_y606,marker='x',color=\"lime\")#,alpha=0.25)\n",
    "\n",
    "figb = figure(figsize=(15,15))\n",
    "imshow(imb,cmap=\"Blues\",origin='lower')\n",
    "scatter(starpoints_x435,starpoints_y435,marker='x',color=\"aqua\")#,alpha=0.25)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from photutils.datasets import load_simulated_hst_star_image\n",
    "# hdu = load_simulated_hst_star_image()\n",
    "# data = hdu.data  \n",
    "# print(data)\n",
    "# print(type(data))\n",
    "# from photutils.datasets import load_simulated_hst_star_image\n",
    "# from photutils.datasets import make_noise_image\n",
    "# #HERE - somehow get values of the FITS file in the same form as the sample data file, used the same way imshow is used, so should be same form - but what about boundaries??  \n",
    "# data += make_noise_image(data.shape, distribution='gaussian', mean=10., stddev=5., seed=123)\n",
    "# hdu = load_simulated_hst_star_image()\n",
    "# data = hdu.data\n",
    "# data += make_noise_image(data.shape, distribution='gaussian', mean=10., stddev=5., seed=123)\n",
    "# norm = simple_norm(data, 'sqrt', percent=99.)\n",
    "# imshow(data, norm=norm, origin='lower', cmap='viridis')\n",
    "# from photutils.detection import find_peaks\n",
    "# peaks_tbl = find_peaks(data, threshold=500.)  \n",
    "# peaks_tbl['peak_value'].info.format = '%.8g'  # for consistent table output  \n",
    "# print(peaks_tbl) \n",
    "# size = 25\n",
    "# hsize = (size - 1) / 2\n",
    "# x = peaks_tbl['x_peak']  \n",
    "# y = peaks_tbl['y_peak']  \n",
    "# mask = ((x > hsize) & (x < (data.shape[1] -1 - hsize)) & (y > hsize) & (y < (data.shape[0] -1 - hsize)))  \n",
    "# stars_tbl = Table()\n",
    "# stars_tbl['x'] = x[mask]  \n",
    "# stars_tbl['y'] = y[mask]  \n",
    "# mean_val, median_val, std_val = sigma_clipped_stats(data, sigma=2.)  \n",
    "# data -= median_val  \n",
    "# nddata = NDData(data=data) \n",
    "# print(nddata)\n",
    "# print(stars_tbl)\n",
    "# stars = extract_stars(nddata, stars_tbl, size=25) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CREATE EPSF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://photutils.readthedocs.io/en/stable/epsf.html\n",
    "#the arrays are:\n",
    "#imr_2_arr = numpy.array(imr)\n",
    "#img_2_arr = numpy.array(img)\n",
    "#imb_2_arr = numpy.array(imb)\n",
    "the_size = 51*data_factor #101 #needs an odd number, will add a pixel row and column if I do not do this\n",
    "hsize = (the_size-1)/2\n",
    "#red\n",
    "x_tabler = starpoints_x814*data_factor\n",
    "y_tabler = starpoints_y814*data_factor\n",
    "#green\n",
    "x_tableg = starpoints_x606*data_factor\n",
    "y_tableg = starpoints_y606*data_factor\n",
    "#blue\n",
    "x_tableb = starpoints_x435*data_factor\n",
    "y_tableb = starpoints_y435*data_factor\n",
    "#table\n",
    "stars_tblr = Table()\n",
    "stars_tblg = Table()\n",
    "stars_tblb = Table()\n",
    "#these two need to be -labeled- as x and y or SkyCoords\n",
    "stars_tblr['x'] = x_tabler\n",
    "stars_tblr['y'] = y_tabler\n",
    "#green\n",
    "stars_tblg['x'] = x_tableg\n",
    "stars_tblg['y'] = y_tableg\n",
    "#blue\n",
    "stars_tblb['x'] = x_tableb\n",
    "stars_tblb['y'] = y_tableb\n",
    "#which one do I use?  test both\n",
    "#red\n",
    "mean_valr, median_valr, std_valr = sigma_clipped_stats(imr,sigma=2.)  \n",
    "imr -= median_valr\n",
    "nddatar = NDData(data=imr)\n",
    "print(\"median_valr = sky value? =\",median_valr)\n",
    "#green\n",
    "mean_valg, median_valg, std_valg = sigma_clipped_stats(img,sigma=2.)  \n",
    "img -= median_valg\n",
    "nddatag = NDData(data=img)\n",
    "print(\"median_valg = sky value? =\",median_valg)\n",
    "#blue\n",
    "mean_valb, median_valb, std_valb = sigma_clipped_stats(imb,sigma=2.)  \n",
    "imb -= median_valb\n",
    "nddatab = NDData(data=imb)\n",
    "print(\"median_valb = sky value? =\",median_valb)\n",
    "# mean_val, median_val, std_val = sigma_clipped_stats(imr_2_arr,sigma=2.)  \n",
    "# imr_2_arr -= median_val\n",
    "# nddata = NDData(data=imr_2_arr)\n",
    "\n",
    "# print(nddata)\n",
    "# print(stars_tbl)\n",
    "\n",
    "#now extract stars\n",
    "#extract_stars(data, catalogs, size)\n",
    "starsr = extract_stars(nddatar, stars_tblg, size=the_size)\n",
    "starsg = extract_stars(nddatag, stars_tblg, size=the_size)\n",
    "starsb = extract_stars(nddatab, stars_tblg, size=the_size)\n",
    "\n",
    "#IMPORTANT SUBPLOTS HERE: commenting out because subplots keep giving errors, can uncomment each one on its own if need to see all at once\n",
    "print(\"RED\")\n",
    "#red\n",
    "# nrows = 4\n",
    "# ncols = 4\n",
    "fig, ax = subplots(nrows=1, ncols=7, figsize=(20, 20), squeeze=True)\n",
    "ax = ax.ravel() #return a contiguous flattened array\n",
    "for i in range(1 * 7):\n",
    "    norm = simple_norm(starsr[i], 'linear', percent=99.)\n",
    "    ax[i].imshow(starsr[i], norm=norm, origin='lower',cmap='viridis')\n",
    "    #add axis labels to identify which stars we are looking at\n",
    "print(\"GREEN\")\n",
    "#green\n",
    "fig, ax = subplots(nrows=1, ncols=7, figsize=(20, 20), squeeze=True)\n",
    "ax = ax.ravel() #return a contiguous flattened array\n",
    "for i in range(1 * 7):\n",
    "    norm = simple_norm(starsg[i], 'linear', percent=99.)\n",
    "    ax[i].imshow(starsg[i], norm=norm, origin='lower',cmap='viridis')\n",
    "print(\"BLUE\")\n",
    "#blue\n",
    "fig, ax = subplots(nrows=1, ncols=7, figsize=(20, 20), squeeze=True)\n",
    "ax = ax.ravel() #return a contiguous flattened array\n",
    "for i in range(1 * 7):\n",
    "    norm = simple_norm(starsb[i], 'linear', percent=99.)\n",
    "    ax[i].imshow(starsb[i], norm=norm, origin='lower',cmap='viridis')\n",
    "\n",
    "\n",
    "#PREVIOUS VERSION - THIS WORKED BEFORE\n",
    "# fig, ax = subplots(nrows=3, ncols=3, figsize=(10, 10), squeeze=True)\n",
    "# ax = ax.ravel() #return a contiguous flattened array\n",
    "# for i in range(3 * 3):\n",
    "#     norm = simple_norm(starsr[i], 'linear', percent=99.)\n",
    "#     ax[i].imshow(starsr[i], norm=norm, origin='lower',cmap='viridis')\n",
    "#     #add axis labels to identify which stars we are looking at\n",
    "# print(\"GREEN\")\n",
    "# #green\n",
    "# fig, ax = subplots(nrows=1, ncols=7, figsize=(20, 20), squeeze=True)\n",
    "# ax = ax.ravel() #return a contiguous flattened array\n",
    "# for i in range(1 * 7):\n",
    "#     norm = simple_norm(starsg[i], 'linear', percent=99.)\n",
    "#     ax[i].imshow(starsg[i], norm=norm, origin='lower',cmap='viridis')\n",
    "# print(\"BLUE\")\n",
    "# #blue\n",
    "# fig, ax = subplots(nrows=1, ncols=3, figsize=(10, 10), squeeze=True)\n",
    "# ax = ax.ravel() #return a contiguous flattened array\n",
    "# for i in range(1 * 3):\n",
    "#     norm = simple_norm(starsb[i], 'linear', percent=99.)\n",
    "#     ax[i].imshow(starsb[i], norm=norm, origin='lower',cmap='viridis')\n",
    "\n",
    "\n",
    "\n",
    "#what I had before for my smaller star sample\n",
    "# fig, ax = subplots(nrows=2, ncols=5, figsize=(50, 20), squeeze=True)\n",
    "# ax = ax.ravel() #return a contiguous flattened array\n",
    "# for i in range(2 * 5):\n",
    "#     norm = simple_norm(starsr[i], 'linear', percent=99.)\n",
    "#     ax[i].imshow(starsr[i], norm=norm, origin='lower',cmap='viridis')\n",
    "#     #add axis labels to identify which stars we are looking at\n",
    "# #green\n",
    "# fig, ax = subplots(nrows=2, ncols=2, figsize=(10, 10), squeeze=True)\n",
    "# ax = ax.ravel() #return a contiguous flattened array\n",
    "# for i in range(2 * 2):\n",
    "#     norm = simple_norm(starsg[i], 'linear', percent=99.)\n",
    "#     ax[i].imshow(starsg[i], norm=norm, origin='lower',cmap='viridis')\n",
    "# #blue\n",
    "# fig, ax = subplots(nrows=1, ncols=2, figsize=(10, 10), squeeze=True)\n",
    "# ax = ax.ravel() #return a contiguous flattened array\n",
    "# for i in range(1 * 2):\n",
    "#     norm = simple_norm(starsb[i], 'linear', percent=99.)\n",
    "#     ax[i].imshow(starsb[i], norm=norm, origin='lower',cmap='viridis')\n",
    "\n",
    "#use gridspec to place the subplots where I need them\n",
    "\n",
    "#same thing!  don't need to do this then\n",
    "# fig, ax = subplots(nrows=nrows, ncols=nrows, figsize=(10, 10), squeeze=True)\n",
    "# ax = ax.ravel() #return a contiguous flattened array\n",
    "# for i in range(nrows * ncols):\n",
    "#     norm = simple_norm(stars[i], 'log', percent=99.)\n",
    "#     ax[i].imshow(stars[i], norm=norm, origin='lower', cmap='viridis')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(7):#9):\n",
    "    figure()\n",
    "    norm = simple_norm(starsr[i], 'linear', percent=99.)\n",
    "    imshow(starsr[i], norm=norm, origin='lower',cmap='viridis')\n",
    "    colorbar()\n",
    "    title(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(7):\n",
    "    figure()\n",
    "    norm = simple_norm(starsg[i], 'linear', percent=99.)\n",
    "    imshow(starsg[i], norm=norm, origin='lower',cmap='viridis')\n",
    "    colorbar()\n",
    "    title(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(7):#3):\n",
    "    figure()\n",
    "    norm = simple_norm(starsb[i], 'linear', percent=99.)\n",
    "    imshow(starsb[i], norm=norm, origin='lower',cmap='viridis')\n",
    "    colorbar()\n",
    "    title(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#NOW THIS IS THE FINAL SAMPLE unless we subtract the final PSF and have weird residuals\n",
    "#https://photutils.readthedocs.io/en/stable/epsf.html\n",
    "\n",
    "#build the actual ePSFs from the selected star sample\n",
    "#epsf_r is an EPSFModel object\n",
    "#fitted_stars_r is an \n",
    "\n",
    "#FOR THE DATA IMAGE CUTOUT, 101X101\n",
    "\n",
    "print(\"F814W\")\n",
    "epsf_builder = EPSFBuilder(oversampling=1, recentering_boxsize=5, norm_radius=15, shape=51, maxiters=5, progress_bar=True)\n",
    "epsf_r, fitted_stars_r = epsf_builder(starsr)\n",
    "\n",
    "print(\"F606W\")\n",
    "epsf_builder = EPSFBuilder(oversampling=1, recentering_boxsize=45, norm_radius=45, shape=51, maxiters=5, progress_bar=True)\n",
    "epsf_g, fitted_stars_g = epsf_builder(starsg)\n",
    "\n",
    "print(\"F435W\")\n",
    "epsf_builder = EPSFBuilder(oversampling=1, recentering_boxsize=45, norm_radius=45, shape=51, maxiters=5, progress_bar=True)\n",
    "epsf_b, fitted_stars_b = epsf_builder(starsb)\n",
    "\n",
    "\n",
    "\n",
    "#FOR THE 101X101 PIXEL CUTOUT\n",
    "\n",
    "# print(\"F814W\")\n",
    "# epsf_builder = EPSFBuilder(oversampling=1, recentering_boxsize=50, norm_radius=50, shape=101, maxiters=1, progress_bar=True)\n",
    "# epsf_r, fitted_stars_r = epsf_builder(starsr)\n",
    "\n",
    "# print(\"F606W\")\n",
    "# epsf_builder = EPSFBuilder(oversampling=1, recentering_boxsize=50, norm_radius=50, shape=101, maxiters=1, progress_bar=True)\n",
    "# epsf_g, fitted_stars_g = epsf_builder(starsg)\n",
    "\n",
    "# print(\"F435W\")\n",
    "# epsf_builder = EPSFBuilder(oversampling=1, recentering_boxsize=50, norm_radius=50, shape=101, maxiters=1, progress_bar=True)\n",
    "# epsf_b, fitted_stars_b = epsf_builder(starsb)\n",
    "\n",
    "\n",
    "#FOR THE 51X51 PIXEL CUTOUT\n",
    "\n",
    "# print(\"F814W\")\n",
    "# epsf_builder = EPSFBuilder(oversampling=1, recentering_boxsize=51, norm_radius=51, shape=51, maxiters=2, progress_bar=True)\n",
    "# epsf_r, fitted_stars_r = epsf_builder(starsr)\n",
    "\n",
    "# print(\"F606W\")\n",
    "# epsf_builder = EPSFBuilder(oversampling=1, recentering_boxsize=51, norm_radius=51, shape=51, maxiters=2, progress_bar=True)\n",
    "# epsf_g, fitted_stars_g = epsf_builder(starsg)\n",
    "\n",
    "# print(\"F435W\")\n",
    "# epsf_builder = EPSFBuilder(oversampling=1, recentering_boxsize=51, norm_radius=51, shape=51, maxiters=2, progress_bar=True)\n",
    "# epsf_b, fitted_stars_b = epsf_builder(starsb)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#now plot them all\n",
    "\n",
    "figure(400)\n",
    "normr = simple_norm(epsf_r.data, 'linear', percent=99.)\n",
    "imshow(epsf_r.data, norm=normr, origin='lower', cmap='viridis')#, vmin=0, vmax=0.001)\n",
    "title(\"F814W ePSF\")\n",
    "colorbar()\n",
    "\n",
    "figure(401)\n",
    "normg = simple_norm(epsf_g.data, 'linear', percent=99.)\n",
    "imshow(epsf_g.data, norm=normg, origin='lower', cmap='viridis')#, vmin=0, vmax=0.001)\n",
    "title(\"F606W ePSF\")\n",
    "colorbar()\n",
    "\n",
    "figure(402)\n",
    "normb = simple_norm(epsf_b.data, 'linear', percent=99.)\n",
    "imshow(epsf_b.data, norm=normb, origin='lower', cmap='viridis')#, vmin=0, vmax=0.001)\n",
    "title(\"F435W ePSF\")\n",
    "colorbar()\n",
    "\n",
    "#for these I did not set the \"shape\" variable (it causes an issue) - I can trim them if needed\n",
    "#it seems like it was able to subtract the background as well as other objects in the field\n",
    "#maybe this means I can use more stars??  if it has the ability to effectively ignore things in crowded fields\n",
    "#so that would give me a better eventual empirical PSF\n",
    "\n",
    "#check https://photutils.readthedocs.io/en/stable/api/photutils.psf.EPSFBuilder.html#photutils.psf.EPSFBuilder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #EPSFBuilder outputs an EPSFModel object and an EPSFStars object, the latter of which is comprised of EPSFStar objects\n",
    "\n",
    "# #red\n",
    "# fig, ax = subplots(nrows=9, ncols=4, figsize=(15,30), squeeze=True)\n",
    "# for i in range(9):\n",
    "#     norm = simple_norm(starsr[i], 'linear', percent=99.)\n",
    "#     im0 = ax[i][0].imshow(epsf_r.data, origin='lower', cmap='viridis')\n",
    "#     ax[i][0].set_xticks(numpy.linspace(0,101,5))\n",
    "#     ax[i][0].set_yticks(numpy.linspace(0,101,5))\n",
    "#     ax[i][0].set_title('PSF_814')\n",
    "#     im1 = ax[i][1].imshow(starsr[i], origin='lower',cmap='viridis')\n",
    "#     ax[i][1].set_xticks(numpy.linspace(0,101,5))\n",
    "#     ax[i][1].set_yticks(numpy.linspace(0,101,5))\n",
    "#     ax[i][1].set_title('star'+str(i)+'_814')\n",
    "#     #show the residual image\n",
    "#     test_red_psf_residual = fitted_stars_r.all_stars[i].compute_residual_image(epsf_r) #no difference if use all_good_stars, so must be using all stars\n",
    "#     im2 = ax[i][2].imshow(test_red_psf_residual, origin='lower', cmap='viridis')\n",
    "#     ax[i][2].set_xticks(numpy.linspace(0,101,5))\n",
    "#     ax[i][2].set_yticks(numpy.linspace(0,101,5))\n",
    "#     ax[i][2].set_title('residual'+str(i)+'_814')    \n",
    "#     im3 = ax[i][3].imshow(test_red_psf_residual, origin='lower', cmap='viridis', vmin=0, vmax=50) #scaled\n",
    "#     ax[i][3].set_xticks(numpy.linspace(0,101,5))\n",
    "#     ax[i][3].set_yticks(numpy.linspace(0,101,5))\n",
    "#     ax[i][3].set_title('residual'+str(i)+'_814_scaled')\n",
    "#     colorbar(im0, ax=ax[i,0])\n",
    "#     colorbar(im1, ax=ax[i,1])\n",
    "#     colorbar(im2, ax=ax[i,2])\n",
    "#     colorbar(im3, ax=ax[i,3])\n",
    "\n",
    "# #green\n",
    "# fig, ax = subplots(nrows=7, ncols=4, figsize=(15,25), squeeze=True)\n",
    "# for i in range(7):\n",
    "#     im0 = ax[i][0].imshow(epsf_g.data, origin='lower', cmap='viridis')\n",
    "#     ax[i][0].set_xticks(numpy.linspace(0,101,5))\n",
    "#     ax[i][0].set_yticks(numpy.linspace(0,101,5))\n",
    "#     ax[i][0].set_title('PSF_606')\n",
    "#     im1 = ax[i][1].imshow(starsg[i], origin='lower',cmap='viridis')\n",
    "#     ax[i][1].set_xticks(numpy.linspace(0,101,5))\n",
    "#     ax[i][1].set_yticks(numpy.linspace(0,101,5))\n",
    "#     ax[i][1].set_title('star'+str(i)+'_606')\n",
    "#     #show the residual image\n",
    "#     test_green_psf_residual = fitted_stars_g.all_stars[i].compute_residual_image(epsf_g)\n",
    "#     im2 = ax[i][2].imshow(test_green_psf_residual, origin='lower', cmap='viridis')\n",
    "#     ax[i][2].set_xticks(numpy.linspace(0,101,5))\n",
    "#     ax[i][2].set_yticks(numpy.linspace(0,101,5))\n",
    "#     ax[i][2].set_title('residual'+str(i)+'_606')    \n",
    "#     im3 = ax[i][3].imshow(test_green_psf_residual, origin='lower', cmap='viridis', vmin=0, vmax=50) #scaled\n",
    "#     ax[i][3].set_xticks(numpy.linspace(0,101,5))\n",
    "#     ax[i][3].set_yticks(numpy.linspace(0,101,5))\n",
    "#     ax[i][3].set_title('residual'+str(i)+'_606_scaled')\n",
    "#     colorbar(im0, ax=ax[i,0])\n",
    "#     colorbar(im1, ax=ax[i,1])\n",
    "#     colorbar(im2, ax=ax[i,2])\n",
    "#     colorbar(im3, ax=ax[i,3])\n",
    "\n",
    "# #blue\n",
    "# fig, ax = subplots(nrows=3, ncols=4, figsize=(15,10), squeeze=True)\n",
    "# for i in range(3):\n",
    "#     im0 = ax[i][0].imshow(epsf_b.data, origin='lower', cmap='viridis')\n",
    "#     ax[i][0].set_xticks(numpy.linspace(0,101,5))\n",
    "#     ax[i][0].set_yticks(numpy.linspace(0,101,5))\n",
    "#     ax[i][0].set_title('PSF_435')\n",
    "#     im1 = ax[i][1].imshow(starsb[i], origin='lower',cmap='viridis')\n",
    "#     ax[i][1].set_xticks(numpy.linspace(0,101,5))\n",
    "#     ax[i][1].set_yticks(numpy.linspace(0,101,5))\n",
    "#     ax[i][1].set_title('star'+str(i)+'_435')\n",
    "#     #show the residual image\n",
    "#     test_blue_psf_residual = fitted_stars_b.all_stars[i].compute_residual_image(epsf_b) #no difference if use all_good_stars, so must be using all stars\n",
    "#     im2 = ax[i][2].imshow(test_blue_psf_residual, origin='lower', cmap='viridis')\n",
    "#     ax[i][2].set_xticks(numpy.linspace(0,101,5))\n",
    "#     ax[i][2].set_yticks(numpy.linspace(0,101,5))\n",
    "#     ax[i][2].set_title('residual'+str(i)+'_435')    \n",
    "#     im3 = ax[i][3].imshow(test_blue_psf_residual, origin='lower', cmap='viridis', vmin=0, vmax=50) #scaled\n",
    "#     ax[i][3].set_xticks(numpy.linspace(0,101,5))\n",
    "#     ax[i][3].set_yticks(numpy.linspace(0,101,5))\n",
    "#     ax[i][3].set_title('residual'+str(i)+'_435_scaled')\n",
    "#     colorbar(im0, ax=ax[i,0])\n",
    "#     colorbar(im1, ax=ax[i,1])\n",
    "#     colorbar(im2, ax=ax[i,2])\n",
    "#     colorbar(im3, ax=ax[i,3])\n",
    "\n",
    "# #background is subtracted as an average\n",
    "# #background subtraction also results in some negative or close to 0 negative pixels in these cutouts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#now plot them all\n",
    "\n",
    "figure(400)\n",
    "normr = simple_norm(epsf_r.data, 'linear', percent=99.)\n",
    "imshow(epsf_r.data, origin='lower', cmap='viridis')#, vmin=0, vmax=0.011)\n",
    "colorbar()\n",
    "\n",
    "figure(401)\n",
    "normg = simple_norm(epsf_g.data, 'linear', percent=99.)\n",
    "imshow(epsf_g.data, origin='lower', cmap='viridis')#, vmin=0, vmax=0.011)\n",
    "colorbar()\n",
    "\n",
    "figure(402)\n",
    "normb = simple_norm(epsf_b.data, 'linear', percent=99.)\n",
    "imshow(epsf_b.data, origin='lower', cmap='viridis')#, vmin=0, vmax=0.011)\n",
    "colorbar()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GALAXY CONVOLUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Prof says: You could test this by taking some galaxy model and convolving with your model PSF as well as with the various stars\n",
    "#Comparing the different convolved images would let you quantify how much difference you get from using different PSFs\n",
    "\n",
    "#Prof Jha says: subtract PSF from each individual star and check residuals\n",
    "#is fine because not using it to subtract stars, using it to subtract elliptical cluster member galaxies\n",
    "\n",
    "#TEST 1: above two cells\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TEST 2: make test Sersic galaxy; convolve it with PSF for each filter; convolve it with each star in each filter; compare residuals\n",
    "\n",
    "#https://docs.astropy.org/en/stable/api/astropy.convolution.convolve.html#astropy.convolution.convolve\n",
    "\n",
    "# #create grid for the model galaxy\n",
    "# ny,nx = 800,800\n",
    "# y,x = numpy.mgrid[0:ny,0:nx]\n",
    "# elliptical_galaxy = Sersic2D(amplitude=1, r_eff=200, n=4, x_0=400, y_0=400, ellip=0.5, theta=0.5)\n",
    "# image = elliptical_galaxy(x,y)\n",
    "# figure()\n",
    "# imshow(image, cmap='inferno', origin='lower', norm=simple_norm(image,stretch='log',log_a=10000))\n",
    "\n",
    "# #convolution of galaxy with psf\n",
    "# ell_conv_red_psf = convolve(image,epsf_r.data)\n",
    "# figure()\n",
    "# imshow(ell_conv_red_psf, cmap='inferno', origin='lower', norm=simple_norm(image, stretch='log', log_a=10000))\n",
    "# figure()\n",
    "# ell_conv_green_psf = convolve(image,epsf_g.data)\n",
    "# imshow(ell_conv_green_psf, cmap='inferno', origin='lower', norm=simple_norm(image, stretch='log', log_a=10000))\n",
    "# figure()\n",
    "# ell_conv_blue_psf = convolve(image,epsf_b.data)\n",
    "# imshow(ell_conv_blue_psf, cmap='inferno', origin='lower', norm=simple_norm(image, stretch='log', log_a=10000))\n",
    "# title(\"Test Elliptical Convolved with F435W PSF\")\n",
    "# figure()\n",
    "# imshow(ell_conv_red_psf-image, cmap='inferno', origin='lower', norm=simple_norm(image, stretch='log', log_a=10000))\n",
    "\n",
    "# #test\n",
    "# figure()\n",
    "# ell_conv_star = convolve(image,starsr[0].data)\n",
    "# imshow(ell_conv_star, cmap='inferno', origin='lower', norm=simple_norm(image, stretch='log', log_a=10000))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Point PSF Test\n",
    "\n",
    "#check how one point gets convolved with the PSF\n",
    "\n",
    "#create grid for the model galaxy\n",
    "ny,nx = 800,800\n",
    "y,x = numpy.mgrid[0:ny,0:nx]\n",
    "elliptical_galaxy = Sersic2D(amplitude=1, r_eff=200, n=4, x_0=400, y_0=400, ellip=0.5, theta=0.5)\n",
    "image = elliptical_galaxy(x,y) + 0. - elliptical_galaxy(x,y)\n",
    "image[400][400] = 1.\n",
    "#print(type(image))\n",
    "\n",
    "ny,nx = 101,101\n",
    "y,x = numpy.mgrid[0:ny,0:nx]\n",
    "elliptical_galaxy = Sersic2D(amplitude=1, r_eff=200, n=4, x_0=400, y_0=400, ellip=0.5, theta=0.5)\n",
    "red_point_faux_psf = elliptical_galaxy(x,y) + 0. - elliptical_galaxy(x,y)\n",
    "red_point_faux_psf[51][51] = 1.\n",
    "\n",
    "figure()\n",
    "imshow(image, norm=normr, cmap='viridis', origin='lower')\n",
    "title(\"One Point\")\n",
    "xlim(350,450)\n",
    "ylim(350,450)\n",
    "colorbar()\n",
    "\n",
    "figure()\n",
    "ell_conv_star = convolve(image,epsf_r.data)\n",
    "imshow(ell_conv_star, norm=normr, cmap='viridis', origin='lower')\n",
    "title(\"Point Convolved with F814W ePSF\")\n",
    "xlim(350,450)\n",
    "ylim(350,450)\n",
    "colorbar()\n",
    "\n",
    "figure()\n",
    "imshow(epsf_r.data, norm=normr, origin='lower', cmap='viridis')\n",
    "title(\"F814W ePSF\")\n",
    "colorbar()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #present all info on psfs, star cutouts, and elliptical galaxy convolutions\n",
    "\n",
    "# #grid for model galaxy\n",
    "# # ny,nx = 200,200\n",
    "# # y,x = numpy.mgrid[0:ny,0:nx]\n",
    "# # elliptical_galaxy = Sersic2D(amplitude=1, r_eff=50, n=4, x_0=100, y_0=100, ellip=0.5, theta=0.5)\n",
    "# # image = elliptical_galaxy(x,y)\n",
    "# # figure()\n",
    "# # imshow(image, cmap='inferno', origin='lower', norm=simple_norm(image,stretch='log',log_a=10000))\n",
    "\n",
    "# #EPSFBuilder outputs an EPSFModel object and an EPSFStars object, the latter of which is comprised of EPSFStar objects\n",
    "\n",
    "# #red\n",
    "# fig, ax = subplots(nrows=9, ncols=10, figsize=(35,30), squeeze=True)\n",
    "# for i in range(9):\n",
    "#     norm = simple_norm(starsr[i], 'linear', percent=99.)\n",
    "#     im0 = ax[i][0].imshow(epsf_r.data, origin='lower', cmap='viridis')\n",
    "#     ax[i][0].set_xticks(numpy.linspace(0,101,5))\n",
    "#     ax[i][0].set_yticks(numpy.linspace(0,101,5))\n",
    "#     ax[i][0].set_title('PSF_814')\n",
    "#     im1 = ax[i][1].imshow(starsr[i], origin='lower',cmap='viridis')\n",
    "#     ax[i][1].set_xticks(numpy.linspace(0,101,5))\n",
    "#     ax[i][1].set_yticks(numpy.linspace(0,101,5))\n",
    "#     ax[i][1].set_title('star'+str(i)+'_814')\n",
    "#     #show the residual image\n",
    "#     test_red_psf_residual = fitted_stars_r.all_stars[i].compute_residual_image(epsf_r) #no difference if use all_good_stars, so must be using all stars\n",
    "#     im2 = ax[i][2].imshow(test_red_psf_residual, origin='lower', cmap='viridis')\n",
    "#     ax[i][2].set_xticks(numpy.linspace(0,101,5))\n",
    "#     ax[i][2].set_yticks(numpy.linspace(0,101,5))\n",
    "#     ax[i][2].set_title('residual'+str(i)+'_814')    \n",
    "#     im3 = ax[i][3].imshow(test_red_psf_residual, origin='lower', cmap='viridis', vmin=0, vmax=50) #scaled\n",
    "#     ax[i][3].set_xticks(numpy.linspace(0,101,5))\n",
    "#     ax[i][3].set_yticks(numpy.linspace(0,101,5))\n",
    "#     ax[i][3].set_title('residual'+str(i)+'_814_scaled')\n",
    "#     #test galaxy\n",
    "#     im4 = ax[i][4].imshow(image, cmap='inferno', origin='lower', norm=simple_norm(image,stretch='log',log_a=10000))\n",
    "#     ax[i][4].set_title('Ell_Sersic_n4')\n",
    "#     #convolve galaxy with psf\n",
    "#     ell_conv_red_psf = convolve(image,epsf_r.data)\n",
    "#     im5 = ax[i][5].imshow(ell_conv_red_psf, cmap='inferno', origin='lower', norm=simple_norm(image, stretch='log', log_a=10000))\n",
    "#     ax[i][5].set_title('Convolved w/PSF 814')    \n",
    "#     #convolved with PSF - plain sersic\n",
    "#     im6 = ax[i][6].imshow(ell_conv_red_psf-image, cmap='inferno', origin='lower', norm=simple_norm(image, stretch='log', log_a=10000))\n",
    "#     ax[i][6].set_title('Conv.PSF - Ell_Ser')    \n",
    "#     #convolve galaxy with stars\n",
    "#     conv_red_star = convolve(image,starsr[i].data)\n",
    "#     im7 = ax[i][7].imshow(conv_red_star, cmap='inferno', origin='lower', norm=simple_norm(image, stretch='log', log_a=10000))\n",
    "#     ax[i][7].set_title('Convolved w/star'+str(i)+'814')    \n",
    "#     #convolved with star - plain sersic\n",
    "#     im8 = ax[i][8].imshow(conv_red_star-image, cmap='inferno', origin='lower', norm=simple_norm(image, stretch='log', log_a=10000))\n",
    "#     ax[i][8].set_title('Conv.star'+str(i)+' - Ell_Ser')   \n",
    "#     #residuals of convolution with psf vs star\n",
    "#     im9 = ax[i][9].imshow(conv_red_star-ell_conv_red_psf, cmap='inferno', origin='lower', norm=simple_norm(image, stretch='log', log_a=10000))\n",
    "#     ax[i][9].set_title('Conv.star'+str(i)+'-Conv.PSF')\n",
    "#     colorbar(im0, ax=ax[i,0])\n",
    "#     colorbar(im1, ax=ax[i,1])\n",
    "#     colorbar(im2, ax=ax[i,2])\n",
    "#     colorbar(im3, ax=ax[i,3])\n",
    "#     colorbar(im4, ax=ax[i,4])\n",
    "#     colorbar(im5, ax=ax[i,5])\n",
    "#     colorbar(im6, ax=ax[i,6])\n",
    "#     colorbar(im7, ax=ax[i,7])    \n",
    "#     colorbar(im8, ax=ax[i,8])\n",
    "#     colorbar(im9, ax=ax[i,9])\n",
    "    \n",
    "\n",
    "# #green\n",
    "# fig, ax = subplots(nrows=7, ncols=10, figsize=(35,25), squeeze=True)\n",
    "# for i in range(7):\n",
    "#     im0 = ax[i][0].imshow(epsf_g.data, origin='lower', cmap='viridis')\n",
    "#     ax[i][0].set_xticks(numpy.linspace(0,101,5))\n",
    "#     ax[i][0].set_yticks(numpy.linspace(0,101,5))\n",
    "#     ax[i][0].set_title('PSF_606')\n",
    "#     im1 = ax[i][1].imshow(starsg[i], origin='lower',cmap='viridis')\n",
    "#     ax[i][1].set_xticks(numpy.linspace(0,101,5))\n",
    "#     ax[i][1].set_yticks(numpy.linspace(0,101,5))\n",
    "#     ax[i][1].set_title('star'+str(i)+'_606')\n",
    "#     #show the residual image\n",
    "#     test_green_psf_residual = fitted_stars_g.all_stars[i].compute_residual_image(epsf_g)\n",
    "#     im2 = ax[i][2].imshow(test_green_psf_residual, origin='lower', cmap='viridis')\n",
    "#     ax[i][2].set_xticks(numpy.linspace(0,101,5))\n",
    "#     ax[i][2].set_yticks(numpy.linspace(0,101,5))\n",
    "#     ax[i][2].set_title('residual'+str(i)+'_606')    \n",
    "#     im3 = ax[i][3].imshow(test_green_psf_residual, origin='lower', cmap='viridis', vmin=0, vmax=50) #scaled\n",
    "#     ax[i][3].set_xticks(numpy.linspace(0,101,5))\n",
    "#     ax[i][3].set_yticks(numpy.linspace(0,101,5))\n",
    "#     ax[i][3].set_title('residual'+str(i)+'_606_scaled')\n",
    "#     #test galaxy\n",
    "#     im4 = ax[i][4].imshow(image, cmap='inferno', origin='lower', norm=simple_norm(image,stretch='log',log_a=10000))\n",
    "#     ax[i][4].set_title('Ell_Sersic_n4')\n",
    "#     #convolve galaxy with psf\n",
    "#     ell_conv_green_psf = convolve(image,epsf_g.data)\n",
    "#     im5 = ax[i][5].imshow(ell_conv_green_psf, cmap='inferno', origin='lower', norm=simple_norm(image, stretch='log', log_a=10000))\n",
    "#     ax[i][5].set_title('Convolved w/PSF 606')    \n",
    "#     #convolved with PSF - plain sersic\n",
    "#     im6 = ax[i][6].imshow(ell_conv_green_psf-image, cmap='inferno', origin='lower', norm=simple_norm(image, stretch='log', log_a=10000))\n",
    "#     ax[i][6].set_title('Conv.PSF - Ell_Ser')    \n",
    "#     #convolve galaxy with stars\n",
    "#     conv_green_star = convolve(image,starsg[i].data)\n",
    "#     im7 = ax[i][7].imshow(conv_green_star, cmap='inferno', origin='lower', norm=simple_norm(image, stretch='log', log_a=10000))\n",
    "#     ax[i][7].set_title('Convolved w/star'+str(i)+'606')    \n",
    "#     #convolved with star - plain sersic\n",
    "#     im8 = ax[i][8].imshow(conv_green_star-image, cmap='inferno', origin='lower', norm=simple_norm(image, stretch='log', log_a=10000))\n",
    "#     ax[i][8].set_title('Conv.star'+str(i)+' - Ell_Ser')   \n",
    "#     #residuals of convolution with psf vs star\n",
    "#     im9 = ax[i][9].imshow(conv_green_star-ell_conv_green_psf, cmap='inferno', origin='lower', norm=simple_norm(image, stretch='log', log_a=10000))\n",
    "#     ax[i][9].set_title('Conv.star'+str(i)+'-Conv.PSF')\n",
    "#     colorbar(im0, ax=ax[i,0])\n",
    "#     colorbar(im1, ax=ax[i,1])\n",
    "#     colorbar(im2, ax=ax[i,2])\n",
    "#     colorbar(im3, ax=ax[i,3])\n",
    "#     colorbar(im4, ax=ax[i,4])\n",
    "#     colorbar(im5, ax=ax[i,5])\n",
    "#     colorbar(im6, ax=ax[i,6])\n",
    "#     colorbar(im7, ax=ax[i,7])    \n",
    "#     colorbar(im8, ax=ax[i,8])\n",
    "#     colorbar(im9, ax=ax[i,9])\n",
    "\n",
    "# #blue\n",
    "# fig, ax = subplots(nrows=3, ncols=10, figsize=(35,10), squeeze=True)\n",
    "# for i in range(3):\n",
    "#     im0 = ax[i][0].imshow(epsf_b.data, origin='lower', cmap='viridis')\n",
    "#     ax[i][0].set_xticks(numpy.linspace(0,101,5))\n",
    "#     ax[i][0].set_yticks(numpy.linspace(0,101,5))\n",
    "#     ax[i][0].set_title('PSF_435')\n",
    "#     im1 = ax[i][1].imshow(starsb[i], origin='lower',cmap='viridis')\n",
    "#     ax[i][1].set_xticks(numpy.linspace(0,101,5))\n",
    "#     ax[i][1].set_yticks(numpy.linspace(0,101,5))\n",
    "#     ax[i][1].set_title('star'+str(i)+'_435')\n",
    "#     #show the residual image\n",
    "#     test_blue_psf_residual = fitted_stars_b.all_stars[i].compute_residual_image(epsf_b) #no difference if use all_good_stars, so must be using all stars\n",
    "#     im2 = ax[i][2].imshow(test_blue_psf_residual, origin='lower', cmap='viridis')\n",
    "#     ax[i][2].set_xticks(numpy.linspace(0,101,5))\n",
    "#     ax[i][2].set_yticks(numpy.linspace(0,101,5))\n",
    "#     ax[i][2].set_title('residual'+str(i)+'_435')    \n",
    "#     im3 = ax[i][3].imshow(test_blue_psf_residual, origin='lower', cmap='viridis', vmin=0, vmax=50) #scaled\n",
    "#     ax[i][3].set_xticks(numpy.linspace(0,101,5))\n",
    "#     ax[i][3].set_yticks(numpy.linspace(0,101,5))\n",
    "#     ax[i][3].set_title('residual'+str(i)+'_435_scaled')\n",
    "#     #test galaxy\n",
    "#     im4 = ax[i][4].imshow(image, cmap='inferno', origin='lower', norm=simple_norm(image,stretch='log',log_a=10000))\n",
    "#     ax[i][4].set_title('Ell_Sersic_n4')\n",
    "#     #convolve galaxy with psf\n",
    "#     ell_conv_blue_psf = convolve(image,epsf_b.data)\n",
    "#     im5 = ax[i][5].imshow(ell_conv_blue_psf, cmap='inferno', origin='lower', norm=simple_norm(image, stretch='log', log_a=10000))\n",
    "#     ax[i][5].set_title('Convolved w/PSF 435')    \n",
    "#     #convolved with PSF - plain sersic\n",
    "#     im6 = ax[i][6].imshow(ell_conv_blue_psf-image, cmap='inferno', origin='lower', norm=simple_norm(image, stretch='log', log_a=10000))\n",
    "#     ax[i][6].set_title('Conv.PSF - Ell_Ser')    \n",
    "#     #convolve galaxy with stars\n",
    "#     conv_blue_star = convolve(image,starsb[i].data)\n",
    "#     im7 = ax[i][7].imshow(conv_blue_star, cmap='inferno', origin='lower', norm=simple_norm(image, stretch='log', log_a=10000))\n",
    "#     ax[i][7].set_title('Convolved w/star'+str(i)+'435')    \n",
    "#     #convolved with star - plain sersic\n",
    "#     im8 = ax[i][8].imshow(conv_blue_star-image, cmap='inferno', origin='lower', norm=simple_norm(image, stretch='log', log_a=10000))\n",
    "#     ax[i][8].set_title('Conv.star'+str(i)+' - Ell_Ser')   \n",
    "#     #residuals of convolution with psf vs star\n",
    "#     im9 = ax[i][9].imshow(conv_blue_star-ell_conv_blue_psf, cmap='inferno', origin='lower', norm=simple_norm(image, stretch='log', log_a=10000))\n",
    "#     ax[i][9].set_title('Conv.star'+str(i)+'-Conv.PSF')\n",
    "#     colorbar(im0, ax=ax[i,0])\n",
    "#     colorbar(im1, ax=ax[i,1])\n",
    "#     colorbar(im2, ax=ax[i,2])\n",
    "#     colorbar(im3, ax=ax[i,3])\n",
    "#     colorbar(im4, ax=ax[i,4])\n",
    "#     colorbar(im5, ax=ax[i,5])\n",
    "#     colorbar(im6, ax=ax[i,6])\n",
    "#     colorbar(im7, ax=ax[i,7])    \n",
    "#     colorbar(im8, ax=ax[i,8])\n",
    "#     colorbar(im9, ax=ax[i,9])\n",
    "\n",
    "\n",
    "# #background is subtracted as an average\n",
    "# #background subtraction also results in some negative or close to 0 negative pixels in these cutouts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #consolidated/useful plots\n",
    "# #present all info on psfs, star cutouts, and elliptical galaxy convolutions\n",
    "\n",
    "# #EPSFBuilder outputs an EPSFModel object and an EPSFStars object, the latter of which is comprised of EPSFStar objects\n",
    "\n",
    "# #create grid for the model galaxy\n",
    "# ny,nx = 400,400\n",
    "# y,x = numpy.mgrid[0:ny,0:nx]\n",
    "# elliptical_galaxy = Sersic2D(amplitude=1, r_eff=100, n=4, x_0=200, y_0=200, ellip=0.5, theta=0.5)\n",
    "# image = elliptical_galaxy(x,y)\n",
    "# figure()\n",
    "# imshow(image, cmap='inferno', origin='lower', norm=simple_norm(image,stretch='log',log_a=10000))\n",
    "\n",
    "# #red\n",
    "# fig, ax = subplots(nrows=9, ncols=8, figsize=(35,30), squeeze=True)\n",
    "# for i in range(9):\n",
    "#     #final PSF - is same for all rows\n",
    "#     norm = simple_norm(starsr[i], 'linear', percent=99.)\n",
    "#     im0 = ax[i][0].imshow(epsf_r.data, origin='lower', cmap='viridis')\n",
    "#     ax[i][0].set_xticks(numpy.linspace(0,101,5))\n",
    "#     ax[i][0].set_yticks(numpy.linspace(0,101,5))\n",
    "#     ax[i][0].set_title('PSF_814')\n",
    "#     #show star labeled i\n",
    "#     im1 = ax[i][1].imshow(starsr[i], origin='lower',cmap='viridis')\n",
    "#     ax[i][1].set_xticks(numpy.linspace(0,101,5))\n",
    "#     ax[i][1].set_yticks(numpy.linspace(0,101,5))\n",
    "#     ax[i][1].set_title('star'+str(i)+'_814')\n",
    "#     #show residual on same scale as star\n",
    "#     test_red_psf_residual = fitted_stars_r.all_stars[i].compute_residual_image(epsf_r) #no difference if use all_good_stars, so must be using all stars\n",
    "#     im2 = ax[i][2].imshow(test_red_psf_residual, origin='lower', cmap='viridis', vmin=numpy.min(starsr[i]), vmax=numpy.max(starsr[i])) #scaled\n",
    "#     ax[i][2].set_xticks(numpy.linspace(0,101,5))\n",
    "#     ax[i][2].set_yticks(numpy.linspace(0,101,5))\n",
    "#     ax[i][2].set_title('residual'+str(i)+'_814 orig_scale')\n",
    "#     #show the residual image\n",
    "#     im3 = ax[i][3].imshow(test_red_psf_residual, origin='lower', cmap='PiYG', vmin=-100, vmax=100)\n",
    "#     ax[i][3].set_xticks(numpy.linspace(0,101,5))\n",
    "#     ax[i][3].set_yticks(numpy.linspace(0,101,5))\n",
    "#     ax[i][3].set_title('residual'+str(i)+'_814')    \n",
    "#     #test galaxy\n",
    "#     im4 = ax[i][4].imshow(image, cmap='inferno', origin='lower', norm=simple_norm(image,stretch='log',log_a=10000))\n",
    "#     ax[i][4].set_title('Ell_Sersic_n4')\n",
    "#     #convolve galaxy with psf\n",
    "#     ell_conv_red_psf = convolve(image,epsf_r.data)\n",
    "#     im5 = ax[i][5].imshow(ell_conv_red_psf, cmap='inferno', origin='lower', norm=simple_norm(image, stretch='log', log_a=10000))\n",
    "#     ax[i][5].set_title('Convolved w/PSF 814')    \n",
    "#     # #convolved with PSF - plain sersic\n",
    "#     # im6 = ax[i][6].imshow(ell_conv_red_psf-image, cmap='inferno', origin='lower', norm=simple_norm(image, stretch='log', log_a=10000))\n",
    "#     # ax[i][6].set_title('Conv.PSF - Ell_Ser')    \n",
    "#     #convolve galaxy with stars\n",
    "#     conv_red_star = convolve(image,starsr[i].data)\n",
    "#     im6 = ax[i][6].imshow(conv_red_star, cmap='inferno', origin='lower', norm=simple_norm(image, stretch='log', log_a=10000))\n",
    "#     ax[i][6].set_title('Convolved w/star'+str(i)+'814')    \n",
    "#     # #convolved with star - plain sersic\n",
    "#     # im6 = ax[i][8].imshow(conv_red_star-image, cmap='inferno', origin='lower', norm=simple_norm(image, stretch='log', log_a=10000))\n",
    "#     # ax[i][8].set_title('Conv.star'+str(i)+' - Ell_Ser')   \n",
    "#     #residuals of convolution with psf vs star\n",
    "#     im7 = ax[i][7].imshow(conv_red_star-ell_conv_red_psf, cmap='PiYG', origin='lower', vmin=-2, vmax=2)\n",
    "#     ax[i][7].set_title('Conv.star'+str(i)+'-Conv.PSF')\n",
    "#     colorbar(im0, ax=ax[i,0])\n",
    "#     colorbar(im1, ax=ax[i,1])\n",
    "#     colorbar(im2, ax=ax[i,2])\n",
    "#     colorbar(im3, ax=ax[i,3])\n",
    "#     colorbar(im4, ax=ax[i,4])\n",
    "#     colorbar(im5, ax=ax[i,5])\n",
    "#     colorbar(im6, ax=ax[i,6])\n",
    "#     colorbar(im7, ax=ax[i,7])    \n",
    "    \n",
    "\n",
    "# #green\n",
    "# fig, ax = subplots(nrows=7, ncols=8, figsize=(35,25), squeeze=True)\n",
    "# for i in range(7):\n",
    "#     #final PSF - is same for all rows\n",
    "#     norm = simple_norm(starsg[i], 'linear', percent=99.)\n",
    "#     im0 = ax[i][0].imshow(epsf_g.data, origin='lower', cmap='viridis')\n",
    "#     ax[i][0].set_xticks(numpy.linspace(0,101,5))\n",
    "#     ax[i][0].set_yticks(numpy.linspace(0,101,5))\n",
    "#     ax[i][0].set_title('PSF_606')\n",
    "#     #show star labeled i\n",
    "#     im1 = ax[i][1].imshow(starsg[i], origin='lower',cmap='viridis')\n",
    "#     ax[i][1].set_xticks(numpy.linspace(0,101,5))\n",
    "#     ax[i][1].set_yticks(numpy.linspace(0,101,5))\n",
    "#     ax[i][1].set_title('star'+str(i)+'_606')\n",
    "#     #show residual on same scale as star\n",
    "#     test_green_psf_residual = fitted_stars_g.all_stars[i].compute_residual_image(epsf_g) #no difference if use all_good_stars, so must be using all stars\n",
    "#     im2 = ax[i][2].imshow(test_green_psf_residual, origin='lower', cmap='viridis', vmin=numpy.min(starsg[i]), vmax=numpy.max(starsg[i])) #scaled\n",
    "#     ax[i][2].set_xticks(numpy.linspace(0,101,5))\n",
    "#     ax[i][2].set_yticks(numpy.linspace(0,101,5))\n",
    "#     ax[i][2].set_title('residual'+str(i)+'_606 orig_scale')\n",
    "#     #show the residual image\n",
    "#     im3 = ax[i][3].imshow(test_green_psf_residual, origin='lower', cmap='PiYG', vmin=-100, vmax=100)\n",
    "#     ax[i][3].set_xticks(numpy.linspace(0,101,5))\n",
    "#     ax[i][3].set_yticks(numpy.linspace(0,101,5))\n",
    "#     ax[i][3].set_title('residual'+str(i)+'_606')    \n",
    "#     #test galaxy\n",
    "#     im4 = ax[i][4].imshow(image, cmap='inferno', origin='lower', norm=simple_norm(image,stretch='log',log_a=10000))\n",
    "#     ax[i][4].set_title('Ell_Sersic_n4')\n",
    "#     #convolve galaxy with psf\n",
    "#     ell_conv_green_psf = convolve(image,epsf_g.data)\n",
    "#     im5 = ax[i][5].imshow(ell_conv_green_psf, cmap='inferno', origin='lower', norm=simple_norm(image, stretch='log', log_a=10000))\n",
    "#     ax[i][5].set_title('Convolved w/PSF 606')    \n",
    "#     # #convolved with PSF - plain sersic\n",
    "#     # im6 = ax[i][6].imshow(ell_conv_green_psf-image, cmap='inferno', origin='lower', norm=simple_norm(image, stretch='log', log_a=10000))\n",
    "#     # ax[i][6].set_title('Conv.PSF - Ell_Ser')    \n",
    "#     #convolve galaxy with stars\n",
    "#     conv_green_star = convolve(image,starsg[i].data)\n",
    "#     im6 = ax[i][6].imshow(conv_green_star, cmap='inferno', origin='lower', norm=simple_norm(image, stretch='log', log_a=10000))\n",
    "#     ax[i][6].set_title('Convolved w/star'+str(i)+'606')    \n",
    "#     # #convolved with star - plain sersic\n",
    "#     # im6 = ax[i][8].imshow(conv_green_star-image, cmap='inferno', origin='lower', norm=simple_norm(image, stretch='log', log_a=10000))\n",
    "#     # ax[i][8].set_title('Conv.star'+str(i)+' - Ell_Ser')   \n",
    "#     #residuals of convolution with psf vs star\n",
    "#     im7 = ax[i][7].imshow(conv_green_star-ell_conv_green_psf, cmap='PiYG', origin='lower', vmin=-2, vmax=2)\n",
    "#     ax[i][7].set_title('Conv.star'+str(i)+'-Conv.PSF')\n",
    "#     colorbar(im0, ax=ax[i,0])\n",
    "#     colorbar(im1, ax=ax[i,1])\n",
    "#     colorbar(im2, ax=ax[i,2])\n",
    "#     colorbar(im3, ax=ax[i,3])\n",
    "#     colorbar(im4, ax=ax[i,4])\n",
    "#     colorbar(im5, ax=ax[i,5])\n",
    "#     colorbar(im6, ax=ax[i,6])\n",
    "#     colorbar(im7, ax=ax[i,7])    \n",
    "\n",
    "\n",
    "# #blue\n",
    "# fig, ax = subplots(nrows=3, ncols=8, figsize=(35,10), squeeze=True)\n",
    "# for i in range(3):\n",
    "#     #final PSF - is same for all rows\n",
    "#     norm = simple_norm(starsb[i], 'linear', percent=99.)\n",
    "#     im0 = ax[i][0].imshow(epsf_b.data, origin='lower', cmap='viridis')\n",
    "#     ax[i][0].set_xticks(numpy.linspace(0,101,5))\n",
    "#     ax[i][0].set_yticks(numpy.linspace(0,101,5))\n",
    "#     ax[i][0].set_title('PSF_435')\n",
    "#     #show star labeled i\n",
    "#     im1 = ax[i][1].imshow(starsb[i], origin='lower',cmap='viridis')\n",
    "#     ax[i][1].set_xticks(numpy.linspace(0,101,5))\n",
    "#     ax[i][1].set_yticks(numpy.linspace(0,101,5))\n",
    "#     ax[i][1].set_title('star'+str(i)+'_435')\n",
    "#     #show residual on same scale as star\n",
    "#     test_blue_psf_residual = fitted_stars_b.all_stars[i].compute_residual_image(epsf_b) #no difference if use all_good_stars, so must be using all stars\n",
    "#     im2 = ax[i][2].imshow(test_blue_psf_residual, origin='lower', cmap='viridis', vmin=numpy.min(starsb[i]), vmax=numpy.max(starsb[i])) #scaled\n",
    "#     ax[i][2].set_xticks(numpy.linspace(0,101,5))\n",
    "#     ax[i][2].set_yticks(numpy.linspace(0,101,5))\n",
    "#     ax[i][2].set_title('residual'+str(i)+'_435 orig_scale')\n",
    "#     #show the residual image\n",
    "#     im3 = ax[i][3].imshow(test_blue_psf_residual, origin='lower', cmap='PiYG', vmin=-100, vmax=100)\n",
    "#     ax[i][3].set_xticks(numpy.linspace(0,101,5))\n",
    "#     ax[i][3].set_yticks(numpy.linspace(0,101,5))\n",
    "#     ax[i][3].set_title('residual'+str(i)+'_435')    \n",
    "#     #test galaxy\n",
    "#     im4 = ax[i][4].imshow(image, cmap='inferno', origin='lower', norm=simple_norm(image,stretch='log',log_a=10000))\n",
    "#     ax[i][4].set_title('Ell_Sersic_n4')\n",
    "#     #convolve galaxy with psf\n",
    "#     ell_conv_blue_psf = convolve(image,epsf_b.data)\n",
    "#     im5 = ax[i][5].imshow(ell_conv_blue_psf, cmap='inferno', origin='lower', norm=simple_norm(image, stretch='log', log_a=10000))\n",
    "#     ax[i][5].set_title('Convolved w/PSF 435')    \n",
    "#     # #convolved with PSF - plain sersic\n",
    "#     # im6 = ax[i][6].imshow(ell_conv_blue_psf-image, cmap='inferno', origin='lower', norm=simple_norm(image, stretch='log', log_a=10000))\n",
    "#     # ax[i][6].set_title('Conv.PSF - Ell_Ser')    \n",
    "#     #convolve galaxy with stars\n",
    "#     conv_blue_star = convolve(image,starsb[i].data)\n",
    "#     im6 = ax[i][6].imshow(conv_blue_star, cmap='inferno', origin='lower', norm=simple_norm(image, stretch='log', log_a=10000))\n",
    "#     ax[i][6].set_title('Convolved w/star'+str(i)+'435')    \n",
    "#     # #convolved with star - plain sersic\n",
    "#     # im6 = ax[i][8].imshow(conv_blue_star-image, cmap='inferno', origin='lower', norm=simple_norm(image, stretch='log', log_a=10000))\n",
    "#     # ax[i][8].set_title('Conv.star'+str(i)+' - Ell_Ser')   \n",
    "#     #residuals of convolution with psf vs star\n",
    "#     im7 = ax[i][7].imshow(conv_blue_star-ell_conv_blue_psf, cmap='PiYG', origin='lower', vmin=-2, vmax=2)\n",
    "#     ax[i][7].set_title('Conv.star'+str(i)+'-Conv.PSF')\n",
    "#     colorbar(im0, ax=ax[i,0])\n",
    "#     colorbar(im1, ax=ax[i,1])\n",
    "#     colorbar(im2, ax=ax[i,2])\n",
    "#     colorbar(im3, ax=ax[i,3])\n",
    "#     colorbar(im4, ax=ax[i,4])\n",
    "#     colorbar(im5, ax=ax[i,5])\n",
    "#     colorbar(im6, ax=ax[i,6])\n",
    "#     colorbar(im7, ax=ax[i,7])    \n",
    "\n",
    "\n",
    "# #background is subtracted as an average\n",
    "# #background subtraction also results in some negative or close to 0 negative pixels in these cutouts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#now that we have the 3 PSFs for each filter, we need to turn each PSF into a FITS file\n",
    "#https://docs.astropy.org/en/stable/io/fits/index.html\n",
    "\n",
    "#create a numpy object for the data\n",
    "#epsf_r.data?\n",
    "\n",
    "#create a PrimaryHDU object to encapsulate the data:\n",
    "hdu_r = fits.PrimaryHDU(epsf_r.data)\n",
    "hdu_g = fits.PrimaryHDU(epsf_g.data)\n",
    "hdu_b = fits.PrimaryHDU(epsf_b.data)\n",
    "#hdu_faux = fits.PrimaryHDU(red_point_faux_psf)\n",
    "\n",
    "#then create an HDUList to contain the newly created primary HDU and write to a new file:\n",
    "#hdul_r = fits.HDUList([hdu_r])\n",
    "#hdul_r.writeto('/mnt/c/Users/lana-/Desktop/PSF_814.fits')\n",
    "\n",
    "#or just do this\n",
    "hdu_r.writeto('/mnt/c/Users/lana-/Desktop/PSF_814.fits',overwrite=True)\n",
    "hdu_g.writeto('/mnt/c/Users/lana-/Desktop/PSF_606.fits',overwrite=True)\n",
    "hdu_b.writeto('/mnt/c/Users/lana-/Desktop/PSF_435.fits',overwrite=True)\n",
    "#hdu_faux.writeto('/mnt/c/Users/lana-/Desktop/PSF_faux.fits',overwrite=True)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convolve Model with PSF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #need to read in lensedmpsnobo file (model without PSF convolution)\n",
    "# no_conv = fits.open('/mnt/c/Users/lana-/Desktop/arc0_814_skip/pixsrc_out/arc0_814_arc_source_814_0_lensedmpsnobo.fits')[0]\n",
    "# pix_conv = fits.open('/mnt/c/Users/lana-/Desktop/arc0_814_skip/pixsrc_out/arc0_814_arc_source_814_0_lensedmps.fits')[0]\n",
    "\n",
    "# #then need to convolve it with the PSF to see if recover the model with PSF convolution (lensedmps)\n",
    "# conv = convolve(no_conv.data,epsf_r.data)\n",
    "# hdu_conv = fits.PrimaryHDU(conv)\n",
    "# hdu_conv.writeto('/mnt/c/Users/lana-/Desktop/conv.fits',overwrite=True)\n",
    "\n",
    "# figure(85)\n",
    "# imshow(no_conv.data,origin=\"lower\",vmin=0,vmax=150)\n",
    "# title(\"Not Convolved\")\n",
    "# figure(86)\n",
    "# imshow(conv,origin=\"lower\",vmin=0,vmax=150)\n",
    "# title(\"I Convolved\")\n",
    "# figure(87)\n",
    "# imshow(pix_conv.data,origin=\"lower\",vmin=0,vmax=150)\n",
    "# title(\"PixSrc Convolved\")\n",
    "# #ideally, can do this with the highest resolution (lots of grid points) run, which is still running\n",
    "# #this is a test to check if the convolution in pixsrc is doing what I think it does\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BELOW HERE STARTS THE ARC STUFF WITH GALAXY MASKING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# abell370_color = fits.open('abell370_RGB.fits')\n",
    "\n",
    "# # abell370_color.info()\n",
    "# abell370_color.close()\n",
    "# # Read in RGB file\n",
    "# RGBfile = 'abell370_RGB.fits'\n",
    "# RGB = fits.open(RGBfile)\n",
    "# wcs_rgb = WCS(RGBfile)\n",
    "# # Put separate extensions into own R/G/B arrays\n",
    "# imr=Image.fromarray(RGB[1].data,mode=None) \n",
    "# img=Image.fromarray(RGB[2].data,mode=None)\n",
    "# imb=Image.fromarray(RGB[3].data,mode=None)\n",
    "\n",
    "# #this is all repeated from earlier just to remind myself what I named things\n",
    "# #now we need to (1) split the abell370 RGB FITS file into three filters\n",
    "\n",
    "# #below, we split the RGB image into R G B FITS files\n",
    "# #what is going on with the WCS info?  \n",
    "\n",
    "# #not sure what this does, calling each image itself I suppose from how I defined the data arrays earlier\n",
    "# red_image = fits.PrimaryHDU(data=imr)\n",
    "# green_image = fits.PrimaryHDU(data=img)\n",
    "# blue_image = fits.PrimaryHDU(data=imb)\n",
    "\n",
    "# #save each as a FITS file - this should go last\n",
    "# red_image.writeto('/mnt/c/Users/lana-/Desktop/a370_arc_red.fits',overwrite=True)\n",
    "# green_image.writeto('/mnt/c/Users/lana-/Desktop/a370_arc_green.fits',overwrite=True)\n",
    "# blue_image.writeto('/mnt/c/Users/lana-/Desktop/a370_arc_blue.fits',overwrite=True)\n",
    "\n",
    "\n",
    "#OVERWRITE BECAUSE NOW USING SCIENCE IMAGE\n",
    "\n",
    "#SCIENCE IMAGES\n",
    "#need to replace one at a time, start with F814W\n",
    "sci_im_red = fits.open('/mnt/c/Users/lana-/Desktop/hlsp_frontier_hst_acs-30mas-selfcal_abell370_f814w_v1.0-epoch1_drz.fits')[0]\n",
    "imr = sci_im_red.data\n",
    "\n",
    "wcs_rgb = WCS(sci_im_red)\n",
    "#now plot\n",
    "# fig = figure(figsize=(15,15))\n",
    "# imshow(imr, origin='lower')\n",
    "\n",
    "#need to replace one at a time, next F606W\n",
    "sci_im_green = fits.open('/mnt/c/Users/lana-/Desktop/hlsp_frontier_hst_acs-30mas-selfcal_abell370_f606w_v1.0-epoch1_drz.fits')[0]\n",
    "img = sci_im_green.data\n",
    "wcs_rgb = WCS(sci_im_green)\n",
    "#now plot\n",
    "# fig = figure(figsize=(15,15))\n",
    "# imshow(img, origin='lower')\n",
    "\n",
    "#need to replace one at a time, now F435W\n",
    "sci_im_blue = fits.open('/mnt/c/Users/lana-/Desktop/hlsp_frontier_hst_acs-30mas-selfcal_abell370_f435w_v1.0-epoch1_drz.fits')[0]\n",
    "imb = sci_im_blue.data\n",
    "wcs_rgb = WCS(sci_im_blue)\n",
    "\n",
    "#not sure what this does, calling each image itself I suppose from how I defined the data arrays earlier\n",
    "red_image = fits.PrimaryHDU(data=imr)\n",
    "green_image = fits.PrimaryHDU(data=img)\n",
    "blue_image = fits.PrimaryHDU(data=imb)\n",
    "\n",
    "#save each as a FITS file - this should go last\n",
    "red_image.writeto('/mnt/c/Users/lana-/Desktop/a370_arc_red.fits',overwrite=True)\n",
    "green_image.writeto('/mnt/c/Users/lana-/Desktop/a370_arc_green.fits',overwrite=True)\n",
    "blue_image.writeto('/mnt/c/Users/lana-/Desktop/a370_arc_blue.fits',overwrite=True)\n",
    "\n",
    "#plot again\n",
    "fig = figure(figsize=(15,15))\n",
    "imshow(imr, origin='lower', norm=simple_norm(imr, 'linear', percent=99.67), vmin=0.)#, cmap='Reds'\n",
    "#plot again\n",
    "fig = figure(figsize=(15,15))\n",
    "imshow(img, origin='lower', norm=simple_norm(img, 'linear', percent=99.67), vmin=0.)#, cmap='Greens'\n",
    "#plot again\n",
    "fig = figure(figsize=(15,15))\n",
    "imshow(imb, origin='lower', norm=simple_norm(imb, 'linear', percent=99.67), vmin=0.)#, cmap='Blues'\n",
    "\n",
    "#factor to convert between pixels in data image instead of RGB image\n",
    "data_factor = 2.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "FITS CUTOUT FUNCTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#now we need to (2) trim each filter FITS file into just the area around the arc\n",
    "#https://docs.astropy.org/en/stable/nddata/utils.html\n",
    "#this can probably be done using the outlined steps at the bottom of that page\n",
    "\n",
    "def save_cutout_image(position, size, filter_color, name_cutout):\n",
    "\n",
    "    \n",
    "    # Load the original RGB image and the WCS\n",
    "    # hdu_orig = fits.open('/mnt/c/Users/lana-/Desktop/abell370_RGB.fits')[0]\n",
    "    if filter_color=='red':\n",
    "        sci_im = sci_im_red\n",
    "    if filter_color=='green':\n",
    "        sci_im = sci_im_green\n",
    "    if filter_color=='blue':\n",
    "        sci_im = sci_im_blue\n",
    "    hdu_orig = sci_im\n",
    "    wcs_orig = WCS(hdu_orig.header)\n",
    "    #is there a separate header corresponding to each filter?  maybe I'm doing this assuming there's only one\n",
    "\n",
    "    # Load the filter image and the WCS\n",
    "    hdu = sci_im# fits.open('/mnt/c/Users/lana-/Desktop/a370_arc_'+str(filter_color)+'.fits')[0]\n",
    "    wcs = WCS(hdu.header)\n",
    "\n",
    "    # Make the cutout, including the WCS\n",
    "    cutout = Cutout2D(hdu.data, position=position, size=size, wcs=wcs_orig)\n",
    "\n",
    "    # Put the cutout image in the FITS HDU\n",
    "    hdu.data = cutout.data\n",
    "\n",
    "    # Update the FITS header with the cutout WCS\n",
    "    hdu.header.update(cutout.wcs.to_header()) #this has coordinate info that gets put into the new header\n",
    "    #hdu.header = hdu_orig.header #this manages to copy over everything, which is not what I need to do\n",
    "\n",
    "    #print(wcs)\n",
    "\n",
    "    #trying to copy over the header info\n",
    "    # header_old = hdu_orig.header\n",
    "\n",
    "    # #more specifically - can add more if needed\n",
    "    # keys_to_copy = ['TELESCOP','INSTRUME','IMAGETYP','PRIMESI','TARGNAME','SUNANGLE','MOONANGL','SUN_ALT','FGSLOCK','GYROMODE','EXPSTART','EXPEND','EXPTIME','TEXPTIME','TEXPTIME','DARKTIME','POSTARG1','POSTARG2','OBSTYPE','OBSMODE','NRPTEXP','DETECTOR','APERTURE','DRIZCORR','MDRIZTAB']\n",
    "    # for key in keys_to_copy:\n",
    "    #     if key in header_old.keys():\n",
    "    #         hdu.header[key] = header_old[key]\n",
    "\n",
    "    # hdu.header = hdu_orig.header\n",
    "\n",
    "    # Write the cutout to a new FITS file\n",
    "    hdu.writeto('/mnt/c/Users/lana-/Desktop/cutout_'+str(name_cutout)+'.fits', overwrite=True)\n",
    "\n",
    "\n",
    "# arc_edge_cutout_red = save_cutout_image(position=(2114.6*data_factor,3540.2*data_factor), size=(115*data_factor,115*data_factor), filter_color='red', name_cutout='red_edge')\n",
    "# arc_edge_cutout_green = save_cutout_image(position=(2114.6*data_factor,3540.2*data_factor), size=(115*data_factor,115*data_factor), filter_color='green', name_cutout='green_edge')\n",
    "# arc_edge_cutout_blue = save_cutout_image(position=(2114.6*data_factor,3540.2*data_factor), size=(115*data_factor,115*data_factor), filter_color='blue', name_cutout='blue_edge')\n",
    "\n",
    "#start with just the right side of the tail to figure out GALFIT with one or two galaxies to model and subtract\n",
    "\n",
    "\n",
    "#then do the entire arc and see how large of a region we would need to model to subtract light from - e.g. does one of the BCGs contaminate\n",
    "#when using GALFIT, model only the large galaxies that contaminate the light of the arc, smaller ones should be masked in pixsrc\n",
    "\n",
    "#FIX THIS\n",
    "\n",
    "#was 700x700 vs 1000x1000\n",
    "arc_full_cutout_red = save_cutout_image(position=(1925*data_factor,3650*data_factor), size=(1000*data_factor,1000*data_factor), filter_color='red', name_cutout='red_full')\n",
    "arc_full_cutout_green = save_cutout_image(position=(1925*data_factor,3650*data_factor), size=(1000*data_factor,1000*data_factor), filter_color='green', name_cutout='green_full')\n",
    "arc_full_cutout_blue = save_cutout_image(position=(1925*data_factor,3650*data_factor), size=(1000*data_factor,1000*data_factor), filter_color='blue', name_cutout='blue_full')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MASKING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #I should just open the new FITS file and work with it as usual\n",
    "# arc_edge_cutout_red_read = fits.open('/mnt/c/Users/lana-/Desktop/cutout_red_edge.fits')\n",
    "# arc_edge_cutout_green_read = fits.open('/mnt/c/Users/lana-/Desktop/cutout_green_edge.fits')\n",
    "# arc_edge_cutout_blue_read = fits.open('/mnt/c/Users/lana-/Desktop/cutout_blue_edge.fits')\n",
    "# arc_edge_cutout_red_read.info()\n",
    "# arc_edge_cutout_green_read.info()\n",
    "# arc_edge_cutout_blue_read.info()\n",
    "\n",
    "#for the full arc\n",
    "arc_full_cutout_red_read = fits.open('/mnt/c/Users/lana-/Desktop/cutout_red_full.fits')\n",
    "arc_full_cutout_green_read = fits.open('/mnt/c/Users/lana-/Desktop/cutout_green_full.fits')\n",
    "arc_full_cutout_blue_read = fits.open('/mnt/c/Users/lana-/Desktop/cutout_blue_full.fits')\n",
    "\n",
    "\n",
    "# # Read in file\n",
    "# red_file = '/mnt/c/Users/lana-/Desktop/cutout_red_edge.fits'\n",
    "# green_file = '/mnt/c/Users/lana-/Desktop/cutout_green_edge.fits'\n",
    "# blue_file = '/mnt/c/Users/lana-/Desktop/cutout_blue_edge.fits'\n",
    "# Red = fits.open(red_file)\n",
    "# Green = fits.open(green_file)\n",
    "# Blue = fits.open(blue_file)\n",
    "# #set up the WCS for when I figure out how to save this as a FITS file\n",
    "# wcs_red = WCS(red_file)\n",
    "# wcs_green = WCS(green_file)\n",
    "# wcs_blue = WCS(blue_file)\n",
    "# # Put separate extensions into own arrays\n",
    "# red_edge_to_mask = Image.fromarray(arc_edge_cutout_red_read[0].data,mode=None) \n",
    "# green_edge_to_mask = Image.fromarray(arc_edge_cutout_green_read[0].data,mode=None) \n",
    "# blue_edge_to_mask = Image.fromarray(arc_edge_cutout_blue_read[0].data,mode=None) \n",
    "# # print(red_edge_to_mask)\n",
    "\n",
    "#for the full arc\n",
    "# Read in file\n",
    "red_file_arc = '/mnt/c/Users/lana-/Desktop/cutout_red_full.fits'\n",
    "green_file_arc = '/mnt/c/Users/lana-/Desktop/cutout_green_full.fits'\n",
    "blue_file_arc = '/mnt/c/Users/lana-/Desktop/cutout_blue_full.fits'\n",
    "Red_arc = fits.open(red_file_arc)\n",
    "Green_arc = fits.open(green_file_arc)\n",
    "Blue_arc = fits.open(blue_file_arc)\n",
    "#set up the WCS for when I figure out how to save this as a FITS file\n",
    "wcs_red_arc = WCS(red_file_arc)\n",
    "wcs_green_arc = WCS(green_file_arc)\n",
    "wcs_blue_arc = WCS(blue_file_arc)\n",
    "# Put separate extensions into own arrays\n",
    "red_arc_to_mask = Image.fromarray(arc_full_cutout_red_read[0].data,mode=None) \n",
    "green_arc_to_mask = Image.fromarray(arc_full_cutout_green_read[0].data,mode=None) \n",
    "blue_arc_to_mask = Image.fromarray(arc_full_cutout_blue_read[0].data,mode=None) \n",
    "# print(red_edge_to_mask)\n",
    "\n",
    "\n",
    "# #not sure what this does, calling each image itself I suppose from how I defined the data arrays earlier\n",
    "# red_test = fits.PrimaryHDU(data=red_edge_to_mask)\n",
    "# green_test = fits.PrimaryHDU(data=green_edge_to_mask)\n",
    "# blue_test = fits.PrimaryHDU(data=blue_edge_to_mask)\n",
    "\n",
    "#full arc\n",
    "red_test_arc = fits.PrimaryHDU(data=red_arc_to_mask)\n",
    "green_test_arc = fits.PrimaryHDU(data=green_arc_to_mask)\n",
    "blue_test_arc = fits.PrimaryHDU(data=blue_arc_to_mask)\n",
    "\n",
    "\n",
    "#FINALLY GOT WHAT I NEEDED\n",
    "# print(red_test.data)\n",
    "# print(len(red_test.data))\n",
    "# print(red_test.data[0][1])#[y][x]\n",
    "\n",
    "# #test to plot and see if merging works before I do anything else to the arrays\n",
    "# #convert from floats to integers so can plot as RGB\n",
    "# red_conv = red_arc_to_mask.convert('L')\n",
    "# green_conv = green_arc_to_mask.convert('L')\n",
    "# blue_conv = blue_arc_to_mask.convert('L')\n",
    "# # Merge them back into one image\n",
    "# merged_test=Image.merge(\"RGB\",(red_conv,green_conv,blue_conv))\n",
    "# # Plot it\n",
    "# fig = figure(figsize=(15,15))\n",
    "# imshow(merged_test, origin='lower', norm=simple_norm(imr, 'linear', percent=99.67), vmin=0.)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# arc_masked_red = red_test.data\n",
    "# arc_masked_green = green_test.data + 100 #will subtract in next step\n",
    "# arc_masked_blue = blue_test.data + 100 #will subtract in next step\n",
    "#full arc\n",
    "arc_masked_red_full = red_test_arc.data\n",
    "arc_masked_green_full = green_test_arc.data# + 100 #will subtract in next step\n",
    "arc_masked_blue_full = blue_test_arc.data# + 100 #will subtract in next step\n",
    "\n",
    "\n",
    "# Red.close()\n",
    "# Green.close()\n",
    "# Blue.close()\n",
    "#full arc\n",
    "Red_arc.close()\n",
    "Green_arc.close()\n",
    "Blue_arc.close()\n",
    "\n",
    "\n",
    "# #redefine so no overwrite?!\n",
    "# arc_masked_red = arc_masked_red.copy()\n",
    "# arc_masked_green = arc_masked_green.copy()\n",
    "# arc_masked_blue = arc_masked_blue.copy()\n",
    "#redefine so no overwrite\n",
    "arc_masked_red_full = arc_masked_red_full.copy()\n",
    "arc_masked_green_full = arc_masked_green_full.copy()\n",
    "arc_masked_blue_full = arc_masked_blue_full.copy()\n",
    "\n",
    "\n",
    "# #now to mask a section of this that includes the arc\n",
    "# for x in range(115):\n",
    "#     for y in range(115):\n",
    "#         if ((y)>(0.75*x+18)):\n",
    "#             arc_masked_red[y][x] = 0\n",
    "#             arc_masked_green[y][x] = 0\n",
    "#             arc_masked_blue[y][x] = 0\n",
    "# # print(red_test.data)\n",
    "\n",
    "data_factor_int = 2\n",
    "\n",
    "#figure out what needs to be masked here - use the previous thing and start with the first one \n",
    "#ok, this is for the box that we previously blocked out, it is a different size and shape\n",
    "#added 150 because cutout size changed\n",
    "#trapezoid\n",
    "for x in range(100*data_factor_int):\n",
    "    for y in range(100*data_factor_int):\n",
    "        #this was to block the right edge of the arc, adjust the position later\n",
    "        if ((y)>(0.625*x+(10*data_factor_int))):\n",
    "            # if (y>25) and (x>7.5):\n",
    "            arc_masked_red_full[y+((700-400-100+5+150)*data_factor_int)][x+((480+10+150)*data_factor_int)] = 0.\n",
    "            arc_masked_green_full[y+((700-400-100+5+150)*data_factor_int)][x+((480+10+150)*data_factor_int)] = 0.\n",
    "            arc_masked_blue_full[y+((700-400-100+5+150)*data_factor_int)][x+((480+10+150)*data_factor_int)] = 0.\n",
    "#rectangle\n",
    "for x in range(40*data_factor_int):\n",
    "    for y in range(30*data_factor_int):\n",
    "        arc_masked_red_full[y+((235+150)*data_factor_int)][x+((470+150-10)*data_factor_int)] = 0.\n",
    "        arc_masked_green_full[y+((235+150)*data_factor_int)][x+((470+150-10)*data_factor_int)] = 0.\n",
    "        arc_masked_blue_full[y+((235+150)*data_factor_int)][x+((470+150-10)*data_factor_int)] = 0.\n",
    "#this is for the next part of the arc to the left of that\n",
    "#rectangle\n",
    "for x in range(60*data_factor_int):\n",
    "    for y in range(25*data_factor_int):\n",
    "        arc_masked_red_full[y+((212+150)*data_factor_int)][x+((440+150-10)*data_factor_int)] = 0.\n",
    "        arc_masked_green_full[y+((212+150)*data_factor_int)][x+((440+150-10)*data_factor_int)] = 0.\n",
    "        arc_masked_blue_full[y+((212+150)*data_factor_int)][x+((440+150-10)*data_factor_int)] = 0.\n",
    "#triangle\n",
    "for x in range(100*data_factor_int):\n",
    "    for y in range(50*data_factor_int):\n",
    "        if y>(0.65*x):\n",
    "            arc_masked_red_full[y+((190+150-5)*data_factor_int)][x+((425+150-5)*data_factor_int)] = 0.\n",
    "            arc_masked_green_full[y+((190+150-5)*data_factor_int)][x+((425+150-5)*data_factor_int)] = 0.\n",
    "            arc_masked_blue_full[y+((190+150-5)*data_factor_int)][x+((425+150-5)*data_factor_int)] = 0.\n",
    "#square\n",
    "for x in range(25*data_factor_int):\n",
    "    for y in range(25*data_factor_int):\n",
    "        arc_masked_red_full[y+((185+150)*data_factor_int)][x+((400+150)*data_factor_int)] = 0.\n",
    "        arc_masked_green_full[y+((185+150)*data_factor_int)][x+((400+150*data_factor_int))] = 0.\n",
    "        arc_masked_blue_full[y+((185+150)*data_factor_int)][x+((400+150)*data_factor_int)] = 0.\n",
    "#now for the middle part of the arc\n",
    "#trapezoid\n",
    "for x in range(50*data_factor_int):\n",
    "    for y in range(25*data_factor_int):\n",
    "        if y<(-0.3*x+(25*data_factor_int)):\n",
    "            arc_masked_red_full[y+((190+150)*data_factor_int)][x+((320+150)*data_factor_int)] = 0.\n",
    "            arc_masked_green_full[y+((190+150)*data_factor_int)][x+((320+150)*data_factor_int)] = 0.\n",
    "            arc_masked_blue_full[y+((190+150)*data_factor_int)][x+((320+150)*data_factor_int)] = 0.\n",
    "#this left ish part will need to be masked and unmasked for each of the overlapping galaxies here\n",
    "#first do a general mask of the arc - come back to this later when modeling individual galaxies\n",
    "#trapezoid\n",
    "for x in range(50*data_factor_int):\n",
    "    for y in range(25*data_factor_int):\n",
    "        if y<(-0.15*x+(25*data_factor_int)):\n",
    "            arc_masked_red_full[y+((195+150)*data_factor_int)][x+((225+150)*data_factor_int)] = 0.\n",
    "            arc_masked_green_full[y+((195+150)*data_factor_int)][x+((225+150)*data_factor_int)] = 0.\n",
    "            arc_masked_blue_full[y+((195+150)*data_factor_int)][x+((225+150)*data_factor_int)] = 0.\n",
    "#square\n",
    "for x in range(25*data_factor_int):\n",
    "    for y in range(25*data_factor_int):\n",
    "        arc_masked_red_full[y+((210+150)*data_factor_int)][x+((220+150)*data_factor_int)] = 0.\n",
    "        arc_masked_green_full[y+((210+150)*data_factor_int)][x+((220+150)*data_factor_int)] = 0.\n",
    "        arc_masked_blue_full[y+((210+150)*data_factor_int)][x+((220+150)*data_factor_int)] = 0.\n",
    "#square\n",
    "for x in range(25*data_factor_int):\n",
    "    for y in range(25*data_factor_int):\n",
    "        arc_masked_red_full[y+((195+150)*data_factor_int)][x+((275+150)*data_factor_int)] = 0.\n",
    "        arc_masked_green_full[y+((195+150)*data_factor_int)][x+((275+150)*data_factor_int)] = 0.\n",
    "        arc_masked_blue_full[y+((195+150)*data_factor_int)][x+((275+150)*data_factor_int)] = 0.\n",
    "\n",
    "\n",
    "# arc_masked_red = red_test.data\n",
    "# arc_masked_green = green_test.data\n",
    "# arc_masked_blue = blue_test.data\n",
    "#imshow(red_test.data,origin='lower')\n",
    "# figure()\n",
    "# imshow(arc_masked_red,origin='lower')\n",
    "# title(\"F814W\")\n",
    "# figure()\n",
    "# imshow(arc_masked_green,origin='lower')\n",
    "# title(\"F606W (+100)\")\n",
    "# figure()\n",
    "# imshow(arc_masked_blue,origin='lower')\n",
    "# title(\"F435W (+100)\")\n",
    "#full arc\n",
    "figure(figsize=(10,10))\n",
    "imshow(arc_masked_red_full,origin='lower', norm=simple_norm(imr, 'linear', percent=99.5), vmin=0.)\n",
    "title(\"F814W\")\n",
    "figure(figsize=(10,10))\n",
    "imshow(arc_masked_green_full,origin='lower', norm=simple_norm(imr, 'linear', percent=99), vmin=0.) #imshow(arc_masked_green_full-100,origin='lower')\n",
    "title(\"F606W\")# (+100)\")\n",
    "figure(figsize=(10,10))\n",
    "imshow(arc_masked_blue_full,origin='lower', norm=simple_norm(imr, 'linear', percent=95), vmin=0.) #imshow(arc_masked_blue_full-100,origin='lower')\n",
    "title(\"F435W\")# (+100)\")\n",
    "\n",
    "#full arc but grey\n",
    "#full arc\n",
    "figure(figsize=(10,10))\n",
    "imshow(arc_masked_red_full,origin='lower', cmap='gray', norm=simple_norm(imr, 'log', percent=99.75), vmin=0.)\n",
    "title(\"F814W\")\n",
    "figure(figsize=(10,10))\n",
    "imshow(arc_masked_green_full,origin='lower', cmap='gray', norm=simple_norm(imr, 'log', percent=99.75), vmin=0.) #imshow(arc_masked_green_full-100,origin='lower')\n",
    "title(\"F606W\")# (+100)\")\n",
    "figure(figsize=(10,10))\n",
    "imshow(arc_masked_blue_full,origin='lower', cmap='gray', norm=simple_norm(imr, 'log', percent=99.75), vmin=0.) #imshow(arc_masked_blue_full-100,origin='lower')\n",
    "title(\"F435W\")# (+100)\")\n",
    "\n",
    "\n",
    "# #yet another test\n",
    "# # Put separate extensions into own R/G/B arrays\n",
    "# imr_try=Image.fromarray(arc_masked_red_full,mode=None) \n",
    "# img_try=Image.fromarray(arc_masked_green_full-100,mode=None)\n",
    "# imb_try=Image.fromarray(arc_masked_blue_full-100,mode=None)\n",
    "# imr_try_plot = imr_try.convert('L')\n",
    "# img_try_plot = img_try.convert('L')\n",
    "# imb_try_plot = imb_try.convert('L')\n",
    "# # Merge them back into one image\n",
    "# merged_test=Image.merge(\"RGB\",(imr_try_plot,img_try_plot,imb_try_plot))\n",
    "# # Plot it\n",
    "# fig = figure(figsize=(5,5))\n",
    "# imshow(merged_test, origin='lower', norm=simple_norm(imr, 'linear', percent=99.67), vmin=0.)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #ok so now we have arc_masked_red that has zeros - we need to actually mask those with numpy.ma\n",
    "# arc_mask_red = numpy.ma.masked_equal(arc_masked_red, numpy.zeros(arc_masked_red.shape))\n",
    "# arc_mask_green = numpy.ma.masked_equal(arc_masked_green, numpy.zeros(arc_masked_green.shape)) - 100\n",
    "# arc_mask_blue = numpy.ma.masked_equal(arc_masked_blue, numpy.zeros(arc_masked_blue.shape)) - 100\n",
    "#WOOHOO fixed!\n",
    "#could just +1 to array before set region to 0, mask the 0 area, and then subtract one from entire array - used 100\n",
    "\n",
    "#same but for entire image\n",
    "arc_mask_red_full = numpy.ma.masked_equal(arc_masked_red_full, numpy.zeros(arc_masked_red_full.shape))\n",
    "arc_mask_green_full = numpy.ma.masked_equal(arc_masked_green_full, numpy.zeros(arc_masked_green_full.shape))# - 100\n",
    "arc_mask_blue_full = numpy.ma.masked_equal(arc_masked_blue_full, numpy.zeros(arc_masked_blue_full.shape))# - 100\n",
    "\n",
    "\n",
    "#define colormaps for each\n",
    "cmap_maskr = cm.get_cmap('gist_heat')\n",
    "cmap_maskr.set_bad(color=\"none\")\n",
    "cmap_maskg = cm.get_cmap('summer')\n",
    "cmap_maskg.set_bad(color=\"none\")\n",
    "cmap_maskb = cm.get_cmap('winter')\n",
    "cmap_maskb.set_bad(color=\"none\")\n",
    "cmap_blank = cm.get_cmap('gray')\n",
    "#AWESOME\n",
    "# figure()\n",
    "# imshow(red_test.data,origin='lower',cmap=cmap_blank)\n",
    "# imshow(arc_mask_red,origin='lower',cmap=cmap_maskr)\n",
    "# title(\"814\")\n",
    "# figure()\n",
    "# imshow(green_test.data,origin='lower',cmap=cmap_blank)\n",
    "# imshow(arc_mask_green,origin='lower',cmap=cmap_maskg)\n",
    "# title(\"606\")\n",
    "# figure()\n",
    "# imshow(blue_test.data,origin='lower',cmap=cmap_blank)\n",
    "# imshow(arc_mask_blue,origin='lower',cmap=cmap_maskb)\n",
    "# title(\"435\")\n",
    "\n",
    "#now for entire image\n",
    "figure()\n",
    "imshow(red_test_arc.data,origin='lower',cmap=cmap_blank, norm=simple_norm(imr, 'log', percent=99.75), vmin=0.)\n",
    "imshow(arc_mask_red_full,origin='lower',cmap=cmap_maskr, norm=simple_norm(imr, 'log', percent=99.75), vmin=0.)\n",
    "title(\"814\")\n",
    "figure()\n",
    "imshow(green_test_arc.data,origin='lower',cmap=cmap_blank, norm=simple_norm(imr, 'log', percent=99.75), vmin=0.)\n",
    "imshow(arc_mask_green_full,origin='lower',cmap=cmap_maskg, norm=simple_norm(imr, 'log', percent=99.75), vmin=0.)\n",
    "title(\"606\")\n",
    "figure()\n",
    "imshow(blue_test_arc.data,origin='lower',cmap=cmap_blank, norm=simple_norm(imr, 'log', percent=99.75), vmin=0.)\n",
    "imshow(arc_mask_blue_full,origin='lower',cmap=cmap_maskb, norm=simple_norm(imr, 'log', percent=99.75), vmin=0.)\n",
    "title(\"435\")\n",
    "\n",
    "\n",
    "# print(arc_masked_red)\n",
    "# print(numpy.min(arc_masked_red))\n",
    "# print(numpy.max(arc_masked_red))\n",
    "\n",
    "\n",
    "# #yet another test\n",
    "# # Put separate extensions into own R/G/B arrays\n",
    "# imr_try=Image.fromarray(arc_mask_red_full,mode=None) \n",
    "# img_try=Image.fromarray(arc_mask_green_full,mode=None)\n",
    "# imb_try=Image.fromarray(arc_mask_blue_full,mode=None)\n",
    "# # Merge them back into one image\n",
    "# merged_test=Image.merge(\"RGB\",(imr_try,img_try,imb_try))\n",
    "# # Plot it\n",
    "# fig = figure(figsize=(5,5))\n",
    "# imshow(merged_test, origin='lower')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "FUNCTIONS DEFINED - FIT_GAL_ELLIPSE AND REMOVE_GAL_STEPS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to just set up the initial ellipse guess and fit the galaxy - since I'm going to be doing this for many galaxies\n",
    "\n",
    "def fit_gal_ellipse(x0_pos,y0_pos,sm_axis,cmap_mask=cmap_maskr,filt=814,ellip=0.5,pos_ang=(numpy.pi)/4.,sigma_clip=3.0,fix_cent=False,max_sma=1200*data_factor,data_image=red_test_arc.data,new_mask=arc_mask_red_full,integrmodee='median',num_clip=3,converg=0.05,max_gerr=0.5,min_it=10,f_flag=0.7,max_r_it=None,fix_p_a=False,fix_el=False,plotyes=False):\n",
    "\n",
    "    # if data_image==red_test_arc.data:\n",
    "    #     cmap_mask = cmap_maskr\n",
    "    #     filt = 814\n",
    "    # if data_image==green_test_arc.data:\n",
    "    #     cmap_mask = cmap_maskg\n",
    "    #     filt = 606\n",
    "    # if data_image==blue_test_arc.data:\n",
    "    #     cmap_mask = cmap_maskb\n",
    "    #     filt = 435\n",
    "\n",
    "    print(\"begin creating and plotting initial ellipse guess\")\n",
    "    \n",
    "    #create and plot initial ellipse guess\n",
    "    geometryy = EllipseGeometry(x0=x0_pos, y0=y0_pos, sma=sm_axis, eps=ellip, pa=pos_ang)\n",
    "    aperr = EllipticalAperture((geometryy.x0, geometryy.y0), geometryy.sma, geometryy.sma * (1 - geometryy.eps), geometryy.pa)\n",
    "    \n",
    "    print(\"end creating and plotting initial ellipse guess, begin fitting ellipse to entire arc\")\n",
    "    \n",
    "    #now for the full arc\n",
    "    ellipsee = Ellipse(new_mask,geometryy)\n",
    "    print(\"done setting up Ellipse, begin creating isolist and fitting to galaxy\")\n",
    "    isolistt = ellipsee.fit_image(integrmode=integrmodee, sclip=sigma_clip, nclip=num_clip, fflag=f_flag, maxgerr=max_gerr, fix_center=fix_cent,conver=converg, maxsma=max_sma,minit=min_it,maxrit=max_r_it,fix_pa=fix_p_a,fix_eps=fix_el)\n",
    "    print(isolistt.pa)\n",
    "    print(\"done fitting and creating isolist, begin converting it to table\")\n",
    "    the_table = isolistt.to_table()\n",
    "    print(the_table)\n",
    "\n",
    "    print(\"done creating isophote list, begin plotting\")\n",
    "\n",
    "    print(\"plot?\",plotyes)\n",
    "\n",
    "    if plotyes==True:\n",
    "\n",
    "        #full arc with initial guess\n",
    "        figure(figsize=(15,15))\n",
    "        imshow(data_image,origin='lower',cmap=cmap_blank, norm=simple_norm(imr, 'log', percent=99.75), vmin=0.)\n",
    "        imshow(new_mask,origin='lower',cmap=cmap_mask, norm=simple_norm(imr, 'log', percent=99.75), vmin=0.)\n",
    "        aperr.plot(color='white')\n",
    "        title(\"Random Test\")\n",
    "\n",
    "        #plot some isophotes overlaid on masked image\n",
    "        fig, ax = subplots(figsize=(15,15))\n",
    "        imshow(data_image,origin='lower',cmap=cmap_blank, norm=simple_norm(imr, 'log', percent=99.75), vmin=0.)\n",
    "        imshow(new_mask,origin='lower',cmap=cmap_mask, norm=simple_norm(imr, 'log', percent=99.75), vmin=0.)\n",
    "        ax.set_title(\"F\"+str(filt)+\"W Isophotes Full Arc\")\n",
    "        # go to the outermost successfully fitted ellipse at sma=235\n",
    "        isos = []\n",
    "        for sma in [5.*data_factor, 10.*data_factor, 15.*data_factor, 20.*data_factor, 25.*data_factor, 30.*data_factor, 35.*data_factor, 40.*data_factor, 45.*data_factor, 50.*data_factor, 60.*data_factor, 70.*data_factor, 75.*data_factor, 100.*data_factor, 125.*data_factor, 150.*data_factor, 175.*data_factor, 200.*data_factor, 250.*data_factor, 300.*data_factor, 350.*data_factor, 400.*data_factor, 450.*data_factor, 500.*data_factor, 550.*data_factor, 600.*data_factor, 650.*data_factor, 700.*data_factor, 750.*data_factor]:# do like x+ 5 increments\n",
    "            iso = isolistt.get_closest(sma)\n",
    "            isos.append(iso)\n",
    "            x, y, = iso.sampled_coordinates()\n",
    "            plot(x, y, color='w')\n",
    "\n",
    "    return geometryy, aperr, ellipsee, isolistt, the_table\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_gal_steps(iso_galaxy,cmap_mask=cmap_maskr,filt=814,epsf_color=epsf_r,backg_num=15,data_image=red_test_arc.data,new_mask=arc_mask_red_full,conv=False,plotyes=False):\n",
    "#edit colormap\n",
    "    # if data_image==red_test_arc.data:\n",
    "    #     cmap_mask = cmap_maskr\n",
    "    #     filt = 814\n",
    "    #     epsf_color = epsf_r\n",
    "    # if data_image==green_test_arc.data:\n",
    "    #     cmap_mask = cmap_maskg\n",
    "    #     filt = 606        \n",
    "    #     epsf_color = epsf_g\n",
    "    # if data_image==blue_test_arc.data:\n",
    "    #     cmap_mask = cmap_maskb\n",
    "    #     filt = 435\n",
    "    #     epsf_color = epsf_b\n",
    "\n",
    "    background_number = backg_num\n",
    "\n",
    "    #make a model of the galaxy\n",
    "    mod_img = build_ellipse_model(data_image.shape, iso_galaxy, fill=0)#numpy.mean(red_test.data[20:120, 20:120]))\n",
    "    mod_img_backgr = mod_img*1.\n",
    "    mod_img_backgr[numpy.where(mod_img_backgr != 0)] = mod_img_backgr[numpy.where(mod_img_backgr != 0)] - (background_number)\n",
    "    #arc_mask_red try if no work\n",
    "\n",
    "    #convolution, optional\n",
    "    if conv==True:\n",
    "        mod_img = convolve(mod_img,epsf_color.data)\n",
    "\n",
    "    #now test if can remove and have normal residual\n",
    "    residual_color = data_image - mod_img\n",
    "    residual_color_backgr = data_image - mod_img_backgr\n",
    "    new_masked_img = new_mask - mod_img_backgr\n",
    "\n",
    "    print(\"plot?\",plotyes)\n",
    "\n",
    "    if plotyes==True:\n",
    "\n",
    "        figure()\n",
    "        imshow(mod_img, origin='lower',cmap=cmap_mask, norm=simple_norm(imr, 'log', percent=99.75), vmin=0.)#, vmin=0, vmax=161)\n",
    "        title(\"Model \"+str(filt))\n",
    "\n",
    "        figure()\n",
    "        imshow(mod_img_backgr, origin='lower',cmap=cmap_mask, norm=simple_norm(imr, 'log', percent=99.75), vmin=0.)#, vmin=0, vmax=161)\n",
    "        title(\"Model \"+str(filt)+str(background_number))\n",
    "\n",
    "        figure()\n",
    "        imshow(data_image, origin='lower',cmap=cmap_mask, norm=simple_norm(imr, 'log', percent=99.75), vmin=0.)#, vmin=0, vmax=161)\n",
    "        title(\"Data \"+str(filt))\n",
    "\n",
    "        figure(figsize=(15,15))\n",
    "        imshow(residual_color, origin='lower',cmap=cmap_mask, norm=simple_norm(imr, 'log', percent=99.75), vmin=0.)#, vmin=0, vmax=161)\n",
    "        title(\"Residual F\"+str(filt)+\"W Full Arc\")\n",
    "\n",
    "        figure(figsize=(15,15))\n",
    "        imshow(residual_color_backgr, origin='lower',cmap=cmap_mask, norm=simple_norm(imr, 'log', percent=99.75), vmin=0.)#, vmin=0, vmax=161)\n",
    "        title(\"Background \"+str(background_number))\n",
    "\n",
    "    #geom_BCG12, ap_BCG12, elli_BCG12, iso_BCG12, tabl_BCG12 = fit_gal_ellipse(x0_pos=325+150,y0_pos=360+150,sm_axis=100,ellip=0.4,pos_ang=(numpy.pi)/2.,sigma_clip=3.0,fix_cent=False,data_image=model_image_814_backgr)\n",
    "    #why is this using the original image??\n",
    "\n",
    "    return residual_color_backgr,new_masked_img\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BCG1 NEAR THE ARC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "geom_BCG1r, ap_BCG1r, elli_BCG1r, iso_BCG1r, tabl_BCG1r = fit_gal_ellipse(cmap_mask=\"tab20\",x0_pos=(325+150)*data_factor,y0_pos=(360+150)*data_factor,sm_axis=200*data_factor,ellip=0.45,pos_ang=(numpy.pi)/2.,sigma_clip=2.0,fix_cent=True,data_image=red_test_arc.data,max_sma=700*data_factor,new_mask=arc_mask_red_full,integrmodee='median',num_clip=3,converg=0.05,max_gerr=0.5,min_it=15,f_flag=0.3,max_r_it=1200*data_factor,fix_p_a=False,fix_el=False,plotyes=True)\n",
    "residual_814_backgr_BCG1,new_masked_img_BCG1r = remove_gal_steps(cmap_mask=\"tab20\",iso_galaxy=iso_BCG1r,backg_num=15,data_image=red_test_arc.data,new_mask=arc_mask_red_full,plotyes=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ok, turns out I need to block out everything for each galaxy while fitting it.. OR\n",
    "#lower sigma clipping number to \n",
    "#so here we do the blocking out of extra light for OUR FIRST GALAXY, the BCG in this cutout\n",
    "\n",
    "#here we do the fitting\n",
    "geom_BCG1r, ap_BCG1r, elli_BCG1r, iso_BCG1r, tabl_BCG1r = fit_gal_ellipse(x0_pos=(325+150)*data_factor,y0_pos=(360+150)*data_factor,sm_axis=200*data_factor,ellip=0.35,pos_ang=(numpy.pi)/2.,sigma_clip=2.5,fix_cent=True,data_image=red_test_arc.data,max_sma=700*data_factor,new_mask=arc_mask_red_full,integrmodee='median',num_clip=5,converg=0.05,max_gerr=0.5,min_it=20,f_flag=0.3,max_r_it=1200*data_factor,fix_p_a=False,fix_el=False,plotyes=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#the BCG in this image (other one is hidden)\n",
    "residual_814_backgr_BCG1,new_masked_img_BCG1r = remove_gal_steps(iso_galaxy=iso_BCG1r,backg_num=0.00065,data_image=red_test_arc.data,new_mask=arc_mask_red_full,plotyes=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test green\n",
    "geom_BCG1g, ap_BCG1g, elli_BCG1g, iso_BCG1g, tabl_BCG1g = fit_gal_ellipse(x0_pos=(325+150)*data_factor,y0_pos=(360+150)*data_factor,sm_axis=200*data_factor,cmap_mask=cmap_maskr,filt=606,ellip=0.45,pos_ang=(numpy.pi)/2.,sigma_clip=2.0,fix_cent=True,data_image=green_test_arc.data,max_sma=550*data_factor,new_mask=arc_mask_green_full,integrmodee='median',num_clip=3,converg=0.05,max_gerr=0.5,min_it=15,f_flag=0.3,max_r_it=750*data_factor,fix_p_a=False,fix_el=False,plotyes=True)\n",
    "residual_606_backgr_BCG1,new_masked_img_BCG1g = remove_gal_steps(cmap_mask=cmap_maskr,filt=606,epsf_color=epsf_g,iso_galaxy=iso_BCG1g,backg_num=0.00025,data_image=green_test_arc.data,new_mask=arc_mask_green_full,plotyes=True)\n",
    "\n",
    "#try tab20 colormap or set2 or set3 or pastel2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test blue\n",
    "geom_BCG1b, ap_BCG1b, elli_BCG1b, iso_BCG1b, tabl_BCG1b = fit_gal_ellipse(x0_pos=(325+150)*data_factor,y0_pos=(360+150)*data_factor,sm_axis=50*data_factor,cmap_mask=cmap_maskr,filt=435,ellip=0.45,pos_ang=(numpy.pi)/2.,sigma_clip=2.0,fix_cent=True,data_image=blue_test_arc.data,max_sma=200*data_factor,new_mask=arc_mask_blue_full,integrmodee='median',num_clip=3,converg=0.05,max_gerr=0.5,min_it=15,f_flag=0.3,max_r_it=500*data_factor,fix_p_a=False,fix_el=False,plotyes=True)\n",
    "residual_435_backgr_BCG1,new_masked_img_BCG1b = remove_gal_steps(cmap_mask=cmap_maskr,filt=435,epsf_color=epsf_b,iso_galaxy=iso_BCG1b,backg_num=0.,data_image=blue_test_arc.data,new_mask=arc_mask_blue_full,plotyes=True)\n",
    "\n",
    "#cmap_maskr etc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(type(red_test_arc))\n",
    "# print(type(red_arc_to_mask))\n",
    "# print(type(arc_masked_red_full))\n",
    "# print(type(arc_mask_red_full))\n",
    "# print(type(new_masked_img_BCG1b))\n",
    "# print(type(residual_814_backgr_BCG1))\n",
    "# print(type(imr_try))\n",
    "# # print(type())\n",
    "# # print(type())\n",
    "# # print(type())\n",
    "\n",
    "\n",
    "\n",
    "# #yet another test\n",
    "# # Put separate extensions into own R/G/B arrays\n",
    "# imr_try=Image.fromarray(residual_814_backgr_BCG1,mode=None) \n",
    "# img_try=Image.fromarray(residual_606_backgr_BCG1,mode=None)\n",
    "# imb_try=Image.fromarray(residual_435_backgr_BCG1,mode=None)\n",
    "# # Merge them back into one image\n",
    "# merged_test=Image.merge(\"RGB\",(imr_try,img_try,imb_try))\n",
    "# # Plot it\n",
    "# fig = figure(figsize=(5,5))\n",
    "# imshow(merged_test, origin='lower')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "R1 GALAXY:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#the farthest one on the right\n",
    "geom_R1r, ap_R1r, elli_R1r, iso_R1r, tabl_R1r = fit_gal_ellipse(cmap_mask=cmap_maskr,filt=814,x0_pos=(528.01+150)*data_factor,y0_pos=(230+150)*data_factor,sm_axis=15*data_factor/2,ellip=0.5,pos_ang=(numpy.pi)/4.,sigma_clip=2.5,fix_cent=False,data_image=residual_814_backgr_BCG1,new_mask=new_masked_img_BCG1r,integrmodee='median',num_clip=3,converg=0.05,max_gerr=0.5,max_sma=55*data_factor,min_it=10,f_flag=0.5,max_r_it=30*data_factor,fix_p_a=False,fix_el=False,plotyes=True)\n",
    "residual_814_backgr_R1,new_masked_img_R1r = remove_gal_steps(cmap_mask=cmap_maskr,filt=814,iso_galaxy=iso_R1r,backg_num=0.0005,data_image=residual_814_backgr_BCG1,new_mask=new_masked_img_BCG1r,plotyes=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#the farthest one on the right\n",
    "geom_R1g, ap_R1g, elli_R1g, iso_R1g, tabl_R1g = fit_gal_ellipse(cmap_mask=cmap_maskr,filt=606,x0_pos=(528.01+150)*data_factor,y0_pos=(230+150)*data_factor,sm_axis=15*data_factor,ellip=0.55,pos_ang=(numpy.pi)/4.,sigma_clip=2.0,fix_cent=False,data_image=residual_606_backgr_BCG1,new_mask=new_masked_img_BCG1g,integrmodee='median',num_clip=3,converg=0.05,max_gerr=0.5,max_sma=55*data_factor,min_it=10,f_flag=0.4,max_r_it=35*data_factor,fix_p_a=False,fix_el=False,plotyes=True)\n",
    "residual_606_backgr_R1,new_masked_img_R1g = remove_gal_steps(cmap_mask=cmap_maskr,filt=606,iso_galaxy=iso_R1g,backg_num=0.0001,data_image=residual_606_backgr_BCG1,new_mask=new_masked_img_BCG1g,plotyes=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#the farthest one on the right\n",
    "geom_R1b, ap_R1, elli_R1b, iso_R1b, tabl_R1b = fit_gal_ellipse(cmap_mask=cmap_maskr,filt=435,x0_pos=(528.01+150)*data_factor,y0_pos=(230+150)*data_factor,sm_axis=6*data_factor,ellip=0.4,pos_ang=(numpy.pi)/4.,sigma_clip=3.0,fix_cent=True,data_image=residual_435_backgr_BCG1,new_mask=new_masked_img_BCG1b,integrmodee='median',num_clip=3,converg=0.05,max_gerr=0.5,max_sma=27.5*data_factor,min_it=10,f_flag=0.5,max_r_it=27*data_factor,fix_p_a=False,fix_el=False,plotyes=True)\n",
    "residual_435_backgr_R1,new_masked_img_R1b = remove_gal_steps(cmap_mask=cmap_maskr,filt=435,iso_galaxy=iso_R1b,backg_num=0.,data_image=residual_435_backgr_BCG1,new_mask=new_masked_img_BCG1b,plotyes=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "R2 GALAXY:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model other galaxies around arc\n",
    "geom_R2r, ap_R2r, elli_R2r, iso_R2r, tabl_R2r = fit_gal_ellipse(cmap_mask=cmap_maskr,filt=814,x0_pos=(457+152)*data_factor,y0_pos=(198+151)*data_factor,sm_axis=7*data_factor,ellip=0.25,pos_ang=numpy.pi/6.,sigma_clip=2.0,fix_cent=False,data_image=residual_814_backgr_BCG1,new_mask=new_masked_img_BCG1r,integrmodee='median',num_clip=2,converg=0.05,max_gerr=0.5,max_sma=40*data_factor,min_it=10,f_flag=0.7,max_r_it=20*data_factor,fix_p_a=False,fix_el=False,plotyes=True)\n",
    "residual_814_backgr_R2,new_masked_img_R2r = remove_gal_steps(cmap_mask=cmap_maskr,filt=814,iso_galaxy=iso_R2r,backg_num=0.0005,data_image=residual_814_backgr_R1,new_mask=new_masked_img_BCG1r,plotyes=True)\n",
    "#20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model other galaxies around arc\n",
    "geom_R2g, ap_R2g, elli_R2g, iso_R2g, tabl_R2g = fit_gal_ellipse(cmap_mask=cmap_maskr,filt=606,x0_pos=(457+150)*data_factor,y0_pos=(198+150)*data_factor,sm_axis=7*data_factor,ellip=0.25,pos_ang=numpy.pi/3.,sigma_clip=3.0,fix_cent=False,data_image=residual_606_backgr_BCG1,new_mask=new_masked_img_BCG1g,integrmodee='median',num_clip=3,converg=0.05,max_gerr=0.5,max_sma=40*data_factor,min_it=10,f_flag=0.7,max_r_it=25*data_factor,fix_p_a=False,fix_el=False,plotyes=True)\n",
    "residual_606_backgr_R2,new_masked_img_R2g = remove_gal_steps(cmap_mask=cmap_maskr,filt=606,iso_galaxy=iso_R2g,backg_num=0.0001,data_image=residual_606_backgr_R1,new_mask=new_masked_img_BCG1g,plotyes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model other galaxies around arc\n",
    "geom_R2b, ap_R2b, elli_R2b, iso_R2b, tabl_R2b = fit_gal_ellipse(cmap_mask=cmap_maskr,filt=435,x0_pos=(457+151)*data_factor,y0_pos=(198+151)*data_factor,sm_axis=4*data_factor,ellip=0.1,pos_ang=numpy.pi/3.,sigma_clip=3.0,fix_cent=False,data_image=residual_435_backgr_BCG1,new_mask=new_masked_img_BCG1b,integrmodee='median',num_clip=3,converg=0.05,max_gerr=0.5,max_sma=40*data_factor,min_it=10,f_flag=0.7,max_r_it=25*data_factor,fix_p_a=False,fix_el=False,plotyes=True)\n",
    "residual_435_backgr_R2,new_masked_img_R2b = remove_gal_steps(cmap_mask=cmap_maskr,filt=435,iso_galaxy=iso_R2b,backg_num=0.,data_image=residual_435_backgr_R1,new_mask=new_masked_img_BCG1b,plotyes=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "L1 GALAXY:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model other galaxies around arc\n",
    "geom_L1r, ap_L1r, elli_L1r, iso_L1r, tabl_L1r = fit_gal_ellipse(cmap_mask=cmap_maskr,filt=814,x0_pos=(125+150)*data_factor,y0_pos=(295+150)*data_factor,sm_axis=7*data_factor,ellip=0,pos_ang=0,sigma_clip=3.0,fix_cent=False,data_image=residual_814_backgr_R2,new_mask=new_masked_img_R2r,integrmodee='median',num_clip=3,converg=0.05,max_gerr=0.5,max_sma=20*data_factor,min_it=10,f_flag=0.5,max_r_it=10*data_factor,fix_p_a=False,fix_el=False,plotyes=True)\n",
    "residual_814_backgr_L1,new_masked_img_L1r = remove_gal_steps(cmap_mask=cmap_maskr,filt=814,iso_galaxy=iso_L1r,backg_num=0.0005,data_image=residual_814_backgr_R2,new_mask=new_masked_img_R2r,plotyes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model other galaxies around arc\n",
    "geom_L1g, ap_L1g, elli_L1g, iso_L1g, tabl_L1g = fit_gal_ellipse(cmap_mask=cmap_maskr,filt=606,x0_pos=(125+150)*data_factor,y0_pos=(295+150)*data_factor,sm_axis=7*data_factor,ellip=0,pos_ang=0,sigma_clip=3.0,fix_cent=False,data_image=residual_606_backgr_R2,new_mask=new_masked_img_R2g,integrmodee='median',num_clip=3,converg=0.05,max_gerr=0.5,max_sma=20*data_factor,min_it=10,f_flag=0.5,max_r_it=10*data_factor,fix_p_a=False,fix_el=False,plotyes=True)\n",
    "residual_606_backgr_L1,new_masked_img_L1g = remove_gal_steps(cmap_mask=cmap_maskr,filt=606,iso_galaxy=iso_L1g,backg_num=0.0001,data_image=residual_606_backgr_R2,new_mask=new_masked_img_R2g,plotyes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model other galaxies around arc\n",
    "geom_L1b, ap_L1b, elli_L1b, iso_L1b, tabl_L1b = geom_R2b, ap_R2b, elli_R2b, iso_R2b, tabl_R2b#fit_gal_ellipse(cmap_mask=cmap_maskr,filt=435,x0_pos=(127+152)*data_factor,y0_pos=(293+152)*data_factor,sm_axis=3*data_factor,ellip=0,pos_ang=0,sigma_clip=2.0,fix_cent=True,data_image=residual_435_backgr_R2,new_mask=new_masked_img_R2b,integrmodee='median',num_clip=3,converg=0.05,max_gerr=0.5,max_sma=20*data_factor,min_it=10,f_flag=0.5,max_r_it=10*data_factor,fix_p_a=False,fix_el=False,plotyes=True)\n",
    "residual_435_backgr_L1,new_masked_img_L1b = residual_435_backgr_R2,new_masked_img_R2b#remove_gal_steps(cmap_mask=cmap_maskr,filt=435,iso_galaxy=iso_L1b,backg_num=0.,data_image=residual_435_backgr_R2,new_mask=new_masked_img_R2b,plotyes=True)\n",
    "#easier to just mask it later, not too extended"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "L2 GALAXY:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model other galaxies around arc\n",
    "geom_L2r, ap_L2r, elli_L2r, iso_L2r, tabl_L2r = fit_gal_ellipse(cmap_mask=cmap_maskr,filt=814,x0_pos=(140+150)*data_factor,y0_pos=(275+150)*data_factor,sm_axis=4*data_factor,ellip=0,pos_ang=0,sigma_clip=2.0,fix_cent=False,data_image=residual_814_backgr_L1,new_mask=new_masked_img_L1r,integrmodee='median',num_clip=3,converg=0.05,max_gerr=0.5,max_sma=25*data_factor,min_it=10,f_flag=0.3,max_r_it=5*data_factor,fix_p_a=True,fix_el=True,plotyes=True)\n",
    "residual_814_backgr_L2,new_masked_img_L2r = remove_gal_steps(cmap_mask=cmap_maskr,filt=814,iso_galaxy=iso_L2r,backg_num=0.0005,data_image=residual_814_backgr_L1,new_mask=new_masked_img_L1r,plotyes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model other galaxies around arc\n",
    "geom_L2g, ap_L2g, elli_L2g, iso_L2g, tabl_L2g = fit_gal_ellipse(cmap_mask=cmap_maskr,filt=606,x0_pos=(140+150)*data_factor,y0_pos=(275+150)*data_factor,sm_axis=4*data_factor,ellip=0,pos_ang=0,sigma_clip=2.0,fix_cent=False,data_image=residual_606_backgr_L1,new_mask=new_masked_img_L1g,integrmodee='median',num_clip=3,converg=0.05,max_gerr=0.5,max_sma=20*data_factor,min_it=10,f_flag=0.3,max_r_it=5*data_factor,fix_p_a=True,fix_el=True,plotyes=True)\n",
    "residual_606_backgr_L2,new_masked_img_L2g = remove_gal_steps(cmap_mask=cmap_maskr,filt=606,iso_galaxy=iso_L2g,backg_num=0.0001,data_image=residual_606_backgr_L1,new_mask=new_masked_img_L1g,plotyes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model other galaxies around arc\n",
    "geom_L2b, ap_L2b, elli_L2b, iso_L2b, tabl_L2b = geom_L1b, ap_L1b, elli_L1b, iso_L1b, tabl_L1b#fit_gal_ellipse(cmap_mask=cmap_maskr,filt=435,x0_pos=140+150,y0_pos=275+150,sm_axis=4,ellip=0,pos_ang=0,sigma_clip=2.0,fix_cent=False,data_image=residual_435_backgr_L1,new_mask=new_masked_img_L1b,integrmodee='median',num_clip=3,converg=0.05,max_gerr=0.5,max_sma=25,min_it=10,f_flag=0.3,max_r_it=5,fix_p_a=True,fix_el=True)\n",
    "residual_435_backgr_L2,new_masked_img_L2b = residual_435_backgr_L1,new_masked_img_L1b#remove_gal_steps(cmap_mask=cmap_maskr,filt=435,iso_galaxy=iso_L2b,backg_num=20,data_image=residual_435_backgr_L1,new_mask=new_masked_img_L1b)\n",
    "# nothing visible in this filter #most backgrounds from before are like 15"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "M1 GALAXY:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model other galaxies around arc\n",
    "geom_M1r, ap_M1r, elli_M1r, iso_M1r, tabl_M1r = fit_gal_ellipse(cmap_mask=cmap_maskr,filt=814,x0_pos=(264+150)*data_factor,y0_pos=(238+150)*data_factor,sm_axis=17*data_factor,ellip=0.65,pos_ang=5.5*numpy.pi/6.,sigma_clip=2.0,fix_cent=False,data_image=residual_814_backgr_L2,new_mask=new_masked_img_L2r,integrmodee='median',num_clip=3,converg=0.05,max_gerr=0.5,max_sma=50*data_factor,min_it=10,f_flag=0.5,max_r_it=100*data_factor,fix_p_a=False,fix_el=False,plotyes=True)\n",
    "residual_814_backgr_M1,new_masked_img_M1r = remove_gal_steps(cmap_mask=cmap_maskr,filt=814,iso_galaxy=iso_M1r,backg_num=0.0005,data_image=residual_814_backgr_L2,new_mask=new_masked_img_L2r,plotyes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model other galaxies around arc\n",
    "geom_M1g, ap_M1g, elli_M1g, iso_M1g, tabl_M1g = fit_gal_ellipse(cmap_mask=cmap_maskr,filt=606,x0_pos=(264+150)*data_factor,y0_pos=(238+150)*data_factor,sm_axis=17*data_factor,ellip=0.65,pos_ang=5.5*numpy.pi/6.,sigma_clip=2.0,fix_cent=True,data_image=residual_606_backgr_L2,new_mask=new_masked_img_L2g,integrmodee='median',num_clip=3,converg=0.05,max_gerr=0.5,max_sma=52*data_factor,min_it=10,f_flag=0.7,max_r_it=55*data_factor,fix_p_a=False,fix_el=False,plotyes=True)\n",
    "residual_606_backgr_M1,new_masked_img_M1g = remove_gal_steps(cmap_mask=cmap_maskr,filt=606,iso_galaxy=iso_M1g,backg_num=0.0001,data_image=residual_606_backgr_L2,new_mask=new_masked_img_L2g,plotyes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model other galaxies around arc\n",
    "geom_M1b, ap_M1b, elli_M1b, iso_M1b, tabl_M1b = fit_gal_ellipse(cmap_mask=cmap_maskr,filt=435,x0_pos=(264+150)*data_factor,y0_pos=(238+150)*data_factor,sm_axis=17*data_factor,ellip=0.65,pos_ang=5.5*numpy.pi/6.,sigma_clip=2.0,fix_cent=False,data_image=residual_435_backgr_L2,new_mask=new_masked_img_L2b,integrmodee='median',num_clip=3,converg=0.05,max_gerr=0.5,max_sma=45*data_factor,min_it=10,f_flag=0.5,max_r_it=100*data_factor,fix_p_a=False,fix_el=False,plotyes=True)\n",
    "residual_435_backgr_M1,new_masked_img_M1b = remove_gal_steps(cmap_mask=cmap_maskr,filt=435,iso_galaxy=iso_M1b,backg_num=0.,data_image=residual_435_backgr_L2,new_mask=new_masked_img_L2b,plotyes=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SM1 GALAXY:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model other galaxies around arc\n",
    "geom_SM1r, ap_SM1r, elli_SM1r, iso_SM1r, tabl_SM1r = fit_gal_ellipse(cmap_mask=cmap_maskr,filt=814,x0_pos=(250+150)*data_factor,y0_pos=(265+150)*data_factor,sm_axis=7.5*data_factor,ellip=0.5,pos_ang=numpy.pi/4.,sigma_clip=3.0,fix_cent=True,data_image=residual_814_backgr_M1,new_mask=new_masked_img_M1r,integrmodee='median',num_clip=3,converg=0.05,max_gerr=0.5,max_sma=30*data_factor,min_it=10,f_flag=0.3,max_r_it=35*data_factor,fix_p_a=False,fix_el=False,plotyes=True)\n",
    "residual_814_backgr_SM1,new_masked_img_SM1r = remove_gal_steps(cmap_mask=cmap_maskr,filt=814,iso_galaxy=iso_SM1r,backg_num=0.0005,data_image=residual_814_backgr_M1,new_mask=new_masked_img_M1r,plotyes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model other galaxies around arc\n",
    "geom_SM1g, ap_SM1g, elli_SM1g, iso_SM1g, tabl_SM1g = fit_gal_ellipse(cmap_mask=cmap_maskr,filt=606,x0_pos=(250+150)*data_factor,y0_pos=(265+150)*data_factor,sm_axis=7.5*data_factor,ellip=0.5,pos_ang=numpy.pi/4.,sigma_clip=3.0,fix_cent=True,data_image=residual_606_backgr_M1,new_mask=new_masked_img_M1g,integrmodee='median',num_clip=3,converg=0.05,max_gerr=0.5,max_sma=30*data_factor,min_it=10,f_flag=0.3,max_r_it=35*data_factor,fix_p_a=False,fix_el=False,plotyes=True)\n",
    "residual_606_backgr_SM1,new_masked_img_SM1g = remove_gal_steps(cmap_mask=cmap_maskr,filt=606,iso_galaxy=iso_SM1g,backg_num=0.0001,data_image=residual_606_backgr_M1,new_mask=new_masked_img_M1g,plotyes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model other galaxies around arc\n",
    "geom_SM1b, ap_SM1b, elli_SM1b, iso_SM1b, tabl_SM1b = geom_M1b, ap_M1b, elli_M1b, iso_M1b, tabl_M1b#fit_gal_ellipse(cmap_mask=cmap_maskr,filt=435,x0_pos=253+150,y0_pos=266+150,sm_axis=3,ellip=0.45,pos_ang=numpy.pi/5.,sigma_clip=3.0,fix_cent=True,data_image=residual_435_backgr_M1,new_mask=new_masked_img_M1b,integrmodee='median',num_clip=3,converg=0.05,max_gerr=0.5,max_sma=15,min_it=10,f_flag=0.7,max_r_it=20,fix_p_a=False,fix_el=False)\n",
    "residual_435_backgr_SM1,new_masked_img_SM1b = residual_435_backgr_M1,new_masked_img_M1b#remove_gal_steps(cmap_mask=cmap_maskr,filt=435,iso_galaxy=iso_SM1b,backg_num=18,data_image=residual_435_backgr_M1,new_mask=new_masked_img_M1b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SM2 GALAXY:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model other galaxies around arc\n",
    "geom_SM2r, ap_SM2r, elli_SM2r, iso_SM2r, tabl_SM2r = fit_gal_ellipse(cmap_mask=cmap_maskr,filt=814,x0_pos=(287+150)*data_factor,y0_pos=(242+150)*data_factor,sm_axis=3*data_factor,ellip=0,pos_ang=0,sigma_clip=2.0,fix_cent=False,data_image=residual_814_backgr_SM1,new_mask=new_masked_img_SM1r,integrmodee='median',num_clip=3,converg=0.05,max_gerr=0.5,max_sma=15*data_factor,min_it=10,f_flag=0.5,max_r_it=20*data_factor,fix_p_a=True,fix_el=True,plotyes=True)\n",
    "residual_814_backgr_SM2,new_masked_img_SM2r = remove_gal_steps(cmap_mask=cmap_maskr,filt=814,iso_galaxy=iso_SM2r,backg_num=0.0005,data_image=residual_814_backgr_SM1,new_mask=new_masked_img_SM1r,plotyes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model other galaxies around arc\n",
    "geom_SM2g, ap_SM2g, elli_SM2g, iso_SM2g, tabl_SM2g = fit_gal_ellipse(cmap_mask=cmap_maskr,filt=606,x0_pos=(287+150)*data_factor,y0_pos=(242+150)*data_factor,sm_axis=3*data_factor,ellip=0,pos_ang=0,sigma_clip=2.0,fix_cent=False,data_image=residual_606_backgr_SM1,new_mask=new_masked_img_SM1g,integrmodee='median',num_clip=3,converg=0.05,max_gerr=0.5,max_sma=15*data_factor,min_it=10,f_flag=0.5,max_r_it=20*data_factor,fix_p_a=True,fix_el=True,plotyes=True)\n",
    "residual_606_backgr_SM2,new_masked_img_SM2g = remove_gal_steps(cmap_mask=cmap_maskr,filt=606,iso_galaxy=iso_SM2g,backg_num=0.0001,data_image=residual_606_backgr_SM1,new_mask=new_masked_img_SM1g,plotyes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model other galaxies around arc\n",
    "geom_SM2b, ap_SM2b, elli_SM2b, iso_SM2b, tabl_SM2b = fit_gal_ellipse(cmap_mask=cmap_maskr,filt=435,x0_pos=(287+150)*data_factor,y0_pos=(242+150)*data_factor,sm_axis=3*data_factor,ellip=0,pos_ang=0,sigma_clip=2.0,fix_cent=False,data_image=residual_435_backgr_SM1,new_mask=new_masked_img_SM1b,integrmodee='median',num_clip=3,converg=0.05,max_gerr=0.5,max_sma=15*data_factor,min_it=10,f_flag=0.5,max_r_it=20*data_factor,fix_p_a=True,fix_el=True,plotyes=True)\n",
    "residual_435_backgr_SM2,new_masked_img_SM2b = remove_gal_steps(cmap_mask=cmap_maskr,filt=435,iso_galaxy=iso_SM2b,backg_num=0.,data_image=residual_435_backgr_SM1,new_mask=new_masked_img_SM1b,plotyes=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "C1 GALAXY:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model other galaxies around arc - put temporary mask on half that divides galaxy, then remove mask and use other mask - can just be standalone or update\n",
    "geom_C1r, ap_C1r, elli_C1r, iso_C1r, tabl_C1r = fit_gal_ellipse(cmap_mask=cmap_maskr,filt=814,x0_pos=(255+150)*data_factor,y0_pos=(222+150)*data_factor,sm_axis=3*data_factor,ellip=0,pos_ang=0,sigma_clip=3.0,fix_cent=True,data_image=residual_814_backgr_SM2,new_mask=new_masked_img_SM2r,integrmodee='median',num_clip=3,converg=0.05,max_gerr=0.5,max_sma=10*data_factor,min_it=10,f_flag=0.75,max_r_it=0.5*data_factor,fix_p_a=False,fix_el=True,plotyes=True)\n",
    "residual_814_backgr_C1,new_masked_img_C1r = remove_gal_steps(cmap_mask=cmap_maskr,filt=814,iso_galaxy=iso_C1r,backg_num=0.005,data_image=residual_814_backgr_SM2,new_mask=new_masked_img_SM2r,plotyes=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model other galaxies around arc - put temporary mask on half that divides galaxy, then remove mask and use other mask - can just be standalone or update\n",
    "geom_C1g, ap_C1g, elli_C1g, iso_C1g, tabl_C1g = fit_gal_ellipse(cmap_mask=cmap_maskr,filt=606,x0_pos=(255+150)*data_factor,y0_pos=(222+150)*data_factor,sm_axis=3*data_factor,ellip=0,pos_ang=0,sigma_clip=3.0,fix_cent=True,data_image=residual_606_backgr_SM2,new_mask=new_masked_img_SM2g,integrmodee='median',num_clip=3,converg=0.05,max_gerr=0.5,max_sma=10*data_factor,min_it=10,f_flag=0.75,max_r_it=0.5*data_factor,fix_p_a=False,fix_el=True,plotyes=True)\n",
    "residual_606_backgr_C1,new_masked_img_C1g = remove_gal_steps(cmap_mask=cmap_maskr,filt=606,iso_galaxy=iso_C1g,backg_num=0.001,data_image=residual_606_backgr_SM2,new_mask=new_masked_img_SM2g,plotyes=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model other galaxies around arc - put temporary mask on half that divides galaxy, then remove mask and use other mask - can just be standalone or update\n",
    "geom_C1b, ap_C1b, elli_C1b, iso_C1b, tabl_C1b = fit_gal_ellipse(cmap_mask=cmap_maskr,filt=435,x0_pos=(255+150)*data_factor,y0_pos=(222+150)*data_factor,sm_axis=3*data_factor,ellip=0,pos_ang=0,sigma_clip=3.0,fix_cent=True,data_image=residual_435_backgr_SM2,new_mask=new_masked_img_SM2b,integrmodee='median',num_clip=3,converg=0.05,max_gerr=0.5,max_sma=10*data_factor,min_it=10,f_flag=0.75,max_r_it=0.5*data_factor,fix_p_a=False,fix_el=True,plotyes=True)\n",
    "residual_435_backgr_C1,new_masked_img_C1b = remove_gal_steps(cmap_mask=cmap_maskr,filt=435,iso_galaxy=iso_C1b,backg_num=0.001,data_image=residual_435_backgr_SM2,new_mask=new_masked_img_SM2b,plotyes=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "C2 GALAXY:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model other galaxies around arc\n",
    "geom_C2r, ap_C2r, elli_C2r, iso_C2r, tabl_C2r = fit_gal_ellipse(cmap_mask=cmap_maskr,filt=814,x0_pos=(262+150)*data_factor,y0_pos=(220+150)*data_factor,sm_axis=3*data_factor,ellip=0,pos_ang=0,sigma_clip=2.0,fix_cent=True,data_image=residual_814_backgr_C1,new_mask=new_masked_img_C1r,integrmodee='median',num_clip=3,converg=0.05,max_gerr=0.5,max_sma=7*data_factor,min_it=10,f_flag=0.7,max_r_it=2*data_factor,fix_p_a=False,fix_el=False,plotyes=True)\n",
    "residual_814_backgr_C2,new_masked_img_C2r = remove_gal_steps(cmap_mask=cmap_maskr,filt=814,iso_galaxy=iso_C2r,backg_num=0.005,data_image=residual_814_backgr_C1,new_mask=new_masked_img_C1r,plotyes=True)\n",
    "#DO THIS AFTER SUBTRACTING OTHERS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model other galaxies around arc\n",
    "geom_C2g, ap_C2g, elli_C2g, iso_C2g, tabl_C2g = fit_gal_ellipse(cmap_mask=cmap_maskr,filt=606,x0_pos=(262+150)*data_factor,y0_pos=(220+150)*data_factor,sm_axis=3*data_factor,ellip=0,pos_ang=0,sigma_clip=2.0,fix_cent=True,data_image=residual_606_backgr_C1,new_mask=new_masked_img_C1g,integrmodee='median',num_clip=3,converg=0.05,max_gerr=0.5,max_sma=7*data_factor,min_it=10,f_flag=0.7,max_r_it=2*data_factor,fix_p_a=False,fix_el=False,plotyes=True)\n",
    "residual_606_backgr_C2,new_masked_img_C2g = remove_gal_steps(cmap_mask=cmap_maskr,filt=606,iso_galaxy=iso_C2g,backg_num=0.005,data_image=residual_606_backgr_C1,new_mask=new_masked_img_C1g,plotyes=True)\n",
    "#DO THIS AFTER SUBTRACTING OTHERS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model other galaxies around arc\n",
    "geom_C2b, ap_C2b, elli_C2b, iso_C2b, tabl_C2b = fit_gal_ellipse(cmap_mask=cmap_maskr,filt=435,x0_pos=(262+150)*data_factor,y0_pos=(220+150)*data_factor,sm_axis=3*data_factor,ellip=0,pos_ang=0,sigma_clip=2.0,fix_cent=True,data_image=residual_435_backgr_C1,new_mask=new_masked_img_C1b,integrmodee='median',num_clip=3,converg=0.05,max_gerr=0.5,max_sma=7*data_factor,min_it=10,f_flag=0.7,max_r_it=2*data_factor,fix_p_a=False,fix_el=False,plotyes=True)\n",
    "residual_435_backgr_C2,new_masked_img_C2b = remove_gal_steps(cmap_mask=cmap_maskr,filt=435,iso_galaxy=iso_C2b,backg_num=0.001,data_image=residual_435_backgr_C1,new_mask=new_masked_img_C1b,plotyes=True)\n",
    "#DO THIS AFTER SUBTRACTING OTHERS #these were all around 37"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "M2 GALAXY:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model other galaxies around arc\n",
    "geom_M2r, ap_M2r, elli_M2r, iso_M2r, tabl_M2r = fit_gal_ellipse(cmap_mask=cmap_maskr,filt=814,x0_pos=(350+150)*data_factor,y0_pos=(220+150)*data_factor,sm_axis=20*data_factor,ellip=0.7,pos_ang=numpy.pi/4.,sigma_clip=2.0,fix_cent=False,data_image=residual_814_backgr_C2,new_mask=new_masked_img_C2r,integrmodee='median',num_clip=3,converg=0.05,max_gerr=0.5,max_sma=42*data_factor,min_it=10,f_flag=0.3,max_r_it=55*data_factor,fix_p_a=False,fix_el=False,plotyes=True)\n",
    "residual_814_backgr_M2,new_masked_img_M2r = remove_gal_steps(cmap_mask=cmap_maskr,filt=814,iso_galaxy=iso_M2r,backg_num=0.0005,data_image=residual_814_backgr_C2,new_mask=new_masked_img_C2r,plotyes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model other galaxies around arc\n",
    "geom_M2g, ap_M2g, elli_M2g, iso_M2g, tabl_M2g = fit_gal_ellipse(cmap_mask=cmap_maskr,filt=606,x0_pos=(350+150)*data_factor,y0_pos=(220+150)*data_factor,sm_axis=20*data_factor,ellip=0.7,pos_ang=numpy.pi/4.,sigma_clip=2.0,fix_cent=False,data_image=residual_606_backgr_C2,new_mask=new_masked_img_C2g,integrmodee='median',num_clip=3,converg=0.05,max_gerr=0.5,max_sma=42*data_factor,min_it=10,f_flag=0.3,max_r_it=55*data_factor,fix_p_a=False,fix_el=False,plotyes=True)\n",
    "residual_606_backgr_M2,new_masked_img_M2g = remove_gal_steps(cmap_mask=cmap_maskr,filt=606,iso_galaxy=iso_M2g,backg_num=0.0001,data_image=residual_606_backgr_C2,new_mask=new_masked_img_C2g,plotyes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model other galaxies around arc\n",
    "geom_M2b, ap_M2b, elli_M2b, iso_M2b, tabl_M2b = fit_gal_ellipse(cmap_mask=cmap_maskr,filt=435,x0_pos=(350+150)*data_factor,y0_pos=(220+150)*data_factor,sm_axis=12*data_factor,ellip=0.7,pos_ang=numpy.pi/4.,sigma_clip=3.0,fix_cent=True,data_image=residual_435_backgr_C2,new_mask=new_masked_img_C2b,integrmodee='median',num_clip=3,converg=0.05,max_gerr=0.5,max_sma=40*data_factor,min_it=10,f_flag=0.3,max_r_it=50*data_factor,fix_p_a=False,fix_el=False,plotyes=True)\n",
    "residual_435_backgr_M2,new_masked_img_M2b = remove_gal_steps(cmap_mask=cmap_maskr,filt=435,iso_galaxy=iso_M2b,backg_num=0.,data_image=residual_435_backgr_C2,new_mask=new_masked_img_C2b,plotyes=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "T1 GALAXY:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model other galaxies around arc\n",
    "geom_T1r, ap_T1r, elli_T1r, iso_T1r, tabl_T1r = fit_gal_ellipse(cmap_mask=cmap_maskr,filt=814,x0_pos=(430+150)*data_factor,y0_pos=(270+150)*data_factor,sm_axis=20*data_factor,ellip=0.5,pos_ang=5.5*numpy.pi/6.,sigma_clip=2.0,fix_cent=False,data_image=residual_814_backgr_M2,new_mask=new_masked_img_M2r,integrmodee='median',num_clip=3,converg=0.05,max_gerr=0.5,max_sma=75*data_factor,min_it=10,f_flag=0.3,max_r_it=125*data_factor,fix_p_a=False,fix_el=False,plotyes=True)\n",
    "residual_814_backgr_T1,new_masked_img_T1r = remove_gal_steps(cmap_mask=cmap_maskr,filt=814,iso_galaxy=iso_T1r,backg_num=0.0005,data_image=residual_814_backgr_M2,new_mask=new_masked_img_M2r,plotyes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model other galaxies around arc\n",
    "geom_T1g, ap_T1g, elli_T1g, iso_T1g, tabl_T1g = fit_gal_ellipse(cmap_mask=cmap_maskr,filt=606,x0_pos=(430+150)*data_factor,y0_pos=(270+150)*data_factor,sm_axis=20*data_factor,ellip=0.5,pos_ang=5.5*numpy.pi/6.,sigma_clip=2.0,fix_cent=True,data_image=residual_606_backgr_M2,new_mask=new_masked_img_M2g,integrmodee='median',num_clip=3,converg=0.05,max_gerr=0.5,max_sma=70*data_factor,min_it=10,f_flag=0.5,max_r_it=100*data_factor,fix_p_a=False,fix_el=False,plotyes=True)\n",
    "residual_606_backgr_T1,new_masked_img_T1g = remove_gal_steps(cmap_mask=cmap_maskr,filt=606,iso_galaxy=iso_T1g,backg_num=0.0001,data_image=residual_606_backgr_M2,new_mask=new_masked_img_M2g,plotyes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model other galaxies around arc\n",
    "geom_T1b, ap_T1b, elli_T1b, iso_T1b, tabl_T1b = fit_gal_ellipse(cmap_mask=cmap_maskr,filt=435,x0_pos=(430+150)*data_factor,y0_pos=(270+150)*data_factor,sm_axis=15*data_factor,ellip=0.5,pos_ang=5.5*numpy.pi/6.,sigma_clip=3.0,fix_cent=True,data_image=residual_435_backgr_M2,new_mask=new_masked_img_M2b,integrmodee='median',num_clip=3,converg=0.05,max_gerr=0.5,max_sma=70*data_factor,min_it=10,f_flag=0.5,max_r_it=100*data_factor,fix_p_a=False,fix_el=False,plotyes=True)\n",
    "residual_435_backgr_T1,new_masked_img_T1b = remove_gal_steps(cmap_mask=cmap_maskr,filt=435,iso_galaxy=iso_T1b,backg_num=0.,data_image=residual_435_backgr_M2,new_mask=new_masked_img_M2b,plotyes=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "COMPILED MASKS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(Image.mode(imb))\n",
    "# print(Image.mode(residual_435_backgr_T1))\n",
    "\n",
    "# print(type(imb))\n",
    "# print(type(residual_435_backgr_T1))\n",
    "# print(type(RGB[1].data))\n",
    "# print(type(imb_arc))\n",
    "\n",
    "# print(imb)\n",
    "# print(residual_435_backgr_T1)\n",
    "# print(RGB[1].data)\n",
    "# print(imb_arc)\n",
    "\n",
    "\n",
    "#rename so do not need to rerun\n",
    "residual_814_backgr_total = residual_814_backgr_T1\n",
    "residual_606_backgr_total = residual_606_backgr_T1\n",
    "residual_435_backgr_total = residual_435_backgr_T1\n",
    "\n",
    "\n",
    "\n",
    "#turn into PIL Image object, then merge into an RGB image\n",
    "imr_arc=Image.fromarray(residual_814_backgr_total.astype(numpy.uint8),mode=\"L\") \n",
    "img_arc=Image.fromarray(residual_606_backgr_total.astype(numpy.uint8),mode=\"L\") \n",
    "imb_arc=Image.fromarray(residual_435_backgr_total.astype(numpy.uint8),mode=\"L\") \n",
    "\n",
    "\n",
    "#https://stackoverflow.com/questions/58170901/how-to-save-2d-float-numpy-arrays-losslessly-into-a-grayscale-image-while-preser\n",
    "#https://stackoverflow.com/questions/26918390/python-make-rgb-image-from-3-float32-numpy-arrays\n",
    "#https://stackoverflow.com/questions/26681756/how-to-convert-a-python-numpy-array-to-an-rgb-image-with-opencv-2-4\n",
    "\n",
    "\n",
    "merged_RGB_arc=Image.merge(\"RGB\",(imr_arc,img_arc,imb_arc))\n",
    "# Plot it\n",
    "figure(figsize=(15,15))\n",
    "imshow(merged_RGB_arc, origin='lower')\n",
    "\n",
    "#https://ui.adsabs.harvard.edu/abs/2014MNRAS.445..694T/abstract"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SAVE AS FITS REWRITTEN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#trying to save as FITS rewrite\n",
    "arc_edge_cutout_red_read[0].data = residual_814_backgr_T1\n",
    "arc_edge_cutout_green_read[0].data = residual_606_backgr_T1\n",
    "arc_edge_cutout_blue_read[0].data = residual_435_backgr_T1\n",
    "\n",
    "\n",
    "arc_edge_cutout_red_read.writeto('/mnt/c/Users/lana-/Desktop/arc_814.fits',overwrite=True)\n",
    "arc_edge_cutout_green_read.writeto('/mnt/c/Users/lana-/Desktop/arc_606.fits',overwrite=True)\n",
    "arc_edge_cutout_blue_read.writeto('/mnt/c/Users/lana-/Desktop/arc_435.fits',overwrite=True)\n",
    "\n",
    "#https://docs.astropy.org/en/stable/io/fits/api/files.html#astropy.io.fits.writeto\n",
    "#https://docs.astropy.org/en/stable/io/fits/index.html\n",
    "#https://github.com/JuliaAstro/FITSIO.jl/issues/116\n",
    "\n",
    "#now trim and make a smaller cutout for pixsrc\n",
    "#save_cutout_image(position, size, filter_color, name_cutout)\n",
    "\n",
    "\n",
    "\n",
    "#rewrote, now need to save as new FITS file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#try to rewrite and save as new FITS file in the RGB format so can plot as RGB image\n",
    "\n",
    "abell370_color = fits.open('abell370_RGB.fits')\n",
    "\n",
    "#change R/G/B arrays\n",
    "abell370_color[1].data=residual_814_backgr_T1\n",
    "abell370_color[2].data=residual_606_backgr_T1\n",
    "abell370_color[3].data=residual_435_backgr_T1\n",
    "\n",
    "abell370_color.writeto('/mnt/c/Users/lana-/Desktop/test_RGB.fits',overwrite=True)\n",
    "\n",
    "\n",
    "#this did not work - next try using an empty copied array or something, there was that one post\n",
    "\n",
    "# Read in RGB file\n",
    "test_RGB = fits.open('/mnt/c/Users/lana-/Desktop/test_RGB.fits')\n",
    "# Put separate extensions into own R/G/B arrays\n",
    "imr_arc=Image.fromarray(((test_RGB[1].data*255).round()/255).round().astype(numpy.uint8),mode=\"L\")\n",
    "img_arc=Image.fromarray(((test_RGB[2].data*255).round()/255).round().astype(numpy.uint8),mode=\"L\")\n",
    "imb_arc=Image.fromarray(((test_RGB[3].data*255).round()/255).round().astype(numpy.uint8),mode=\"L\")\n",
    "\n",
    "#What is the range of values in the FITS file? Images have hex RGB values, \n",
    "#meaning that R G and B take on integer values from 0 to 255 (which is why you have to convert to uint8). \n",
    "#If the FITS arrays go from 0 to 1 for example, you'll need to multiply by 255 before converting to integers. \n",
    "\n",
    "# Merge them back into one image\n",
    "merged_arc=Image.merge(\"RGB\",(imr_arc,img_arc,imb_arc))\n",
    "# Plot it\n",
    "# fig = figure(figsize=(15,15))\n",
    "# imshow(merged_arc, origin='lower')\n",
    "\n",
    "\n",
    "# print(type(imr))\n",
    "# print(type(imr_arc))\n",
    "# print(type(residual_814_backgr_total))\n",
    "# print(type(abell370_color[1].data))\n",
    "# print(type(residual_814_backgr_T1))\n",
    "# print(type(arc_edge_cutout_red_read[0].data))\n",
    "# print(type(merged))\n",
    "# print(type(merged_arc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://aplpy.readthedocs.io/en/stable/rgb.html\n",
    "aplpy.make_rgb_cube(['/mnt/c/Users/lana-/Desktop/arc_814.fits','/mnt/c/Users/lana-/Desktop/arc_606.fits','/mnt/c/Users/lana-/Desktop/arc_435.fits'],'/mnt/c/Users/lana-/Desktop/arc_rgb_cube.fits')\n",
    "aplpy.make_rgb_image('/mnt/c/Users/lana-/Desktop/arc_rgb_cube.fits','/mnt/c/Users/lana-/Desktop/test_rgb.png', vmin_r=0.,vmin_g=0.,vmin_b=0.,vmax_r=150.,vmax_g=150.,vmax_b=150.)\n",
    "# f = aplpy.FITSFigure('/mnt/c/Users/lana-/Desktop/arc_rgb_cube.fits')\n",
    "# f.show_rgb('/mnt/c/Users/lana-/Desktop/test_rgb.png')\n",
    "\n",
    "aplpy.make_rgb_cube(['/mnt/c/Users/lana-/Desktop/cutout_red_full.fits','/mnt/c/Users/lana-/Desktop/cutout_green_full.fits','/mnt/c/Users/lana-/Desktop/cutout_blue_full.fits'],'/mnt/c/Users/lana-/Desktop/arc_rgb_unedited_cube.fits')\n",
    "aplpy.make_rgb_image('/mnt/c/Users/lana-/Desktop/arc_rgb_unedited_cube.fits','/mnt/c/Users/lana-/Desktop/unedited_rgb.png', vmin_r=0.,vmin_g=0.,vmin_b=0.,vmax_r=150.,vmax_g=150.,vmax_b=150.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save cutout image for this thing\n",
    "#this one right here\n",
    "\n",
    "# fits.delval('/mnt/c/Users/lana-/Desktop/arc_814.fits','PC1_1')\n",
    "# fits.delval('/mnt/c/Users/lana-/Desktop/arc_814.fits','PC1_2')\n",
    "# fits.delval('/mnt/c/Users/lana-/Desktop/arc_814.fits','PC2_1')\n",
    "# fits.delval('/mnt/c/Users/lana-/Desktop/arc_814.fits','PC2_2')\n",
    "\n",
    "# fits.delval('/mnt/c/Users/lana-/Desktop/arc_606.fits','PC1_1')\n",
    "# fits.delval('/mnt/c/Users/lana-/Desktop/arc_606.fits','PC1_2')\n",
    "# fits.delval('/mnt/c/Users/lana-/Desktop/arc_606.fits','PC2_1')\n",
    "# fits.delval('/mnt/c/Users/lana-/Desktop/arc_606.fits','PC2_2')\n",
    "\n",
    "# fits.delval('/mnt/c/Users/lana-/Desktop/arc_435.fits','PC1_1')\n",
    "# fits.delval('/mnt/c/Users/lana-/Desktop/arc_435.fits','PC1_2')\n",
    "# fits.delval('/mnt/c/Users/lana-/Desktop/arc_435.fits','PC2_1')\n",
    "# fits.delval('/mnt/c/Users/lana-/Desktop/arc_435.fits','PC2_2')\n",
    "\n",
    "def save_cutout_im(position, size, filter_num, name_cutout):\n",
    "\n",
    "    hdu_orig = fits.open('/mnt/c/Users/lana-/Desktop/arc_'+str(filter_num)+'.fits')[0]\n",
    "    hdu_orig.header['CRPIX1'] = 975.0\n",
    "    hdu_orig.header['CRPIX2'] = 150.0\n",
    "    hdu_orig.header['CD1_1'] = -1.6666666666666E-05\n",
    "    hdu_orig.header['CD1_2'] = 8.47032947254300E-22\n",
    "    hdu_orig.header['CD2_1'] = 8.47032947254300E-22\n",
    "    hdu_orig.header['CD2_2'] = 1.6666666666666E-05\n",
    "    hdu_orig.writeto('/mnt/c/Users/lana-/Desktop/arc_'+str(filter_num)+'.fits', overwrite=True)\n",
    "\n",
    "    # Load the original RGB image and the WCS\n",
    "    hdu_orig = fits.open('/mnt/c/Users/lana-/Desktop/cutout_red_full.fits')[0]\n",
    "    wcs_orig = WCS(hdu_orig.header)\n",
    "\n",
    "    # Load the filter image and the WCS\n",
    "    hdu = fits.open('/mnt/c/Users/lana-/Desktop/arc_'+str(filter_num)+'.fits')[0]\n",
    "    wcs = WCS(hdu.header)\n",
    "\n",
    "    # Make the cutout, including the WCS\n",
    "    cutout = Cutout2D(hdu.data, position=position, size=size, wcs=wcs_orig)\n",
    "\n",
    "    # Put the cutout image in the FITS HDU\n",
    "    hdu.data = cutout.data\n",
    "\n",
    "    # Update the FITS header with the cutout WCS\n",
    "    hdu.header.update(cutout.wcs.to_header()) #this has coordinate info that gets put into the new header\n",
    "    #hdu.header = hdu_orig.header #this manages to copy over everything, which is not what I need to do\n",
    "\n",
    "    #copy over the header info\n",
    "    # header_old = hdu_orig.header\n",
    "    # hdu.header = hdu_orig.header\n",
    "    #cutout.header = hdu.header\n",
    "\n",
    "    # Write the cutout to a new FITS file\n",
    "    hdu.writeto('/mnt/c/Users/lana-/Desktop/'+str(name_cutout)+'.fits', overwrite=True)\n",
    "    \n",
    "\n",
    "arc_pix_cutout_r = save_cutout_im(position=(480,400), size=(250,600), filter_num='814', name_cutout='arc_pix_814')\n",
    "arc_pix_cutout_g = save_cutout_im(position=(480,400), size=(250,600), filter_num='606', name_cutout='arc_pix_606')\n",
    "arc_pix_cutout_b = save_cutout_im(position=(480,400), size=(250,600), filter_num='435', name_cutout='arc_pix_435')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#now make arc RGB\n",
    "aplpy.make_rgb_cube(['/mnt/c/Users/lana-/Desktop/arc_pix_814.fits','/mnt/c/Users/lana-/Desktop/arc_pix_606.fits','/mnt/c/Users/lana-/Desktop/arc_pix_435.fits'],'/mnt/c/Users/lana-/Desktop/arc_pix_rgb_cube.fits')\n",
    "aplpy.make_rgb_image('/mnt/c/Users/lana-/Desktop/arc_pix_rgb_cube.fits','/mnt/c/Users/lana-/Desktop/arc_pix_rgb.png', vmin_r=0.,vmin_g=0.,vmin_b=0.,vmax_r=255.,vmax_g=255.,vmax_b=255.)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Statistics of Pixels in Removed Areas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#statistical analysis of all the pixels - should be similar in regions removed vs blank space\n",
    "\n",
    "#first set up two regions - from where BCG1 removed vs. from blank space\n",
    "\n",
    "#arrays to loop through are:\n",
    "#residual_814_backgr_total\n",
    "#residual_606_backgr_total\n",
    "#residual_435_backgr_total\n",
    "\n",
    "#blank space from removed area:\n",
    "#x:450-550\n",
    "#y:650-750\n",
    "#blank space in space:\n",
    "#x:0-100\n",
    "#y:200-300\n",
    "\n",
    "#next do mean / standard deviation / variance of each\n",
    "\n",
    "#need to calculate mean\n",
    "#red\n",
    "removed_arr_r = numpy.zeros(10000)\n",
    "blank_arr_r = numpy.zeros(10000)\n",
    "removed_arr_tot_r = 0\n",
    "blank_arr_tot_r = 0\n",
    "#green\n",
    "removed_arr_g = numpy.zeros(10000)\n",
    "blank_arr_g = numpy.zeros(10000)\n",
    "removed_arr_tot_g = 0\n",
    "blank_arr_tot_g = 0\n",
    "#blue\n",
    "removed_arr_b = numpy.zeros(10000)\n",
    "blank_arr_b = numpy.zeros(10000)\n",
    "removed_arr_tot_b = 0\n",
    "blank_arr_tot_b = 0\n",
    "#count?\n",
    "count_index = -1\n",
    "\n",
    "#loop through each one so can calculate mean\n",
    "\n",
    "for i in range(100):\n",
    "\n",
    "    for j in range(100):\n",
    "\n",
    "        count_index = count_index + 1\n",
    "        #red\n",
    "        removed_arr_tot_r = removed_arr_tot_r + residual_814_backgr_total[450+i][500+j]\n",
    "        blank_arr_tot_r = blank_arr_tot_r + residual_814_backgr_total[175+i][875+j]\n",
    "        #set up for later\n",
    "        removed_arr_r[count_index] = residual_814_backgr_total[450+i][500+j]\n",
    "        blank_arr_r[count_index] = residual_814_backgr_total[175+i][875+j]\n",
    "\n",
    "        #green\n",
    "        removed_arr_tot_g = removed_arr_tot_g + residual_606_backgr_total[450+i][500+j]\n",
    "        blank_arr_tot_g = blank_arr_tot_g + residual_606_backgr_total[175+i][875+j]\n",
    "        #set up for later\n",
    "        removed_arr_g[count_index] = residual_606_backgr_total[450+i][500+j]\n",
    "        blank_arr_g[count_index] = residual_606_backgr_total[175+i][875+j]\n",
    "\n",
    "        #blue\n",
    "        removed_arr_tot_b = removed_arr_tot_b + residual_435_backgr_total[450+i][500+j]\n",
    "        blank_arr_tot_b = blank_arr_tot_b + residual_435_backgr_total[175+i][875+j]\n",
    "        #set up for later\n",
    "        removed_arr_b[count_index] = residual_435_backgr_total[450+i][500+j]\n",
    "        blank_arr_b[count_index] = residual_435_backgr_total[175+i][875+j]\n",
    "\n",
    "mean_red_removed = removed_arr_tot_r/10000\n",
    "mean_red_blank = blank_arr_tot_r/10000\n",
    "mean_green_removed = removed_arr_tot_g/10000\n",
    "mean_green_blank = blank_arr_tot_g/10000\n",
    "mean_blue_removed = removed_arr_tot_b/10000\n",
    "mean_blue_blank = blank_arr_tot_b/10000\n",
    "print(\"mean_red_removed:\",mean_red_removed)\n",
    "print(\"mean_red_blank:\",mean_red_blank)\n",
    "print(\"mean_green_removed:\",mean_green_removed)\n",
    "print(\"mean_green_blank:\",mean_green_blank)\n",
    "print(\"mean_blue_removed:\",mean_blue_removed)\n",
    "print(\"mean_blue_blank:\",mean_blue_blank)\n",
    "# print(removed_arr_r)\n",
    "# print(removed_arr_g)\n",
    "# print(removed_arr_b)\n",
    "# print(blank_arr_r)\n",
    "# print(blank_arr_g)\n",
    "# print(blank_arr_b)\n",
    "#ok so the indices are backwards, as I have to keep reminding myself\n",
    "# print(residual_814_backgr_total[200][300])\n",
    "# print(residual_814_backgr_total[300][200])\n",
    "\n",
    "#standard deviation\n",
    "sum_mean_sq_diff_rem_r = 0\n",
    "sum_mean_sq_diff_blank_r = 0\n",
    "sum_mean_sq_diff_rem_g = 0\n",
    "sum_mean_sq_diff_blank_g = 0\n",
    "sum_mean_sq_diff_rem_b = 0\n",
    "sum_mean_sq_diff_blank_b = 0\n",
    "for i in range(100):\n",
    "    for j in range(100):\n",
    "        #red\n",
    "        sum_mean_sq_diff_rem_r = sum_mean_sq_diff_rem_r + ((residual_814_backgr_total[450+i][500+j] - mean_red_removed)**2)\n",
    "        sum_mean_sq_diff_blank_r = sum_mean_sq_diff_blank_r + ((residual_814_backgr_total[175+i][875+j] - mean_red_blank)**2)\n",
    "        #green\n",
    "        sum_mean_sq_diff_rem_g = sum_mean_sq_diff_rem_g + ((residual_606_backgr_total[450+i][500+j] - mean_green_removed)**2)\n",
    "        sum_mean_sq_diff_blank_g = sum_mean_sq_diff_blank_g + ((residual_606_backgr_total[175+i][875+j] - mean_green_blank)**2)\n",
    "        #blue\n",
    "        sum_mean_sq_diff_rem_b = sum_mean_sq_diff_rem_b + ((residual_435_backgr_total[450+i][500+j] - mean_blue_removed)**2)\n",
    "        sum_mean_sq_diff_blank_b = sum_mean_sq_diff_blank_b + ((residual_435_backgr_total[175+i][875+j] - mean_blue_blank)**2)\n",
    "\n",
    "\n",
    "st_dev_rem_red = numpy.sqrt(sum_mean_sq_diff_rem_r/(10000))\n",
    "st_dev_blank_red = numpy.sqrt(sum_mean_sq_diff_blank_r/(10000))\n",
    "st_dev_rem_green = numpy.sqrt(sum_mean_sq_diff_rem_g/(10000))\n",
    "st_dev_blank_green = numpy.sqrt(sum_mean_sq_diff_blank_g/(10000))\n",
    "st_dev_rem_blue = numpy.sqrt(sum_mean_sq_diff_rem_b/(10000))\n",
    "st_dev_blank_blue = numpy.sqrt(sum_mean_sq_diff_blank_b/(10000))\n",
    "print(\"st_dev_rem_red:\",st_dev_rem_red)\n",
    "print(\"st_dev_blank_red:\",st_dev_blank_red)\n",
    "print(\"st_dev_rem_green:\",st_dev_rem_green)\n",
    "print(\"st_dev_blank_green:\",st_dev_blank_green)\n",
    "print(\"st_dev_rem_blue:\",st_dev_rem_blue)\n",
    "print(\"st_dev_blank_blue:\",st_dev_blank_blue)\n",
    "\n",
    "#variance\n",
    "var_rem_red = st_dev_rem_red**2\n",
    "var_blank_red = st_dev_blank_red**2\n",
    "var_rem_green = st_dev_rem_green**2\n",
    "var_blank_green = st_dev_blank_green**2\n",
    "var_rem_blue = st_dev_rem_blue**2\n",
    "var_blank_blue = st_dev_blank_blue**2\n",
    "print(\"var_rem_red:\",var_rem_red)\n",
    "print(\"var_blank_red:\",var_blank_red)\n",
    "print(\"var_rem_green:\",var_rem_green)\n",
    "print(\"var_blank_green:\",var_blank_green)\n",
    "print(\"var_rem_blue:\",var_rem_blue)\n",
    "print(\"var_blank_blue:\",var_blank_blue)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plots\n",
    "\n",
    "x_ar = numpy.arange(100000)/1000\n",
    "\n",
    "#mean arrays\n",
    "mean_line_rem_red = (x_ar*0)+mean_red_removed\n",
    "mean_line_blank_red = (x_ar*0)+mean_red_blank\n",
    "mean_line_rem_green = (x_ar*0)+mean_green_removed\n",
    "mean_line_blank_green = (x_ar*0)+mean_green_blank\n",
    "mean_line_rem_blue = (x_ar*0)+mean_blue_removed\n",
    "mean_line_blank_blue = (x_ar*0)+mean_blue_blank\n",
    "#standard deviation arrays\n",
    "sigma_rem_red_u = mean_line_rem_red + st_dev_rem_red\n",
    "sigma_rem_red_l = mean_line_rem_red - st_dev_rem_red\n",
    "sigma_blank_red_u = mean_line_blank_red + st_dev_blank_red\n",
    "sigma_blank_red_l = mean_line_blank_red - st_dev_blank_red\n",
    "sigma_rem_green_u = mean_line_rem_green + st_dev_rem_green\n",
    "sigma_rem_green_l = mean_line_rem_green - st_dev_rem_green\n",
    "sigma_blank_green_u = mean_line_blank_green + st_dev_blank_green\n",
    "sigma_blank_green_l = mean_line_blank_green - st_dev_blank_green\n",
    "sigma_rem_blue_u = mean_line_rem_blue + st_dev_rem_red\n",
    "sigma_rem_blue_l = mean_line_rem_blue - st_dev_rem_red\n",
    "sigma_blank_blue_u = mean_line_blank_blue + st_dev_blank_blue\n",
    "sigma_blank_blue_l = mean_line_blank_blue - st_dev_blank_blue\n",
    "\n",
    "\n",
    "#red plot!\n",
    "figure(figsize=(10,7.5))\n",
    "#plot histogram\n",
    "hist(removed_arr_r, bins=15, density=True, color=\"orange\", alpha=0.75, label=\"removed\")\n",
    "hist(blank_arr_r, bins=15, density=True, color=\"palevioletred\", alpha=0.75, label=\"blank\")\n",
    "#plot gaussian with same statistics\n",
    "gauss_rem_red = numpy.exp(-0.5*(((x_ar-mean_red_removed)**2)/(st_dev_rem_red**2)))*(1/(st_dev_rem_red*numpy.sqrt(2*numpy.pi)))\n",
    "gauss_blank_red = numpy.exp(-0.5*(((x_ar-mean_red_blank)**2)/(st_dev_blank_red**2)))*(1/(st_dev_blank_red*numpy.sqrt(2*numpy.pi)))\n",
    "plot(x_ar, gauss_rem_red, color=\"red\")\n",
    "plot(x_ar, gauss_blank_red, color=\"magenta\")\n",
    "#lines\n",
    "plot(mean_line_rem_red,x_ar,color=\"red\",label=r\"$\\mu$=\"+str(mean_red_removed),alpha=0.5)\n",
    "plot(sigma_rem_red_u,x_ar,color=\"red\",linestyle=\"dashed\",label=r\"$\\sigma$=\"+str(st_dev_rem_red),alpha=0.5)\n",
    "plot(sigma_rem_red_l,x_ar,color=\"red\",linestyle=\"dashed\",alpha=0.5)\n",
    "plot(mean_line_blank_red,x_ar,color=\"magenta\",label=r\"$\\mu$=\"+str(mean_red_blank),alpha=0.5)\n",
    "plot(sigma_blank_red_u,x_ar,color=\"magenta\",linestyle=\"dashed\",label=r\"$\\sigma$=\"+str(st_dev_blank_red),alpha=0.5)\n",
    "plot(sigma_blank_red_l,x_ar,color=\"magenta\",linestyle=\"dashed\",alpha=0.5)\n",
    "#plot formatting\n",
    "legend(loc='upper right')\n",
    "xlabel(r\"Pixel\")\n",
    "# ylabel(r\"Value\")\n",
    "xlim(-5,40)\n",
    "ylim(0,0.35)\n",
    "title(r\"F814W Pixels in Removed vs. Blank Square\")\n",
    "\n",
    "#green plot!\n",
    "figure(figsize=(10,7.5))\n",
    "#plot histogram\n",
    "hist(removed_arr_g, bins=35, density=True, color=\"lime\", alpha=0.5, label=\"removed\")\n",
    "hist(blank_arr_g, bins=17, density=True, color=\"yellow\", alpha=0.5, label=\"blank\")\n",
    "#plot gaussian with same statistics\n",
    "gauss_rem_green = numpy.exp(-0.5*(((x_ar-mean_green_removed)**2)/(st_dev_rem_green**2)))*(1/(st_dev_rem_green*numpy.sqrt(2*numpy.pi)))\n",
    "gauss_blank_green = numpy.exp(-0.5*(((x_ar-mean_green_blank)**2)/(st_dev_blank_green**2)))*(1/(st_dev_blank_green*numpy.sqrt(2*numpy.pi)))\n",
    "plot(x_ar, gauss_rem_green, color=\"green\")\n",
    "plot(x_ar, gauss_blank_green, color=\"orange\")\n",
    "#lines\n",
    "plot(mean_line_rem_green,x_ar,color=\"green\",label=r\"$\\mu$=\"+str(mean_green_removed),alpha=0.5)\n",
    "plot(sigma_rem_green_u,x_ar,color=\"green\",linestyle=\"dashed\",label=r\"$\\sigma$=\"+str(st_dev_rem_green),alpha=0.5)\n",
    "plot(sigma_rem_green_l,x_ar,color=\"green\",linestyle=\"dashed\",alpha=0.5)\n",
    "plot(mean_line_blank_green,x_ar,color=\"orange\",label=r\"$\\mu$=\"+str(mean_green_blank),alpha=0.5)\n",
    "plot(sigma_blank_green_u,x_ar,color=\"orange\",linestyle=\"dashed\",label=r\"$\\sigma$=\"+str(st_dev_blank_green),alpha=0.5)\n",
    "plot(sigma_blank_green_l,x_ar,color=\"orange\",linestyle=\"dashed\",alpha=0.5)\n",
    "#plot formatting\n",
    "legend(loc='upper right')\n",
    "xlabel(r\"Pixel\")\n",
    "# ylabel(r\"Value\")\n",
    "xlim(-5,40)\n",
    "ylim(0,0.25)\n",
    "title(r\"F606W Pixels in Removed vs. Blank Square\")\n",
    "\n",
    "#blue plot!\n",
    "figure(figsize=(10,7.5))\n",
    "#plot histogram\n",
    "hist(removed_arr_b, bins=15, density=True, color=\"dodgerblue\", alpha=0.75, label=\"removed\")\n",
    "hist(blank_arr_b, bins=15, density=True, color=\"aqua\", alpha=0.5, label=\"blank\")\n",
    "#plot gaussian with same statistics\n",
    "gauss_rem_blue = numpy.exp(-0.5*(((x_ar-mean_blue_removed)**2)/(st_dev_rem_blue**2)))*(1/(st_dev_rem_blue*numpy.sqrt(2*numpy.pi)))\n",
    "gauss_blank_blue = numpy.exp(-0.5*(((x_ar-mean_blue_blank)**2)/(st_dev_blank_blue**2)))*(1/(st_dev_blank_blue*numpy.sqrt(2*numpy.pi)))\n",
    "plot(x_ar, gauss_rem_blue, color=\"blue\")\n",
    "plot(x_ar, gauss_blank_blue, color=\"lightseagreen\")\n",
    "#lines\n",
    "plot(mean_line_rem_blue,x_ar,color=\"blue\",label=r\"$\\mu$=\"+str(mean_blue_removed),alpha=0.5)\n",
    "plot(sigma_rem_blue_u,x_ar,color=\"blue\",linestyle=\"dashed\",label=r\"$\\sigma$=\"+str(st_dev_rem_blue),alpha=0.5)\n",
    "plot(sigma_rem_blue_l,x_ar,color=\"blue\",linestyle=\"dashed\",alpha=0.5)\n",
    "plot(mean_line_blank_blue,x_ar,color=\"lightseagreen\",label=r\"$\\mu$=\"+str(mean_blue_blank),alpha=0.5)\n",
    "plot(sigma_blank_blue_u,x_ar,color=\"lightseagreen\",linestyle=\"dashed\",label=r\"$\\sigma$=\"+str(st_dev_blank_blue),alpha=0.5)\n",
    "plot(sigma_blank_blue_l,x_ar,color=\"lightseagreen\",linestyle=\"dashed\",alpha=0.5)\n",
    "#plot formatting\n",
    "legend(loc='upper right')\n",
    "xlabel(r\"Pixel\")\n",
    "# ylabel(r\"Value\")\n",
    "xlim(-40,80)\n",
    "ylim(0,0.175)\n",
    "title(r\"F435W Pixels in Removed vs. Blank Square\")\n",
    "\n",
    "\n",
    "\n",
    "#was 750 and 700\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #need to plot the squares used\n",
    "line_val = numpy.arange(100)\n",
    "\n",
    "# #RED\n",
    "# figure(figsize=(15,15))\n",
    "# imshow(residual_814_backgr_total, origin='lower',cmap='magma', vmin=0, vmax=161)\n",
    "# plot(line_val+500,(line_val*0.)+450,color='yellow')\n",
    "# plot((line_val*0.)+500,line_val+450,color='yellow')\n",
    "# plot(line_val+500,(line_val*0.)+450+100,color='yellow')\n",
    "# plot((line_val*0.)+500+100,line_val+450,color='yellow')\n",
    "# plot(line_val+875,(line_val*0.)+175,color='lime')\n",
    "# plot((line_val*0.)+875,line_val+175,color='lime')\n",
    "# plot(line_val+875,(line_val*0.)+175+100,color='lime')\n",
    "# plot((line_val*0.)+875+100,line_val+175,color='lime')\n",
    "# title(\"Statistical Analysis Locations - F814W\")\n",
    "\n",
    "\n",
    "# #GREEN\n",
    "# figure(figsize=(15,15))\n",
    "# imshow(residual_606_backgr_total, origin='lower',cmap='viridis', vmin=0, vmax=161)\n",
    "# plot(line_val+500,(line_val*0.)+450,color='yellow')\n",
    "# plot((line_val*0.)+500,line_val+450,color='yellow')\n",
    "# plot(line_val+500,(line_val*0.)+450+100,color='yellow')\n",
    "# plot((line_val*0.)+500+100,line_val+450,color='yellow')\n",
    "# plot(line_val+875,(line_val*0.)+175,color='lime')\n",
    "# plot((line_val*0.)+875,line_val+175,color='lime')\n",
    "# plot(line_val+875,(line_val*0.)+175+100,color='lime')\n",
    "# plot((line_val*0.)+875+100,line_val+175,color='lime')\n",
    "# title(\"Statistical Analysis Locations - F606W\")\n",
    "\n",
    "\n",
    "# #BLUE\n",
    "# figure(figsize=(15,15))\n",
    "# imshow(residual_435_backgr_total, origin='lower',cmap='cividis', vmin=0, vmax=161)\n",
    "# plot(line_val+500,(line_val*0.)+450,color='yellow')\n",
    "# plot((line_val*0.)+500,line_val+450,color='yellow')\n",
    "# plot(line_val+500,(line_val*0.)+450+100,color='yellow')\n",
    "# plot((line_val*0.)+500+100,line_val+450,color='yellow')\n",
    "# plot(line_val+875,(line_val*0.)+175,color='lime')\n",
    "# plot((line_val*0.)+875,line_val+175,color='lime')\n",
    "# plot(line_val+875,(line_val*0.)+175+100,color='lime')\n",
    "# plot((line_val*0.)+875+100,line_val+175,color='lime')\n",
    "# title(\"Statistical Analysis Locations - F435W\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make an rgb image, display cutouts, and print out images of each - use in paper\n",
    "#no - just display cutouts?\n",
    "\n",
    "# '/mnt/c/Users/lana-/Desktop/arc_pix_rgb_cube.fits'\n",
    "# '/mnt/c/Users/lana-/Desktop/arc_pix_rgb.png'\n",
    "figure(figsize=(15,15))\n",
    "img_rgbtest = aplpy.FITSFigure('/mnt/c/Users/lana-/Desktop/arc_rgb_cube_2d.fits')\n",
    "img_rgbtest.show_rgb('/mnt/c/Users/lana-/Desktop/test_rgb.png')\n",
    "#figure out how to make J2000 .... http://python4esac.github.io/plotting/aplpy.html\n",
    "plot(line_val+500,(line_val*0.)+450,color='yellow')\n",
    "plot((line_val*0.)+500,line_val+450,color='yellow')\n",
    "plot(line_val+500,(line_val*0.)+450+100,color='yellow')\n",
    "plot((line_val*0.)+500+100,line_val+450,color='yellow')\n",
    "plot(line_val+875,(line_val*0.)+175,color='lime')\n",
    "plot((line_val*0.)+875,line_val+175,color='lime')\n",
    "plot(line_val+875,(line_val*0.)+175+100,color='lime')\n",
    "plot((line_val*0.)+875+100,line_val+175,color='lime')\n",
    "title(\"Cleaned Arc Image\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arc_edit_red = fits.open('/mnt/c/Users/lana-/Desktop/arc_pix_814.fits')\n",
    "arc_edit_red_hdu = arc_edit_red[0].header\n",
    "\n",
    "#coordinate alignment and increment - since my pixels are set by me to 1 arcsecond, need to convert from arcseconds to degrees (1 arcsecond = 1/3600 degrees)\n",
    "arc_edit_red_hdu['CD1_1'] = -1.6666666666666E-05\n",
    "arc_edit_red_hdu['CD1_2'] = 8.47032947254300E-22\n",
    "arc_edit_red_hdu['CD2_1'] = 8.47032947254300E-22\n",
    "arc_edit_red_hdu['CD2_2'] = 1.66666666666666E-05\n",
    "arc_edit_red.writeto('/mnt/c/Users/lana-/Desktop/arc_pix_814_v2.fits', overwrite=True)\n",
    "fits.delval('/mnt/c/Users/lana-/Desktop/arc_pix_814.fits','PC1_1')\n",
    "fits.delval('/mnt/c/Users/lana-/Desktop/arc_pix_814.fits','PC1_2')\n",
    "fits.delval('/mnt/c/Users/lana-/Desktop/arc_pix_814.fits','PC2_1')\n",
    "fits.delval('/mnt/c/Users/lana-/Desktop/arc_pix_814.fits','PC2_2')\n",
    "\n",
    "# fits.delval('/mnt/c/Users/lana-/Desktop/arc_pix_814.fits','LONPOLE')\n",
    "# fits.delval('/mnt/c/Users/lana-/Desktop/arc_pix_814.fits','LATPOLE')\n",
    "# fits.delval('/mnt/c/Users/lana-/Desktop/arc_pix_814.fits','WCSNAME')\n",
    "# fits.delval('/mnt/c/Users/lana-/Desktop/arc_pix_814.fits','MJDREF')\n",
    "# fits.delval('/mnt/c/Users/lana-/Desktop/arc_pix_814.fits','RADESYS')\n",
    "# fits.delval('/mnt/c/Users/lana-/Desktop/arc_pix_814.fits','WCSAXES')\n",
    "# fits.delval('/mnt/c/Users/lana-/Desktop/arc_pix_814.fits','CRDER1')\n",
    "# fits.delval('/mnt/c/Users/lana-/Desktop/arc_pix_814.fits','CRDER2')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Noise Calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from photutils.datasets import make_100gaussians_image\n",
    "data = make_100gaussians_image()\n",
    "import matplotlib.pyplot as plt\n",
    "from astropy.visualization import SqrtStretch\n",
    "from astropy.visualization.mpl_normalize import ImageNormalize\n",
    "norm = ImageNormalize(stretch=SqrtStretch())\n",
    "imshow(data, norm=norm, origin='lower', cmap='Greys_r', interpolation='nearest')\n",
    "from astropy.stats import biweight_location\n",
    "print(numpy.median(data))  \n",
    "print(biweight_location(data))  \n",
    "from astropy.stats import mad_std\n",
    "print(mad_std(data))  \n",
    "from astropy.stats import sigma_clipped_stats\n",
    "mean, median, std = sigma_clipped_stats(data, sigma=3.0)\n",
    "print((mean, median, std))  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#determine noise\n",
    "#use blank_arr_tot_r blank_arr_tot_g blank_arr_tot_b arrays\n",
    "#https://photutils.readthedocs.io/en/stable/background.html\n",
    "\n",
    "#USE THIS INSTEAD, GENIUS\n",
    "#https://docs.astropy.org/en/stable/stats/index.html\n",
    "\n",
    "from astropy import stats\n",
    "from astropy.stats import mad_std\n",
    "from astropy.stats import sigma_clipped_stats\n",
    "\n",
    "print(\"SMALL BLANK SQUARE\")\n",
    "print(\"stdev:\",mad_std(blank_arr_r))\n",
    "mean, median, std = sigma_clipped_stats(blank_arr_r, sigma=3.0)\n",
    "print(\"mean, median, stdev w/sig_cl:\",(mean, median, std))\n",
    "print(\"min:\",numpy.min(blank_arr_r))\n",
    "print(\"max:\",numpy.max(blank_arr_r))\n",
    "\n",
    "print(\" \")\n",
    "\n",
    "print(\"REMOVED BLANK SQUARE\")\n",
    "print(\"stdev:\",mad_std(removed_arr_g))\n",
    "mean, median, std = sigma_clipped_stats(removed_arr_g, sigma=3.0)\n",
    "print(\"mean, median, stdev w/sig_cl:\",(mean, median, std))\n",
    "print(\"min:\",numpy.min(removed_arr_g))\n",
    "print(\"max:\",numpy.max(removed_arr_g))\n",
    "\n",
    "print(\" \")\n",
    "\n",
    "print(\"ENTIRE IMAGE I USE?\")\n",
    "print(\"stdev:\",mad_std(residual_814_backgr_total))\n",
    "\n",
    "# #calculate\n",
    "# mean, median, std = sigma_clipped_stats(residual_814_backgr_total, sigma=0., maxiters=5)\n",
    "# print(\"mean, median, stdev w/sig_cl:\",(mean, median, std))\n",
    "# #show masked image with same amount of sigma clipping\n",
    "# masked_array = stats.sigma_clip(residual_814_backgr_total, sigma=0., maxiters=5)\n",
    "# figure()\n",
    "# imshow(masked_array, origin='lower')\n",
    "\n",
    "# #calculate\n",
    "# mean, median, std = sigma_clipped_stats(residual_814_backgr_total, sigma=1., maxiters=5)\n",
    "# print(\"mean, median, stdev w/sig_cl:\",(mean, median, std))\n",
    "# #show masked image with same amount of sigma clipping\n",
    "# masked_array = stats.sigma_clip(residual_814_backgr_total, sigma=1., maxiters=5)\n",
    "# figure()\n",
    "# imshow(masked_array, origin='lower')\n",
    "\n",
    "#calculate\n",
    "mean, median, std = sigma_clipped_stats(residual_814_backgr_total, sigma=1.25, maxiters=5)\n",
    "print(\"mean, median, stdev w/sig_cl:\",(mean, median, std))\n",
    "#show masked image with same amount of sigma clipping\n",
    "masked_array = stats.sigma_clip(residual_814_backgr_total, sigma=1.25, maxiters=5)\n",
    "figure(figsize=(25,25))\n",
    "imshow(masked_array, origin='lower')\n",
    "title(\"St_Dev (~Noise) = \"+str(std),fontsize=40,color='darkgreen')\n",
    "savefig('/mnt/c/Users/lana-/Desktop/noise_det/noise0.png',bbox_inches='tight')\n",
    "\n",
    "#calculate\n",
    "mean, median, std = sigma_clipped_stats(residual_814_backgr_total, sigma=1.5, maxiters=5)\n",
    "print(\"mean, median, stdev w/sig_cl:\",(mean, median, std))\n",
    "#show masked image with same amount of sigma clipping\n",
    "masked_array = stats.sigma_clip(residual_814_backgr_total, sigma=1.5, maxiters=5)\n",
    "figure(figsize=(25,25))\n",
    "imshow(masked_array, origin='lower')\n",
    "title(\"St_Dev (~Noise) = \"+str(std),fontsize=40,color='darkgreen')\n",
    "savefig('/mnt/c/Users/lana-/Desktop/noise_det/noise1.png',bbox_inches='tight')\n",
    "\n",
    "#calculate\n",
    "mean, median, std = sigma_clipped_stats(residual_814_backgr_total, sigma=1.55, maxiters=5)\n",
    "print(\"mean, median, stdev w/sig_cl:\",(mean, median, std))\n",
    "#show masked image with same amount of sigma clipping\n",
    "masked_array = stats.sigma_clip(residual_814_backgr_total, sigma=1.55, maxiters=5)\n",
    "figure(figsize=(25,25))\n",
    "imshow(masked_array, origin='lower')\n",
    "title(\"St_Dev (~Noise) = \"+str(std),fontsize=40,color='darkgreen')\n",
    "savefig('/mnt/c/Users/lana-/Desktop/noise_det/noise2.png',bbox_inches='tight')\n",
    "\n",
    "#calculate\n",
    "mean, median, std = sigma_clipped_stats(residual_814_backgr_total, sigma=1.6, maxiters=5)\n",
    "print(\"mean, median, stdev w/sig_cl:\",(mean, median, std))\n",
    "#show masked image with same amount of sigma clipping\n",
    "masked_array = stats.sigma_clip(residual_814_backgr_total, sigma=1.6, maxiters=5)\n",
    "figure(figsize=(25,25))\n",
    "imshow(masked_array, origin='lower')\n",
    "title(\"St_Dev (~Noise) = \"+str(std),fontsize=40,color='darkgreen')\n",
    "savefig('/mnt/c/Users/lana-/Desktop/noise_det/noise3.png',bbox_inches='tight')\n",
    "\n",
    "#calculate\n",
    "mean, median, std = sigma_clipped_stats(residual_814_backgr_total, sigma=1.65, maxiters=5)\n",
    "print(\"mean, median, stdev w/sig_cl:\",(mean, median, std))\n",
    "#show masked image with same amount of sigma clipping\n",
    "masked_array = stats.sigma_clip(residual_814_backgr_total, sigma=1.65, maxiters=5)\n",
    "figure(figsize=(25,25))\n",
    "imshow(masked_array, origin='lower')\n",
    "title(\"St_Dev (~Noise) = \"+str(std),fontsize=40,color='darkgreen')\n",
    "savefig('/mnt/c/Users/lana-/Desktop/noise_det/noise4.png',bbox_inches='tight')\n",
    "\n",
    "#calculate\n",
    "mean, median, std = sigma_clipped_stats(residual_814_backgr_total, sigma=1.7, maxiters=5)\n",
    "print(\"mean, median, stdev w/sig_cl:\",(mean, median, std))\n",
    "#show masked image with same amount of sigma clipping\n",
    "masked_array = stats.sigma_clip(residual_814_backgr_total, sigma=1.7, maxiters=5)\n",
    "figure(figsize=(25,25))\n",
    "imshow(masked_array, origin='lower')\n",
    "title(\"St_Dev (~Noise) = \"+str(std),fontsize=40,color='darkgreen')\n",
    "savefig('/mnt/c/Users/lana-/Desktop/noise_det/noise5.png',bbox_inches='tight')\n",
    "\n",
    "#calculate\n",
    "mean, median, std = sigma_clipped_stats(residual_814_backgr_total, sigma=1.75, maxiters=5)\n",
    "print(\"mean, median, stdev w/sig_cl:\",(mean, median, std))\n",
    "#show masked image with same amount of sigma clipping\n",
    "masked_array = stats.sigma_clip(residual_814_backgr_total, sigma=1.75, maxiters=5)\n",
    "figure(figsize=(25,25))\n",
    "imshow(masked_array, origin='lower')\n",
    "title(\"St_Dev (~Noise) = \"+str(std),fontsize=40,color='darkgreen')\n",
    "savefig('/mnt/c/Users/lana-/Desktop/noise_det/noise6.png',bbox_inches='tight')\n",
    "\n",
    "#calculate\n",
    "mean, median, std = sigma_clipped_stats(residual_814_backgr_total, sigma=2., maxiters=5)\n",
    "print(\"mean, median, stdev w/sig_cl:\",(mean, median, std))\n",
    "#show masked image with same amount of sigma clipping\n",
    "masked_array = stats.sigma_clip(residual_814_backgr_total, sigma=2., maxiters=5)\n",
    "figure(figsize=(25,25))\n",
    "imshow(masked_array, origin='lower')\n",
    "title(\"St_Dev (~Noise) = \"+str(std),fontsize=40,color='darkgreen')\n",
    "savefig('/mnt/c/Users/lana-/Desktop/noise_det/noise7.png',bbox_inches='tight')\n",
    "\n",
    "# #calculate\n",
    "# mean, median, std = sigma_clipped_stats(residual_814_backgr_total, sigma=3., maxiters=5)\n",
    "# print(\"mean, median, stdev w/sig_cl:\",(mean, median, std))\n",
    "# #show masked image with same amount of sigma clipping\n",
    "# masked_array = stats.sigma_clip(residual_814_backgr_total, sigma=3., maxiters=5)\n",
    "# figure()\n",
    "# imshow(masked_array, origin='lower')\n",
    "\n",
    "# #calculate\n",
    "# mean, median, std = sigma_clipped_stats(residual_814_backgr_total, sigma=4., maxiters=5)\n",
    "# print(\"mean, median, stdev w/sig_cl:\",(mean, median, std))\n",
    "# #show masked image with same amount of sigma clipping\n",
    "# masked_array = stats.sigma_clip(residual_814_backgr_total, sigma=4., maxiters=5)\n",
    "# figure()\n",
    "# imshow(masked_array, origin='lower')\n",
    "\n",
    "# #calculate\n",
    "# mean, median, std = sigma_clipped_stats(residual_814_backgr_total, sigma=5., maxiters=5)\n",
    "# print(\"mean, median, stdev w/sig_cl:\",(mean, median, std))\n",
    "# #show masked image with same amount of sigma clipping\n",
    "# masked_array = stats.sigma_clip(residual_814_backgr_total, sigma=5., maxiters=5)\n",
    "# figure()\n",
    "# imshow(masked_array, origin='lower')\n",
    "\n",
    "# print(\"min:\",numpy.min(residual_814_backgr_total))\n",
    "# print(\"max:\",numpy.max(residual_814_backgr_total))\n",
    "\n",
    "# print(type(data))\n",
    "# print(data)\n",
    "# print(type(blank_arr_r))\n",
    "# print(blank_arr_r)\n",
    "# print(type(removed_arr_g))\n",
    "# print(removed_arr_g)#takes all images and stores them as image_list\n",
    "image_path = Path('/mnt/c/Users/lana-/Desktop/noise_det/')\n",
    "images = list(image_path.glob('*.png'))\n",
    "image_list = []\n",
    "for file_name in images:\n",
    "    image_list.append(imageio.imread(file_name))\n",
    "print(len(image_list))\n",
    "imageio.mimwrite('/mnt/c/Users/lana-/Desktop/noise_det/noise_det.gif', image_list, fps=0.5)\n",
    "\n",
    "# print(type(residual_814_backgr_total))\n",
    "# print(residual_814_backgr_total)\n",
    "\n",
    "\n",
    "#COMPARE THESE TO THE STATISTICS I DID BEFORE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TEST ARC TESTS BEGIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this part finds the coordinates of the edges of the fits files we are using \n",
    "#then finds those coordinates in the RGB fits file\n",
    "#here they happen to be outside the boundaries of the plot from the last cell\n",
    "#so we end up trimming each edge by 100 pixels in the rgb image\n",
    "#and we then trim the other fits files by 30 pixels (roughly 100*1201/4001) so that the edges line up\n",
    "\n",
    "#reads in the x deflection map that is 4001x4001 (artitrary choice just to get the locations of the edges) and the WCS information from it\n",
    "x_deflect_file = 'hlsp_frontier_model_abell370_keeton_v4_x-pixels-deflect.fits'\n",
    "x_deflect = fits.getdata(x_deflect_file)\n",
    "wcs_x_deflect = WCS(x_deflect_file)\n",
    "\n",
    "#gets the WCS coordinates for the lower left corner and upper right corner of the reference x_deflect map\n",
    "xx = wcs_x_deflect.wcs_pix2world([[0,0]],1)\n",
    "yy = wcs_x_deflect.wcs_pix2world([[4001,4001]],1)\n",
    "print(xx)\n",
    "print(yy)\n",
    "\n",
    "#find the x and y coordinates for where we want to trim the RBG file\n",
    "# print(math.ceil(wcs_rgb.wcs_world2pix(xx,1)[0][0]))\n",
    "# print((xx,1)[0][0])\n",
    "# print(math.ceil(wcs_rgb.wcs_world2pix(xx,1)[0][1]))\n",
    "# print(numpy.floor(wcs_rgb.wcs_world2pix(yy,1)[0][0]))\n",
    "# print((yy,1)[0][0])\n",
    "# print(numpy.floor(wcs_rgb.wcs_world2pix(yy,1)[0][1]))\n",
    "xmin, ymin = int(math.ceil(wcs_rgb.wcs_world2pix(xx,1)[0][0])),int(math.ceil(wcs_rgb.wcs_world2pix(xx,1)[0][1]))\n",
    "xmax, ymax = int(numpy.floor(wcs_rgb.wcs_world2pix(yy,1)[0][0])),int(numpy.floor(wcs_rgb.wcs_world2pix(yy,1)[0][1]))\n",
    "\n",
    "print(xmin)\n",
    "print(xmax)\n",
    "print(ymin)\n",
    "print(ymax)\n",
    "\n",
    "#this is because the 4001x4001 pixel size of the other fits files lines up a little before zero on the x axis (-45)\n",
    "val = 100\n",
    "\n",
    "#trim the WCS info and arrays so they have the right coordinates after the zoom\n",
    "wcs_rgbcut = wcs_rgb[ymin+val:ymax-val,xmin+val:xmax-val]\n",
    "merged_image = numpy.array(merged)\n",
    "mcut = merged_image[ymin+val:ymax-val,xmin+val:xmax-val]\n",
    "\n",
    "#zoom the RGB map so do not end up with artifacts:\n",
    "mcut_rgb = ndimage.zoom(mcut,[1201/4001,1201/4001,1]) #first two dimensions are xy, third is COLOR (do not want to mess with that)\n",
    "\n",
    "#plot\n",
    "fig = figure(figsize=(10,10))\n",
    "imshow(mcut_rgb, origin='lower')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(starsr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set up an empty array with room for 100 values: number of pixels plotted for the image arc in each rangemap\n",
    "source_count_array = numpy.arange(100)\n",
    "image_count_array = numpy.arange(100)\n",
    "pixel_count_array = numpy.arange(100)\n",
    "#ave?\n",
    "source_count_array_ave = numpy.arange(100)\n",
    "image_count_array_ave = numpy.arange(100)\n",
    "pixel_count_array_ave = numpy.arange(100)\n",
    "\n",
    "\n",
    "#others\n",
    "source_count_array_red = numpy.arange(100)\n",
    "pixel_count_arraysr = numpy.arange(100)\n",
    "source_count_array_green = numpy.arange(100)\n",
    "pixel_count_arraysg = numpy.arange(100)\n",
    "source_count_array_blue = numpy.arange(100)\n",
    "pixel_count_arraysb = numpy.arange(100)\n",
    "\n",
    "image_count_array_red = numpy.arange(100)\n",
    "pixel_count_arrayir = numpy.arange(100)\n",
    "image_count_array_green = numpy.arange(100)\n",
    "pixel_count_arrayig = numpy.arange(100)\n",
    "image_count_array_blue = numpy.arange(100)\n",
    "pixel_count_arrayig = numpy.arange(100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function Begins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function that calculates and plots everything we need\n",
    "def modelarc(indx,src_params=[4,25,0.8,(numpy.pi)/10]):#,vers=\"src\"):\n",
    "    \n",
    "    #set function input array to src_params\n",
    "    nsrc,Rsrc,esrc,tsrc = src_params\n",
    "    \n",
    "    print(indx)\n",
    "    \n",
    "    #-----------------------------------------------------------------------\n",
    "    \n",
    "    #HERE - NEED TO ITERATE THROUGH EACH OF THE 100 MAPS\n",
    "    #basically just add the indx to the file name when reading it\n",
    "    #google quickly what {:03d} is, could be a \"keep the number with a zero before it while going through numbers\"\n",
    "    #like 01, 02, etc. - this is how the file names are set up\n",
    "    \n",
    "#     deflection_maps = numpy.load(\"fit0-los1-scale1-defs-z0.725.npy\")\n",
    "#     print(len(deflection_maps))\n",
    "#     numpy.load(\"fit0-los1-scale1-defs-z0.725.npy\")\n",
    "    #are flattened, need to reshape into 2D array to view them\n",
    "\n",
    "    #Catie says:\n",
    "    #If you look at the shape of the deflections array its 100 x 1442401 x 2\n",
    "    #so 100 maps of 1201 x 1201 pixels and then the 2 is for x & y\n",
    "    #So to get the maps of the first model you’d do xmap = defs[0].T[0].reshape(1201,1201), and ymap = defs[0].T[1].reshape(1201,1201)\n",
    "\n",
    "    #test\n",
    "    xmap = deflection_maps[indx].T[0].reshape(1201,1201)\n",
    "    ymap = deflection_maps[indx].T[1].reshape(1201,1201)\n",
    "#     print(xmap)\n",
    "#     print(ymap)\n",
    "\n",
    "#     magnification_maps = numpy.load(\"fit0-los1-scale1-mags-z0.725.npy\")\n",
    "#     print(len(magnification_maps))\n",
    "#     numpy.load(\"fit0-los1-scale1-mags-z0.725.npy\")\n",
    "    magmap = magnification_maps[indx].reshape(1201,1201)\n",
    "#     print(magmap)\n",
    "\n",
    "    #-----------------------------------------------------------------------\n",
    "    \n",
    "    #read in range maps - use \"basename\" instead of retyping out everything each time\n",
    "    basename = '/mnt/c/Users/lana-/Desktop/final-maps/hlsp_frontier_model_abells1063_keeton-map{:03d}_v4_'.format(indx)\n",
    "    kappa_fits = fits.getdata(basename+'kappa.fits')\n",
    "    gamma_fits = fits.getdata(basename+'gamma.fits')\n",
    "    alphax_fits = fits.getdata(basename+'x-arcsec-deflect.fits')\n",
    "    alphay_fits = fits.getdata(basename+'y-arcsec-deflect.fits')\n",
    "    #set this up as general shape / dimensions / location of fits files with wcs info\n",
    "    wcs_info = wcs.WCS(basename+'kappa.fits')\n",
    "    \n",
    "    new_val = 30#numpy.rint(100*1201/4001)\n",
    "    \n",
    "    #now need to trim these by 100*1201/4001\n",
    "    #do this to both the files and the wcs data\n",
    "    kappa_fits = kappa_fits[new_val:1201-new_val,new_val:1201-new_val]\n",
    "    gamma_fits = gamma_fits[new_val:1201-new_val,new_val:1201-new_val]\n",
    "    alphax_fits = alphax_fits[new_val:1201-new_val,new_val:1201-new_val]\n",
    "    alphay_fits = alphay_fits[new_val:1201-new_val,new_val:1201-new_val]\n",
    "    wcs_info = wcs_info[new_val:1201-new_val,new_val:1201-new_val]  \n",
    "    \n",
    "    #apply the Dls/Dos scaling\n",
    "    kappa = Dls_over_Dos*kappa_fits\n",
    "    gamma = Dls_over_Dos*gamma_fits\n",
    "    alphax = Dls_over_Dos*alphax_fits\n",
    "    alphay = Dls_over_Dos*alphay_fits\n",
    "\n",
    "    #compute the magnification map\n",
    "    mu = 1.0/((1.0-kappa)**2-gamma**2)\n",
    "    #mu_plot uses logarithmic scaling\n",
    "    mu_plot = numpy.log10(numpy.abs(mu))\n",
    "    #only include values above a certain threshold\n",
    "    mu_plot[mu_plot<1.4] = numpy.nan #this.. gets overwritten I think\n",
    "\n",
    "    #ALL OF THE MAPS ABOVE GET OVERWRITTEN - I kept them here because I use the wcs information from them\n",
    "    \n",
    "    #------------------------\n",
    "    #this is the start of reading in the MCMC run info from the numpy file, so ..no fits file stuff?\n",
    "    #need to REdefine (in case I break something) alphax, alphay, and mu_plot - those are what Catie sent me\n",
    "    alphax = xmap[new_val:1201-new_val,new_val:1201-new_val]\n",
    "    alphay = ymap[new_val:1201-new_val,new_val:1201-new_val]\n",
    "    mu = magmap[new_val:1201-new_val,new_val:1201-new_val]\n",
    "    #mu_plot uses logarithmic scaling\n",
    "    mu_plot = numpy.log10(numpy.abs(mu))\n",
    "    #only include values above a certain threshold\n",
    "    #mu_plot[mu_plot<1.4] = numpy.nan #commenting this out for now, want to see regions of every magnification\n",
    "    \n",
    "#     # read the image and source positions for the arc in this realization;\n",
    "#     # important: recall that there is an offset between draw index and map index\n",
    "    imgdat = numpy.loadtxt('/mnt/c/Users/lana-/Desktop/final-maps/draw{:d}-src-img.dat'.format(indx+1),usecols=(0,1))\n",
    "    #read the image positions from the fiducial model (the src .dat files, first file?  THEY ARE OFFSET SOMETHING IS WRONG HERE)\n",
    "#     imgdat = numpy.loadtxt('/mnt/c/Users/lana-/Desktop/final-maps/draw0-src-img.dat'.format(indx+1),usecols=(0,1))\n",
    "    # xy positions of the source and images - just images for the MCMC analysis\n",
    "    src_xy = imgdat[4]\n",
    "#     print(src_xy)\n",
    "    img_xy = imgdat[5:10]\n",
    "#     print(img_xy)\n",
    "#     print(numpy.shape(img_xy))\n",
    "#     print(numpy.size(img_xy))\n",
    "#     print(numpy.ndim(img_xy))\n",
    "\n",
    "    #from fiducial model\n",
    "    src_xy[0] = -6.485184\n",
    "    src_xy[1] = -13.24760\n",
    "    img_xy[0,0] = -12.8419\n",
    "    img_xy[0,1] = -26.6029\n",
    "    img_xy[1,0] = -2.3633\n",
    "    img_xy[1,1] = -29.8079\n",
    "    img_xy[2,0] = 6.6656\n",
    "    img_xy[2,1] = -27.2922\n",
    "    img_xy[3,0] = 3.3585\n",
    "    img_xy[3,1] = -28.5886\n",
    "    img_xy[4,0] = 2.4730\n",
    "    img_xy[4,1] = -28.9704\n",
    "    #fix this - formatting of array is off, though size/dimensions are the same\n",
    "#     img_xy = ([[-12.8419,-26.6029],[-2.3633,-29.8079],[6.6656,-27.2922],[3.3585,-28.5886],[2.4730,-28.9704]])\n",
    "#     print(img_xy)\n",
    "#     print(numpy.shape(img_xy))\n",
    "#     print(numpy.size(img_xy))\n",
    "#     print(numpy.ndim(img_xy))\n",
    "    \n",
    "    # convert to world coordinates and then to pixels\n",
    "    src_world = xy2world(src_xy[0],src_xy[1])\n",
    "    img_world = xy2world(img_xy[:,0],img_xy[:,1])\n",
    "    src_pix = src_world.to_pixel(wcs_info)\n",
    "    img_pix = img_world.to_pixel(wcs_info)\n",
    "    \n",
    "    #need 2 meshgrids??  \n",
    "\n",
    "    #shape of the grid on which we will compute the arc\n",
    "    mm,nn = kappa_fits.shape\n",
    "    #pixel grid\n",
    "    ii,jj = numpy.meshgrid(numpy.arange(mm),numpy.arange(nn))\n",
    "    \n",
    "    #shape of the grid on which we will compute the arc\n",
    "    mmm,nnn = kappa_fits.shape\n",
    "    #pixel grid\n",
    "    iii,jjj = numpy.meshgrid(numpy.arange(mmm),numpy.arange(nnn))\n",
    "\n",
    "#     print(kappa_fits.shape[0])\n",
    "#     print(kappa_fits.shape[1])\n",
    "    \n",
    "    #--------------------------------------------------------------------------------------------\n",
    "    \n",
    "    #loop through this or do it five times\n",
    "    \n",
    "    #for MCMC-related tests - need to start with leftmost image position and trace it back\n",
    "    #left image:\n",
    "    #round and turn into int\n",
    "    left_img_x = int(numpy.around(img_pix[0][0]))\n",
    "    left_img_y = int(numpy.around(img_pix[1][0]))\n",
    "    #images 2/3/4/5\n",
    "    img2_x = int(numpy.around(img_pix[0][1]))\n",
    "    img2_y = int(numpy.around(img_pix[1][1]))\n",
    "    img3_x = int(numpy.around(img_pix[0][2]))\n",
    "    img3_y = int(numpy.around(img_pix[1][2]))\n",
    "    img4_x = int(numpy.around(img_pix[0][3]))\n",
    "    img4_y = int(numpy.around(img_pix[1][3]))\n",
    "    img5_x = int(numpy.around(img_pix[0][4]))\n",
    "    img5_y = int(numpy.around(img_pix[1][4]))\n",
    "#     print(\"image positions:\")\n",
    "#     print(left_img_x)\n",
    "#     print(left_img_y)\n",
    "#     print(img2_x)\n",
    "#     print(img2_y)\n",
    "#     print(img3_x)\n",
    "#     print(img3_y)\n",
    "#     print(img4_x)\n",
    "#     print(img4_y)\n",
    "#     print(img5_x)\n",
    "#     print(img5_y)\n",
    "    \n",
    "    #need to find deflection map values at this location\n",
    "#     print(\"needed source position, in arcsec\")\n",
    "#     print(src_xy[0])\n",
    "#     print(src_xy[1])\n",
    "    #the fits files have x and y flipped\n",
    "#     print(\"deflections, in arcsec:\")\n",
    "#     print(alphax[left_img_y,left_img_x])\n",
    "#     print(alphay[left_img_y,left_img_x])\n",
    "#     print(alphax[img2_y,img2_x])\n",
    "#     print(alphay[img2_y,img2_x])\n",
    "#     print(alphax[img3_y,img3_x])\n",
    "#     print(alphay[img3_y,img3_x])\n",
    "#     print(alphax[img4_y,img4_x])\n",
    "#     print(alphay[img4_y,img4_x])\n",
    "#     print(alphax[img5_y,img5_x])\n",
    "#     print(alphay[img5_y,img5_x])\n",
    "    \n",
    "\n",
    "    #maybe interpolate instead if this is the right way to do it\n",
    "    #anyways, need to convert from arcseconds to degrees to pixels, since my pixel size is the same as my coordinate steps here\n",
    "    #do this more generally, but for now just test: (now I have the x and y dimension order correct)\n",
    "    x_deflect_source = (alphax[left_img_y,left_img_x])*(90000/(5*3600))\n",
    "    y_deflect_source = (alphay[left_img_y,left_img_x])*(90000/(5*3600))\n",
    "    #for 2/3/4/5\n",
    "    x_deflect_source2 = (alphax[img2_y,img2_x])*(90000/(5*3600))\n",
    "    y_deflect_source2 = (alphay[img2_y,img2_x])*(90000/(5*3600))\n",
    "    x_deflect_source3 = (alphax[img3_y,img3_x])*(90000/(5*3600))\n",
    "    y_deflect_source3 = (alphay[img3_y,img3_x])*(90000/(5*3600))\n",
    "    x_deflect_source4 = (alphax[img4_y,img4_x])*(90000/(5*3600))\n",
    "    y_deflect_source4 = (alphay[img4_y,img4_x])*(90000/(5*3600))\n",
    "    x_deflect_source5 = (alphax[img5_y,img5_x])*(90000/(5*3600))\n",
    "    y_deflect_source5 = (alphay[img5_y,img5_x])*(90000/(5*3600))\n",
    "#     print(\"deflections converted:\")\n",
    "#     print(x_deflect_source)\n",
    "#     print(y_deflect_source)\n",
    "#     print(x_deflect_source2)\n",
    "#     print(y_deflect_source2)\n",
    "#     print(x_deflect_source3)\n",
    "#     print(y_deflect_source3)\n",
    "#     print(x_deflect_source4)\n",
    "#     print(y_deflect_source4)\n",
    "#     print(x_deflect_source5)\n",
    "#     print(y_deflect_source5)\n",
    "    \n",
    "    #If the source position is written as (u,v) and the image position is written as (x,y), we have:\n",
    "    #u(x)=x-α(x)\n",
    "    #v(y)=y-α(y)\n",
    "    source_map_back_x = left_img_x-x_deflect_source\n",
    "    source_map_back_y = left_img_y-y_deflect_source\n",
    "    #for 2/3/4/5\n",
    "    source_map_back_x2 = img2_x-x_deflect_source2\n",
    "    source_map_back_y2 = img2_y-y_deflect_source2\n",
    "    source_map_back_x3 = img3_x-x_deflect_source3\n",
    "    source_map_back_y3 = img3_y-y_deflect_source3\n",
    "    source_map_back_x4 = img4_x-x_deflect_source4\n",
    "    source_map_back_y4 = img4_y-y_deflect_source4\n",
    "    source_map_back_x5 = img5_x-x_deflect_source5\n",
    "    source_map_back_y5 = img5_y-y_deflect_source5\n",
    "#     print(\"  \")\n",
    "#     print(\"mapped back source from each:\")\n",
    "#     print(\"source_map_back_x\",source_map_back_x)\n",
    "#     print(\"source_map_back_y\",source_map_back_y)\n",
    "#     print(\"source_map_back_x2\",source_map_back_x2)\n",
    "#     print(\"source_map_back_y2\",source_map_back_y2)\n",
    "#     print(\"source_map_back_x3\",source_map_back_x3)\n",
    "#     print(\"source_map_back_y3\",source_map_back_y3)\n",
    "#     print(\"source_map_back_x4\",source_map_back_x4)\n",
    "#     print(\"source_map_back_y4\",source_map_back_y4)\n",
    "#     print(\"source_map_back_x5\",source_map_back_x5)\n",
    "#     print(\"source_map_back_y5\",source_map_back_y5)\n",
    "    \n",
    "    #switch some things here - save the original determined source from the fiducial model to plot later\n",
    "    #then replace the src_xy values so we can use the mapped back (from the leftmost image) source position as our plotted source\n",
    "#     print(\"src_pix:\")\n",
    "#     print(src_pix[0])\n",
    "#     print(src_pix[1])\n",
    "#     print(\"src_xy:\")\n",
    "#     print(src_xy[0])\n",
    "#     print(src_xy[1])\n",
    "    orig_src = src_pix\n",
    "#     print(orig_src)\n",
    "#     print(type(orig_src))\n",
    "#     print(\"source_map_back:\")\n",
    "#     print(source_map_back_x)\n",
    "#     print(source_map_back_y)\n",
    "#     print(source_map_back_x/(90000/(5*3600)))\n",
    "#     print(source_map_back_y/(90000/(5*3600)))     \n",
    "          \n",
    "    #convert from pixels to world coordinates then to xy coordinates\n",
    "    #pix2world\n",
    "\n",
    "    #world2xy\n",
    "    \n",
    "    \n",
    "    #or maybe, convert from pixels to xy, so use pix2xy\n",
    "    #pixels to xy coordinates\n",
    "#     def pix2xy(x_pix,y_pix,theWCS):\n",
    "#         pix2xy_return = world2xy(wcs.utils.pixel_to_skycoord(x_pix,y_pix,theWCS))\n",
    "#         return pix2xy_return\n",
    "    src_map_back_xy = pix2xy(source_map_back_x,source_map_back_y,wcs_info)\n",
    "    src_map_back_xy1 = pix2xy(source_map_back_x,source_map_back_y,wcs_info)\n",
    "    src_map_back_xy2 = pix2xy(source_map_back_x2,source_map_back_y2,wcs_info)\n",
    "    src_map_back_xy3 = pix2xy(source_map_back_x3,source_map_back_y3,wcs_info)\n",
    "    src_map_back_xy4 = pix2xy(source_map_back_x4,source_map_back_y4,wcs_info)\n",
    "    src_map_back_xy5 = pix2xy(source_map_back_x5,source_map_back_y5,wcs_info)\n",
    "#     print(\"hopefully\",src_map_back_xy)\n",
    "#     print(\"hopefully\",src_map_back_xy[0])\n",
    "#     print(\"hopefully\",src_map_back_xy[1])\n",
    "\n",
    "    \n",
    "    #convert from asec to degrees to pixels\n",
    "#     alphax_z = alphax_z*(90000/(5*3600))\n",
    "#     alphay_z = alphay_z*(90000/(5*3600))\n",
    "    \n",
    "    #https://nddata.readthedocs.io/en/latest/api/nddata.utils.wcs.pix2world.html\n",
    "    #RA and Dec to xy coordinates\n",
    "#     def world2xy(coord):\n",
    "#         tmp = fieldcenter.spherical_offsets_to(coord)\n",
    "#         world2xy_return_1 = -tmp[0].to('arcsec').value\n",
    "#         world2xy_return_2 = tmp[1].to('arcsec').value\n",
    "#         return world2xy_return_1, world2xy_return_2\n",
    "\n",
    "#     src_world = xy2world(src_xy[0],src_xy[1])\n",
    "#     src_pix = src_world.to_pixel(wcs_info)\n",
    "    \n",
    "#     print(\"yello\")\n",
    "#     print(src_pix[0])\n",
    "#     print(src_pix[1])\n",
    "    \n",
    "    #---------------------------------------------------------------------------------------------\n",
    "    \n",
    "    #NOTE ON HOW TO QUANTIFY THICKNESS OF THE IMAGE ARC\n",
    "    #could start by counting all the pixels that I set to nonzero\n",
    "    \n",
    "    #source setup - was using src_xy in arcsec, now need to use source_map_back after converting it to arcsec?\n",
    "    u,v = pix2xy(ii,jj,wcs_info)\n",
    "    source_func = Sersic2D(amplitude=1, r_eff=Rsrc/7.5, n=nsrc, x_0=src_map_back_xy[0], y_0=src_map_back_xy[1], ellip=esrc, theta=tsrc)\n",
    "    source_sersic = source_func(u,v)\n",
    "    source_sersic[numpy.where(source_sersic<1)] = numpy.nan\n",
    "    src_model = source_sersic\n",
    "    #count the number of pixels in the source - if holding fixed, should be roughly consistent depending on where it lands\n",
    "    src_pix_count = 0\n",
    "    for i in range(kappa_fits.shape[0]):\n",
    "        for j in range(kappa_fits.shape[1]):\n",
    "            if src_model[i][j] > 0:\n",
    "                src_pix_count += 1\n",
    "    #print(\"src_pix_count\",src_pix_count)\n",
    "    source_count_array[indx] = src_pix_count\n",
    "    \n",
    "    #image setup\n",
    "    a,b = pix2xy(iii,jjj,wcs_info)\n",
    "    #plug the positions and deflections into the source function to get the image\n",
    "    x = a - alphax\n",
    "    y = b - alphay\n",
    "    image_grid = source_func(x,y)\n",
    "    image_grid[numpy.where(image_grid<1)] = numpy.nan\n",
    "    img_model = image_grid\n",
    "    #count the number of pixels in the resulting images\n",
    "    img_pix_count = 0\n",
    "    for i in range(kappa_fits.shape[0]):\n",
    "        for j in range(kappa_fits.shape[1]):\n",
    "            if img_model[i][j] > 0:\n",
    "                img_pix_count += 1\n",
    "#                 print(img_model[i][j])\n",
    "    #print(\"img_pix_count\",img_pix_count)\n",
    "    image_count_array[indx] = img_pix_count\n",
    "    \n",
    "    \n",
    "    #------------------------------------------------------------\n",
    "    \n",
    "    #average the source positions obtained from the five image positions\n",
    "    \n",
    "    #source setup - was using src_xy in arcsec, now need to use source_map_back after converting it to arcsec?\n",
    "    u_ave,v_ave = pix2xy(ii,jj,wcs_info)\n",
    "    source_func_ave = Sersic2D(amplitude=1, r_eff=Rsrc/7.5, n=nsrc, x_0=(src_map_back_xy[0]+src_map_back_xy2[0]+src_map_back_xy3[0]+src_map_back_xy4[0]+src_map_back_xy5[0])/5, y_0=(src_map_back_xy[1]+src_map_back_xy2[1]+src_map_back_xy3[1]+src_map_back_xy4[1]+src_map_back_xy5[1])/5, ellip=esrc, theta=tsrc)\n",
    "    source_sersic_ave = source_func_ave(u,v)\n",
    "    source_sersic_ave[numpy.where(source_sersic_ave<1)] = numpy.nan\n",
    "    src_model_ave = source_sersic_ave\n",
    "    #count the number of pixels in the source - if holding fixed, should be roughly consistent depending on where it lands\n",
    "    src_pix_count_ave = 0\n",
    "    for i in range(kappa_fits.shape[0]):\n",
    "        for j in range(kappa_fits.shape[1]):\n",
    "            if src_model_ave[i][j] > 0:\n",
    "                src_pix_count_ave += 1\n",
    "    #print(\"src_pix_count_ave\",src_pix_count_ave)\n",
    "    source_count_array_ave[indx] = src_pix_count_ave\n",
    "    \n",
    "    #image setup\n",
    "    a_ave,b_ave = pix2xy(iii,jjj,wcs_info)\n",
    "    #plug the positions and deflections into the source function to get the image\n",
    "    x_ave = a_ave - alphax\n",
    "    y_ave = b_ave - alphay\n",
    "    image_grid_ave = source_func_ave(x,y)\n",
    "    image_grid_ave[numpy.where(image_grid_ave<1)] = numpy.nan\n",
    "    img_model_ave = image_grid_ave\n",
    "    #count the number of pixels in the resulting images\n",
    "    img_pix_count_ave = 0\n",
    "    for i in range(kappa_fits.shape[0]):\n",
    "        for j in range(kappa_fits.shape[1]):\n",
    "            if img_model_ave[i][j] > 0:\n",
    "                img_pix_count_ave += 1\n",
    "#                 print(img_model_ave[i][j])\n",
    "    #print(\"img_pix_count_ave\",img_pix_count_ave)\n",
    "    image_count_array_ave[indx] = img_pix_count_ave\n",
    "    \n",
    "    #------------------------------------------------------------\n",
    "\n",
    "    #try to figure out how to split the arc colors into different sections\n",
    "    \n",
    "#     img_model_colors = numpy.log10(img_model)\n",
    "#     import sys\n",
    "#     numpy.set_printoptions(threshold=sys.maxsize)\n",
    "    \n",
    "    #print(\"numpy.log10(img_model)\",img_model_colors[numpy.where(img_model_colors>0)])\n",
    "    #colorbars automatically show the min and max of the data set\n",
    "    #restricting it with vmin and vmax just makes everything below vmin and above vmax the single beginning/end colors of the colorbar\n",
    "    #our values go from 0 to like 3.25 ish\n",
    "    #our colorbar goes from 0 to 1.5\n",
    "    #we will set up three ranges within which to count the number of pixels, one set for source one set for image arc:\n",
    "    \n",
    "    \n",
    "    #source:\n",
    "    \n",
    "    #red: >=1\n",
    "    src_pix_count_red = 0\n",
    "    for i in range(kappa_fits.shape[0]):\n",
    "        for j in range(kappa_fits.shape[1]):\n",
    "            if (numpy.log10(src_model[i][j]) >= 1):\n",
    "                src_pix_count_red += 1\n",
    "#                 print(src_model_red[i][j])\n",
    "    #print(\"src_pix_count_red\",src_pix_count_red)\n",
    "    source_count_array_red[indx] = src_pix_count_red\n",
    "    pixel_count_arraysr[indx] = src_pix_count_red#should get rid of this\n",
    "    \n",
    "    \n",
    "    #green: 0.4 to 1\n",
    "    src_pix_count_green = 0\n",
    "    for i in range(kappa_fits.shape[0]):\n",
    "        for j in range(kappa_fits.shape[1]):\n",
    "            if ((numpy.log10(src_model[i][j]) >= 0.4) and (numpy.log10(src_model[i][j]) < 1)):\n",
    "                src_pix_count_green += 1\n",
    "#                 print(src_model_green[i][j])\n",
    "    #print(\"src_pix_count_green\",src_pix_count_green)\n",
    "    source_count_array_green[indx] = src_pix_count_green\n",
    "    pixel_count_arraysg = numpy.arange(src_pix_count_green)\n",
    "\n",
    "    \n",
    "    #blue: 0 to 0.4\n",
    "    src_pix_count_blue = 0\n",
    "    for i in range(kappa_fits.shape[0]):\n",
    "        for j in range(kappa_fits.shape[1]):\n",
    "            if ((numpy.log10(src_model[i][j]) >= 0) and (numpy.log10(src_model[i][j]) < 0.4)):\n",
    "                src_pix_count_blue += 1\n",
    "#                 print(src_model_blue[i][j])\n",
    "    #print(\"src_pix_count_blue\",src_pix_count_blue)\n",
    "    source_count_array_blue[indx] = src_pix_count_blue\n",
    "    pixel_count_arraysb = numpy.arange(src_pix_count_blue)\n",
    "\n",
    "    \n",
    "    #image arc:   \n",
    "    \n",
    "    #red: >=1\n",
    "    img_pix_count_red = 0\n",
    "    for i in range(kappa_fits.shape[0]):\n",
    "        for j in range(kappa_fits.shape[1]):\n",
    "            if (numpy.log10(img_model[i][j]) >= 1):\n",
    "                img_pix_count_red += 1\n",
    "#                 print(img_model_red[i][j])\n",
    "    #print(\"img_pix_count_red\",img_pix_count_red)\n",
    "    image_count_array_red[indx] = img_pix_count_red\n",
    "    pixel_count_arrayir = numpy.arange(img_pix_count_red)\n",
    "\n",
    "   \n",
    "    #green: 0.4 to 1\n",
    "    img_pix_count_green = 0\n",
    "    for i in range(kappa_fits.shape[0]):\n",
    "        for j in range(kappa_fits.shape[1]):\n",
    "            if ((numpy.log10(img_model[i][j]) >= 0.4) and (numpy.log10(img_model[i][j]) < 1)):\n",
    "                img_pix_count_green += 1\n",
    "#                 print(img_model_green[i][j])\n",
    "    #print(\"img_pix_count_green\",img_pix_count_green)\n",
    "    image_count_array_green[indx] = img_pix_count_green\n",
    "    pixel_count_arrayig = numpy.arange(img_pix_count_green)\n",
    "\n",
    "    \n",
    "    #blue: 0 to 0.4\n",
    "    img_pix_count_blue = 0\n",
    "    for i in range(kappa_fits.shape[0]):\n",
    "        for j in range(kappa_fits.shape[1]):\n",
    "            if ((numpy.log10(img_model[i][j]) >= 0) and (numpy.log10(img_model[i][j]) < 0.4)):\n",
    "                img_pix_count_blue += 1\n",
    "#                 print(img_model_blue[i][j])\n",
    "    #print(\"img_pix_count_blue\",img_pix_count_blue)\n",
    "    image_count_array_blue[indx] = img_pix_count_blue\n",
    "    pixel_count_arrayib = numpy.arange(img_pix_count_blue)\n",
    "\n",
    "        \n",
    "    #------------------------------------------------------------\n",
    "    #FIX THE SCALING, THIS IS OFF SOMEHOW\n",
    "    #this section sets up the grids and interpolation for the critical curves from the signed magnification maps\n",
    "    #then we trace the critical curve from the image plane back to the source plane in order to obtain the caustic curves\n",
    "    \n",
    "    #NOTE: THIS IS ALL COPIED/PASTED FROM PROFESSOR'S CODE, WILL BE EDITED TO FIT MORE SEAMLESSLY HERE SOON\n",
    "    \n",
    "    # specify map info\n",
    "    npix = 1201\n",
    "    xmax = 120   # arcsec\n",
    "    pixscale = 2*xmax/(npix-1)\n",
    "\n",
    "    # read and extract deflection maps\n",
    "    def_maps = numpy.load(\"fit0-los1-scale1-defs-z0.725.npy\")\n",
    "    defx = def_maps[0].T[0].reshape(npix,npix)\n",
    "    defy = def_maps[0].T[1].reshape(npix,npix)\n",
    "\n",
    "    # read and extract magnification map\n",
    "    mag_maps = numpy.load(\"fit0-los1-scale1-mags-z0.725-signed.npy\")\n",
    "    mag = mag_maps[0].reshape(npix,npix)\n",
    "\n",
    "    # set up position grids\n",
    "    tmp = -xmax + pixscale*numpy.arange(npix)\n",
    "    # print(tmp)\n",
    "    xx,yy = numpy.meshgrid(tmp,tmp)\n",
    "    # print(xx)\n",
    "    # print(yy)\n",
    "\n",
    "    # compute source position \"grids\"\n",
    "    uu = xx - defx\n",
    "    vv = yy - defy\n",
    "\n",
    "    # set up interpolation for deflections, using indices\n",
    "    tmp = numpy.arange(npix)\n",
    "    defx_interp = RectBivariateSpline(tmp,tmp,defx)\n",
    "    defy_interp = RectBivariateSpline(tmp,tmp,defy)\n",
    "    \n",
    "    #NEXT PART - GET THE CRITICAL CURVES WHERE MAG GOES FROM + TO - AND DEFINE THE CAUSTICS\n",
    "    \n",
    "    # get the contours where 1/mag=0 (this is the python magic!)\n",
    "    cnt = contour(1.0/mag,[0])\n",
    "\n",
    "    # process into list of critical curves and caustics\n",
    "\n",
    "    # first initialize empty lists\n",
    "    allcrit = []\n",
    "    allcaus = []\n",
    "\n",
    "    # loop over all \"segments\" in the contour plot\n",
    "    for v in cnt.allsegs[0]:\n",
    "        # convert from pixel units to arcsec in image plane\n",
    "        x = -xmax + pixscale*v[:,0]\n",
    "        y = -xmax + pixscale*v[:,1]\n",
    "        # interpolate deflections and map to source plane;\n",
    "        # take not of the order of indices in the interpolation\n",
    "        u = x - defx_interp.ev(v[:,1],v[:,0])\n",
    "        v = y - defy_interp.ev(v[:,1],v[:,0])\n",
    "        # add to the lists\n",
    "        allcrit.append([x,y])\n",
    "        allcaus.append([u,v])\n",
    "        \n",
    "    #FINAL PART - PLOT ALL\n",
    "    \n",
    "    # plot\n",
    "    f,ax = subplots(1,2,figsize=(16,8))\n",
    "    for i in range(len(allcrit)):\n",
    "        x,y = allcrit[i]\n",
    "        u,v = allcaus[i]\n",
    "        \n",
    "        x_new = (x+xmax)/pixscale-30\n",
    "        y_new = (y+xmax)/pixscale-30\n",
    "        u_new = (u+xmax)/pixscale-30\n",
    "        v_new = (v+xmax)/pixscale-30\n",
    "\n",
    "    #     print(\"x_new=\",x_new)\n",
    "    #     print(type(x_new))\n",
    "    #     print(\"y_new=\",y_new)\n",
    "    #     print(type(y_new))\n",
    "\n",
    "        #oh no, these are arrays\n",
    "\n",
    "        ax[0].plot(x_new,y_new,zorder=2)\n",
    "        ax[1].plot(u_new,v_new,zorder=3)\n",
    "        \n",
    "    # adjust the figure\n",
    "#     ax[0].set_xlim([-40,40])\n",
    "#     ax[0].set_ylim([-40,40])\n",
    "#     ax[1].set_xlim([-20,20])\n",
    "#     ax[1].set_ylim([-20,20])\n",
    "    ax[0].set_xlabel('not arcsec')\n",
    "    ax[0].set_ylabel('not arcsec')\n",
    "    ax[1].set_xlabel('not arcsec')\n",
    "    ax[1].set_ylabel('not arcsec')\n",
    "    ax[0].set_title('critical curves')\n",
    "    ax[1].set_title('caustics')\n",
    "    #f.show()\n",
    "    \n",
    "    \n",
    "    #maybe shade this differently so can see what ends up where\n",
    "    #could do left side pink, right side green\n",
    "    #or could split up into quadrants\n",
    "    #check how they get these points\n",
    "\n",
    "    #arbitrary quadrants: x_axis 0-550,550-1201; y_axis 0-550,550-1201\n",
    "\n",
    "    #wait, so how does this code even work?  does it have a different array that it plots each iteration?  \n",
    "\n",
    "    #how could I pick out the largest curve if I wanted to color-code each quadrant?  \n",
    "    \n",
    "    \n",
    "    #------------------------------------------------------------\n",
    "    \n",
    "        \n",
    "    #plot everything using subplots so can see zoomed out and zoomed in areas\n",
    "    f,ax = subplots(2,2,figsize=(15,10))\n",
    "#     vmin = [-1.0, -1.0]\n",
    "    #imlist = [1,1]\n",
    "#     print(imlist)\n",
    "\n",
    "    #sets up number of boundaries between color sections\n",
    "    mag_bounds = [0.0, 0.5, 0.8, 1.0, 1.5, 1.8, 2]\n",
    "    #sets up the normalization for the colormap\n",
    "    norm = colors.BoundaryNorm(boundaries=mag_bounds, ncolors=256)\n",
    "    #cmap_sections = colors.ListedColormap(['dodgerblue','lime','red'])\n",
    "\n",
    "    #changed this from subplots 2,1 above and for i in range(2): ax[i].imshow etc\n",
    "    for a in ax:\n",
    "        for b in a:\n",
    "            #rgb image\n",
    "            rgb_im = b.imshow(mcut_rgb,origin='lower',alpha=1,zorder=0)\n",
    "            # magnification map\n",
    "            #magmap = b.imshow(mu_plot,origin='lower',norm=norm,cmap='inferno',vmin=0.250,vmax=2.0,alpha=0.5,zorder=1)\n",
    "    \n",
    "    for i in range(len(allcrit)):\n",
    "        \n",
    "        x,y = allcrit[i]\n",
    "        u,v = allcaus[i]\n",
    "        \n",
    "        ax[0][0].plot((x+xmax)/pixscale-new_val,(y+xmax)/pixscale-new_val,color='yellow',zorder=2)#changed from lime\n",
    "        ax[0][0].plot((u+xmax)/pixscale-new_val,(v+xmax)/pixscale-new_val,color='orange',zorder=3)#changed from aqua to orange\n",
    "        \n",
    "        ax[0][1].plot((x+xmax)/pixscale-new_val,(y+xmax)/pixscale-new_val,color='yellow',zorder=4)\n",
    "        ax[0][1].plot((u+xmax)/pixscale-new_val,(v+xmax)/pixscale-new_val,color='orange',zorder=5)\n",
    "        \n",
    "        ax[1][0].plot((x+xmax)/pixscale-new_val,(y+xmax)/pixscale-new_val,color='yellow',zorder=6)\n",
    "        ax[1][0].plot((u+xmax)/pixscale-new_val,(v+xmax)/pixscale-new_val,color='orange',zorder=7)\n",
    "        \n",
    "        ax[1][1].plot((x+xmax)/pixscale-new_val,(y+xmax)/pixscale-new_val,color='yellow',zorder=8)\n",
    "        ax[1][1].plot((u+xmax)/pixscale-new_val,(v+xmax)/pixscale-new_val,color='orange',zorder=9)\n",
    "    \n",
    "    #set bounds for colorbar sections\n",
    "    bounds = [0, 0.4, 1.0, 5]\n",
    "    cmap_sections = colors.ListedColormap(['dodgerblue','lime','red'])\n",
    "        \n",
    "    #source\n",
    "    src1 = ax[0][0].imshow(numpy.log10(src_model),origin='lower',interpolation='nearest',cmap=cmap_sections,vmin=0.0,vmax=1.5,alpha=0.75,zorder=10)#,vmin=vmin[i])#edit vmin and vmax\n",
    "    src11 = ax[1][0].imshow(numpy.log10(src_model),origin='lower',interpolation='nearest',cmap=cmap_sections,vmin=0.0,vmax=1.5,alpha=0.75,zorder=11)#,vmin=vmin[i])#edit vmin and vmax\n",
    "    #ave source\n",
    "    src2 = ax[0][1].imshow(numpy.log10(src_model_ave),origin='lower',interpolation='nearest',cmap=cmap_sections,vmin=0.0,vmax=1.5,alpha=0.75,zorder=12)#,vmin=vmin[i])#edit vmin and vmax\n",
    "    src22 = ax[1][1].imshow(numpy.log10(src_model_ave),origin='lower',interpolation='nearest',cmap=cmap_sections,vmin=0.0,vmax=1.5,alpha=0.75,zorder=13)#,vmin=vmin[i])#edit vmin and vmax\n",
    "\n",
    "    #arc\n",
    "    img1 = ax[0][0].imshow(numpy.log10(img_model),origin='lower',interpolation='nearest',cmap=cmap_sections,vmin=0.0,vmax=1.5,alpha=0.75,zorder=14)#edit vmin and vmax\n",
    "    img11 = ax[1][0].imshow(numpy.log10(img_model),origin='lower',interpolation='nearest',cmap=cmap_sections,vmin=0.0,vmax=1.5,alpha=0.75,zorder=15)#edit vmin and vmax\n",
    "    #ave arc\n",
    "    img2 = ax[0][1].imshow(numpy.log10(img_model_ave),origin='lower',interpolation='nearest',cmap=cmap_sections,vmin=0.0,vmax=1.5,alpha=0.75,zorder=16)#edit vmin and vmax\n",
    "    img22 = ax[1][1].imshow(numpy.log10(img_model_ave),origin='lower',interpolation='nearest',cmap=cmap_sections,vmin=0.0,vmax=1.5,alpha=0.75,zorder=17)#edit vmin and vmax\n",
    "            \n",
    "    for a in ax:\n",
    "        for b in a:       \n",
    "            # image positions\n",
    "            b.scatter(img_pix[0],img_pix[1],c='blue',marker='x',zorder=18)\n",
    "            #test source mapped back\n",
    "            b.scatter(orig_src[0],orig_src[1],c='lime',marker='x',zorder=18)\n",
    "            #plot the source positions obtained from the five images (before averaging)\n",
    "            b.scatter(source_map_back_x,source_map_back_y,c='mediumorchid',marker='x',alpha=0.5,zorder=18)\n",
    "            b.scatter(source_map_back_x2,source_map_back_y2,c='violet',marker='x',alpha=0.5,zorder=18)\n",
    "            b.scatter(source_map_back_x3,source_map_back_y3,c='fuchsia',marker='x',alpha=0.5,zorder=18)\n",
    "            b.scatter(source_map_back_x4,source_map_back_y4,c='deeppink',marker='x',alpha=0.5,zorder=18)\n",
    "            b.scatter(source_map_back_x5,source_map_back_y5,c='palevioletred',marker='x',alpha=0.5,zorder=18)\n",
    "    \n",
    "    #limits of the subplots\n",
    "    \n",
    "#     ax[0][0].set_xlim([450,675])\n",
    "#     ax[0][0].set_ylim([375,600])\n",
    "    \n",
    "#     ax[0][1].set_xlim([450,675])\n",
    "#     ax[0][1].set_ylim([375,600])\n",
    "    \n",
    "#     ax[1][0].set_xlim([450,675])\n",
    "#     ax[1][0].set_ylim([400,475])\n",
    "    \n",
    "#     ax[1][1].set_xlim([450,675])\n",
    "#     ax[1][1].set_ylim([400,475])\n",
    "\n",
    "    ax[0][0].set_xlim([450,675])\n",
    "    ax[0][0].set_ylim([375,600])\n",
    "    \n",
    "    ax[0][1].set_xlim([450,675])\n",
    "    ax[0][1].set_ylim([375,600])\n",
    "    \n",
    "    ax[1][0].set_xlim([525,575])\n",
    "    ax[1][0].set_ylim([485,530])\n",
    "    \n",
    "    ax[1][1].set_xlim([525,575])\n",
    "    ax[1][1].set_ylim([485,530])\n",
    "    \n",
    "    ax[1][0].set_title('map{:03d}'.format(indx))\n",
    "    ax[1][1].set_title('map{:03d}'.format(indx))\n",
    "    \n",
    "    #f.colorbar(imlist[0],ax=ax[0])\n",
    "    #colorbars on the top left\n",
    "    #f.colorbar(magmap, extend='both', ax=ax[0][0], fraction=0.045)\n",
    "    #f.colorbar(img1, ax=ax[0][0], fraction=0.045)\n",
    "    \n",
    "    #just used this to have a colorbars everywhere to make the plots the same size\n",
    "    #f.colorbar(magmap, ax=ax[0][1], fraction=0.045)\n",
    "    #f.colorbar(img11, ax=ax[0][1], fraction=0.045)\n",
    "#     f.colorbar(img1, ax=ax[1][0], fraction=0.01525)\n",
    "    \n",
    "    f.tight_layout()\n",
    "    #subplots_adjust(wspace=0.25,hspace=0.25)\n",
    "    #subplot_tool()\n",
    "    savefig('MCMC_Arc_Gif_Colors/Gif'+str('%03i.png'%indx),bbox_inches='tight')\n",
    "\n",
    "    print(mu_plot)\n",
    "\n",
    "    \n",
    "#need to print out one plot for the source plane, one plot for the image plane\n",
    "#print(os.getcwd()) #do not need this"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PixSrc Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function that calculates and plots everything we need\n",
    "def just_one_map(indx,src_params=[4,25,0.8,(numpy.pi)/10],project_yes=0,testyes=1):#,vers=\"src\"):\n",
    "    \n",
    "    #set function input array to src_params\n",
    "    nsrc,Rsrc,esrc,tsrc = src_params\n",
    "    \n",
    "    #read in range maps - use \"basename\" instead of retyping out everything each time\n",
    "    basename = '/mnt/c/Users/lana-/Desktop/final-maps/hlsp_frontier_model_abells1063_keeton-map{:03d}_v4_'.format(indx)\n",
    "    kappa_fits = fits.getdata(basename+'kappa.fits')\n",
    "    gamma_fits = fits.getdata(basename+'gamma.fits')\n",
    "    alphax_fits = fits.getdata(basename+'x-arcsec-deflect.fits')\n",
    "    alphay_fits = fits.getdata(basename+'y-arcsec-deflect.fits')\n",
    "    #set this up as general shape / dimensions / location of fits files with wcs info\n",
    "    wcs_info = wcs.WCS(basename+'kappa.fits')\n",
    "    \n",
    "    new_val = 30\n",
    "        \n",
    "    if project_yes==1:\n",
    "        #now need to trim these by 100*1201/4001\n",
    "        #do this to both the files and the wcs data\n",
    "        kappa_fits = kappa_fits[new_val:1201-new_val,new_val:1201-new_val]\n",
    "        gamma_fits = gamma_fits[new_val:1201-new_val,new_val:1201-new_val]\n",
    "        alphax_fits = alphax_fits[new_val:1201-new_val,new_val:1201-new_val]\n",
    "        alphay_fits = alphay_fits[new_val:1201-new_val,new_val:1201-new_val]\n",
    "        wcs_info = wcs_info[new_val:1201-new_val,new_val:1201-new_val]  \n",
    "\n",
    "    mcut_rgb2 = mcut_rgb\n",
    "\n",
    "\n",
    "\n",
    "    #apply the Dls/Dos scaling - remove for a test\n",
    "    if testyes==1:\n",
    "        factor_mult = Dls_over_Dos\n",
    "    if testyes==2:\n",
    "        factor_mult = 1.0\n",
    "    kappa = factor_mult*kappa_fits\n",
    "    gamma = factor_mult*gamma_fits\n",
    "    alphax = factor_mult*alphax_fits\n",
    "    alphay = factor_mult*alphay_fits\n",
    "\n",
    "    print(len(kappa_fits))\n",
    "    print(len(kappa))\n",
    "    print(len(alphax_fits))\n",
    "    print(len(alphax))\n",
    "\n",
    "#     # read the image and source positions for the arc in this realization;\n",
    "#     # important: recall that there is an offset between draw index and map index\n",
    "    imgdat = numpy.loadtxt('/mnt/c/Users/lana-/Desktop/final-maps/draw{:d}-src-img.dat'.format(indx+1),usecols=(0,1))\n",
    "    #read the image positions from the fiducial model (the src .dat files, first file?)\n",
    "    # xy positions of the source - just images for the MCMC analysis\n",
    "    src_xy = imgdat[4]\n",
    "    print(\"HERE LANA\",src_xy)\n",
    "\n",
    "    # #from fiducial model\n",
    "    # src_xy[0] = -6.485184\n",
    "    # src_xy[1] = -13.24760\n",
    "    \n",
    "    # convert to world coordinates and then to pixels\n",
    "    src_world = xy2world(src_xy[0],src_xy[1])\n",
    "    src_pix = src_world.to_pixel(wcs_info)    \n",
    "    \n",
    "    #shape of the grid on which we will compute the arc\n",
    "    mmm,nnn = kappa_fits.shape\n",
    "    #pixel grid\n",
    "    iii,jjj = numpy.meshgrid(numpy.arange(mmm),numpy.arange(nnn))\n",
    "\n",
    "    #image setup\n",
    "    a,b = pix2xy(iii,jjj,wcs_info)\n",
    "    #plug the positions and deflections into the source function to get the image\n",
    "    x = a - alphax\n",
    "    y = b - alphay\n",
    "    source_func = Sersic2D(amplitude=1, r_eff=Rsrc/7.5, n=nsrc, x_0=src_xy[0], y_0=src_xy[1], ellip=esrc, theta=tsrc)\n",
    "    image_grid = source_func(x,y)\n",
    "    image_grid[numpy.where(image_grid<1)] = numpy.nan\n",
    "    img_model = image_grid\n",
    "    #count the number of pixels in the resulting images\n",
    "    img_pix_count = 0\n",
    "    for i in range(kappa_fits.shape[0]):\n",
    "        for j in range(kappa_fits.shape[1]):\n",
    "            if img_model[i][j] > 0:\n",
    "                img_pix_count += 1\n",
    "#                 print(img_model[i][j])\n",
    "    #print(\"img_pix_count\",img_pix_count)\n",
    "    image_count_array[indx] = img_pix_count\n",
    "    \n",
    "    print(len(mcut_rgb))\n",
    "    print(len(mcut))\n",
    "    print(len(img_model))\n",
    "    print(len(kappa_fits))\n",
    "\n",
    "    figure(figsize=(25,25))\n",
    "\n",
    "    if project_yes==1:\n",
    "        imshow(mcut_rgb2,origin='lower',alpha=1,zorder=0)\n",
    "    \n",
    "    imshow(numpy.log10(img_model),origin='lower',interpolation='nearest',cmap='inferno',vmin=0.0,vmax=1.5,alpha=0.75,zorder=14)\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "    return numpy.log10(img_model)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# #makes cropped image that IS aligned with RGB image trim\n",
    "# grid_of_arc = just_one_map(indx=1,project_yes=1,testyes=1)\n",
    "# print(len(grid_of_arc))\n",
    "# print(grid_of_arc)\n",
    "\n",
    "# #makes fullsize image that is ALONE to work with range maps\n",
    "# grid_of_arc = just_one_map(indx=1,project_yes=0,testyes=1)\n",
    "# print(len(grid_of_arc))\n",
    "# print(grid_of_arc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#makes cropped image that IS aligned with RGB image trim\n",
    "grid_of_arc = just_one_map(indx=1,project_yes=1,testyes=1)\n",
    "print(len(grid_of_arc))\n",
    "print(grid_of_arc)\n",
    "\n",
    "#makes fullsize image that is ALONE to work with range maps\n",
    "grid_of_arc = just_one_map(indx=1,project_yes=0,testyes=1)\n",
    "print(len(grid_of_arc))\n",
    "print(grid_of_arc) \n",
    "\n",
    "\n",
    "\n",
    "\n",
    " #use function to create just arc\n",
    "# grid_of_arc = just_one_map(indx=1,testyes=2)\n",
    "# print(len(grid_of_arc))\n",
    "# print(grid_of_arc)\n",
    "\n",
    "# #need to replace NaN values with 0.0 values\n",
    "# grid_of_arc[numpy.isnan(grid_of_arc)] = 0.0\n",
    "# print(grid_of_arc)\n",
    "\n",
    "\n",
    "# #need to convolve with PSF from F814W\n",
    "\n",
    "# #need to add noise\n",
    "# #load the psf\n",
    "# PSF_814 = fits.open('/mnt/c/Users/lana-/Desktop/PSF_814.fits')[0]\n",
    "\n",
    "# #convolution of minitest galaxy with psf\n",
    "# arc_grid_conv = convolve(grid_of_arc,PSF_814.data)\n",
    "\n",
    "# #add noise\n",
    "# arc_grid_conv_noise = arc_grid_conv + make_noise_image(arc_grid_conv.shape, distribution='gaussian', mean=0.005, stddev=0.005, seed=5)\n",
    "\n",
    "# #display figure\n",
    "# figure(figsize=(10,10))\n",
    "# imshow(arc_grid_conv_noise,origin='lower',cmap='inferno')\n",
    "\n",
    "# display figure\n",
    "# figure(figsize=(10,10))\n",
    "# imshow(grid_of_arc,origin='lower',cmap='inferno')\n",
    "\n",
    "#datamask can be added using ds9 regions\n",
    "\n",
    "\n",
    "#save as FITS file:\n",
    "\n",
    "# #if RGB image is not showing, then it means that the full 1201 pixels of the range maps are used\n",
    "# #this I need to save as a FITS file\n",
    "# range_field = fits.open('/mnt/c/Users/lana-/Desktop/range_field.fits')\n",
    "# range_field[0].data = arc_grid_conv_noise\n",
    "# range_field.writeto('/mnt/c/Users/lana-/Desktop/range_field.fits',overwrite=True)\n",
    "\n",
    "# #load the model galaxy\n",
    "# range_field2 = fits.open('/mnt/c/Users/lana-/Desktop/range_field.fits')[0]\n",
    "# #set new variable\n",
    "# rf_2 = range_field2\n",
    "# #unit keywords\n",
    "# rf_2.header['CUNIT1'] = 'deg     '\n",
    "# rf_2.header['CUNIT2'] = 'deg     '\n",
    "# rf_2.data = arc_grid_conv_noise\n",
    "# rf_2.writeto('/mnt/c/Users/lana-/Desktop/range_field2.fits', overwrite=True)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#JUST ARC NO FUZZ\n",
    "\n",
    "#if RGB image is not showing, then it means that the full 1201 pixels of the range maps are used\n",
    "#this I need to save as a FITS file\n",
    "range_field = fits.open('/mnt/c/Users/lana-/Desktop/range_field.fits')\n",
    "range_field[0].data = grid_of_arc\n",
    "range_field.writeto('/mnt/c/Users/lana-/Desktop/range_field.fits',overwrite=True)\n",
    "\n",
    "#load the model galaxy\n",
    "range_field2 = fits.open('/mnt/c/Users/lana-/Desktop/range_field.fits')[0]\n",
    "#set new variable\n",
    "rf_2 = range_field2\n",
    "#ref coor\n",
    "rf_2.header['CRVAL1'] = 39.97041667\n",
    "rf_2.header['CRVAL2'] = -1.57680556\n",
    "#coordinate alignment and increment\n",
    "rf_2.header['CD1_1'] = -5.55555555555556E-05\n",
    "rf_2.header['CD1_2'] = 0.\n",
    "rf_2.header['CD2_1'] = 0.\n",
    "rf_2.header['CD2_2'] = 5.55555555555556E-05\n",
    "#unit keywords\n",
    "rf_2.header['CUNIT1'] = 'deg     '\n",
    "rf_2.header['CUNIT2'] = 'deg     '\n",
    "rf_2.data = grid_of_arc\n",
    "rf_2.data[numpy.isnan(grid_of_arc)] = 0.0\n",
    "blank_arc = rf_2.data\n",
    "rf_2.writeto('/mnt/c/Users/lana-/Desktop/range_field2.fits', overwrite=True)\n",
    "\n",
    "#PSF convolve\n",
    "#load the model galaxy under a new name\n",
    "range_field3 = fits.open('/mnt/c/Users/lana-/Desktop/range_field2.fits')[0]\n",
    "#set new variable\n",
    "rf_3 = range_field3\n",
    "#convolve with PSF from F814W\n",
    "#load the psf\n",
    "PSF_814 = fits.open('/mnt/c/Users/lana-/Desktop/PSF_814.fits')[0]\n",
    "#convolution with psf\n",
    "arc_conv = convolve(blank_arc,PSF_814.data)\n",
    "#display figure\n",
    "figure(figsize=(10,10))\n",
    "imshow(arc_conv,origin='lower',cmap='inferno')\n",
    "#switch new data into FITS file\n",
    "rf_3.data = arc_conv\n",
    "rf_3.writeto('/mnt/c/Users/lana-/Desktop/range_field3.fits', overwrite=True)\n",
    "\n",
    "#noise add\n",
    "#load the model galaxy under a new name\n",
    "range_field4 = fits.open('/mnt/c/Users/lana-/Desktop/range_field2.fits')[0]\n",
    "#set new variable\n",
    "rf_4 = range_field4\n",
    "#add noise\n",
    "arc_noise = blank_arc + make_noise_image(blank_arc.shape, distribution='gaussian', mean=1, stddev=0.075)#, seed=5)\n",
    "#display figure\n",
    "figure(figsize=(10,10))\n",
    "imshow(arc_noise,origin='lower',cmap='inferno')\n",
    "#switch new data into FITS file\n",
    "rf_4.data = arc_noise\n",
    "rf_4.writeto('/mnt/c/Users/lana-/Desktop/range_field4.fits', overwrite=True)\n",
    "\n",
    "#both PSF convolve and noise add\n",
    "#load the model galaxy under a new name\n",
    "range_field5 = fits.open('/mnt/c/Users/lana-/Desktop/range_field2.fits')[0]\n",
    "#set new variable\n",
    "rf_5 = range_field5\n",
    "#convolution with psf\n",
    "mock_data_arc = convolve(blank_arc,PSF_814.data)\n",
    "#add noise\n",
    "mock_data_arc = mock_data_arc + make_noise_image(blank_arc.shape, distribution='gaussian', mean=1, stddev=0.005)#, seed=5)\n",
    "#display figure\n",
    "figure(figsize=(10,10))\n",
    "imshow(mock_data_arc,origin='lower',cmap='inferno')\n",
    "#switch new data into FITS file\n",
    "rf_5.data = mock_data_arc\n",
    "rf_5.writeto('/mnt/c/Users/lana-/Desktop/range_field5.fits', overwrite=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ok so here is the plan\n",
    "#we need to read in arc_814.fits\n",
    "ref_test = fits.open('/mnt/c/Users/lana-/Desktop/arc_814.fits')\n",
    "wcs_ref = WCS(ref_test[0].header)\n",
    "\n",
    "# print(wcs_ref)\n",
    "# print(\"aaaa\")\n",
    "# print(ref_test)\n",
    "\n",
    "fieldcenter2 = SkyCoord(39.97041667,-1.57680556,unit='deg')\n",
    "print(fieldcenter2)\n",
    "print(fieldcenter2.ra.hour)\n",
    "print(fieldcenter2.dec.hour)\n",
    "print(fieldcenter2.ra.degree)\n",
    "print(fieldcenter2.dec.degree)\n",
    "\n",
    "#then we need to figure out where in arc_814.fits do we have the RA and Dec of 39.97041667 -1.57680556\n",
    "#this would match the 2D range maps\n",
    "no_idea1, no_idea2 = wcs_ref.world_to_pixel(fieldcenter2)\n",
    "print(\"these numbers\")\n",
    "print(no_idea1)\n",
    "print(no_idea2)\n",
    "x_round = 350\n",
    "y_round = 563\n",
    "\n",
    "\n",
    "#then after that, we can reset the rotation info and whatever in the cr header stuff to match them too\n",
    "#it will not matter because it will have the same exact format as the model arc above, same orientation\n",
    "#I think - I could be wrong\n",
    "\n",
    "\n",
    "#red\n",
    "#load the rgb image\n",
    "redo_arc = fits.open('/mnt/c/Users/lana-/Desktop/arc_814.fits')[0]\n",
    "#coordinate alignment and increment\n",
    "redo_arc.header['CD1_1'] = -1.6666666666666E-05\n",
    "redo_arc.header['CD1_2'] = 8.47032947254300E-22\n",
    "redo_arc.header['CD2_1'] = 8.47032947254300E-22\n",
    "redo_arc.header['CD2_2'] = 1.66666666666666E-05\n",
    "# redo_arc.header['CD1_1'] = -5.55555555555556E-05\n",
    "# redo_arc.header['CD1_2'] = 0.\n",
    "# redo_arc.header['CD2_1'] = 0.\n",
    "# redo_arc.header['CD2_2'] = 5.55555555555556E-05\n",
    "redo_arc.header['CRPIX1'] = 529.7680668001694\n",
    "redo_arc.header['CRPIX2'] = 838.2636191380333\n",
    "redo_arc.header['CTYPE1'] = 'RA---TAN'\n",
    "redo_arc.header['CTYPE2'] = 'DEC--TAN'\n",
    "redo_arc.header['CRVAL1'] = 39.97041667\n",
    "redo_arc.header['CRVAL2'] = -1.57680556\n",
    "redo_arc.writeto('/mnt/c/Users/lana-/Desktop/redo_arc.fits', overwrite=True)\n",
    "fits.delval('/mnt/c/Users/lana-/Desktop/redo_arc.fits','LONPOLE')\n",
    "fits.delval('/mnt/c/Users/lana-/Desktop/redo_arc.fits','LATPOLE')\n",
    "fits.delval('/mnt/c/Users/lana-/Desktop/redo_arc.fits','CRDER1')\n",
    "fits.delval('/mnt/c/Users/lana-/Desktop/redo_arc.fits','CRDER2')\n",
    "fits.delval('/mnt/c/Users/lana-/Desktop/redo_arc.fits','WCSNAME')\n",
    "fits.delval('/mnt/c/Users/lana-/Desktop/redo_arc.fits','RADESYS')\n",
    "fits.delval('/mnt/c/Users/lana-/Desktop/redo_arc.fits','MJDREF')\n",
    "\n",
    "\n",
    "#GREEN\n",
    "#load the rgb image\n",
    "redo_arc2 = fits.open('/mnt/c/Users/lana-/Desktop/arc_606.fits')[0]\n",
    "#coordinate alignment and increment\n",
    "redo_arc2.header['CD1_1'] = -1.6666666666666E-05\n",
    "redo_arc2.header['CD1_2'] = 8.47032947254300E-22\n",
    "redo_arc2.header['CD2_1'] = 8.47032947254300E-22\n",
    "redo_arc2.header['CD2_2'] = 1.66666666666666E-05\n",
    "redo_arc2.header['CRPIX1'] = 529.7680668001694\n",
    "redo_arc2.header['CRPIX2'] = 838.2636191380333\n",
    "redo_arc2.header['CTYPE1'] = 'RA---TAN'\n",
    "redo_arc2.header['CTYPE2'] = 'DEC--TAN'\n",
    "redo_arc2.header['CRVAL1'] = 39.97041667\n",
    "redo_arc2.header['CRVAL2'] = -1.57680556\n",
    "redo_arc2.writeto('/mnt/c/Users/lana-/Desktop/redo_arc2.fits', overwrite=True)\n",
    "fits.delval('/mnt/c/Users/lana-/Desktop/redo_arc2.fits','LONPOLE')\n",
    "fits.delval('/mnt/c/Users/lana-/Desktop/redo_arc2.fits','LATPOLE')\n",
    "fits.delval('/mnt/c/Users/lana-/Desktop/redo_arc2.fits','CRDER1')\n",
    "fits.delval('/mnt/c/Users/lana-/Desktop/redo_arc2.fits','CRDER2')\n",
    "fits.delval('/mnt/c/Users/lana-/Desktop/redo_arc2.fits','WCSNAME')\n",
    "fits.delval('/mnt/c/Users/lana-/Desktop/redo_arc2.fits','RADESYS')\n",
    "fits.delval('/mnt/c/Users/lana-/Desktop/redo_arc2.fits','MJDREF')\n",
    "\n",
    "\n",
    "#BLUE\n",
    "#load the rgb image\n",
    "redo_arc3 = fits.open('/mnt/c/Users/lana-/Desktop/arc_435.fits')[0]\n",
    "#coordinate alignment and increment\n",
    "redo_arc3.header['CD1_1'] = -1.6666666666666E-05\n",
    "redo_arc3.header['CD1_2'] = 8.47032947254300E-22\n",
    "redo_arc3.header['CD2_1'] = 8.47032947254300E-22\n",
    "redo_arc3.header['CD2_2'] = 1.66666666666666E-05\n",
    "redo_arc3.header['CRPIX1'] = 529.7680668001694\n",
    "redo_arc3.header['CRPIX2'] = 838.2636191380333\n",
    "redo_arc3.header['CTYPE1'] = 'RA---TAN'\n",
    "redo_arc3.header['CTYPE2'] = 'DEC--TAN'\n",
    "redo_arc3.header['CRVAL1'] = 39.97041667\n",
    "redo_arc3.header['CRVAL2'] = -1.57680556\n",
    "redo_arc3.writeto('/mnt/c/Users/lana-/Desktop/redo_arc3.fits', overwrite=True)\n",
    "fits.delval('/mnt/c/Users/lana-/Desktop/redo_arc3.fits','LONPOLE')\n",
    "fits.delval('/mnt/c/Users/lana-/Desktop/redo_arc3.fits','LATPOLE')\n",
    "fits.delval('/mnt/c/Users/lana-/Desktop/redo_arc3.fits','CRDER1')\n",
    "fits.delval('/mnt/c/Users/lana-/Desktop/redo_arc3.fits','CRDER2')\n",
    "fits.delval('/mnt/c/Users/lana-/Desktop/redo_arc3.fits','WCSNAME')\n",
    "fits.delval('/mnt/c/Users/lana-/Desktop/redo_arc3.fits','RADESYS')\n",
    "fits.delval('/mnt/c/Users/lana-/Desktop/redo_arc3.fits','MJDREF')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for n in range(6):\n",
    "\n",
    "    arb_num = 0+n\n",
    "\n",
    "    #red\n",
    "    #want to remove the outliers, which are very small negative numbers\n",
    "    r814 = fits.open('/mnt/c/Users/lana-/Desktop/all_arcs/arc'+str(arb_num)+'/pixsrc_out/arc'+str(arb_num)+'_arc_source_814_0_mps.fits')\n",
    "    r814_data = r814[0].data\n",
    "    header814 = r814[0].header\n",
    "    print(numpy.min(r814_data.flatten()))\n",
    "    print(numpy.max(r814_data.flatten()))\n",
    "    r814_data[numpy.where(r814_data<0.)] = 0.\n",
    "    r814_data[numpy.where(r814_data>125.)] = 0.\n",
    "    arc814_0 = fits.PrimaryHDU(r814_data)\n",
    "    arc814_0.header = header814\n",
    "    arc814_0.writeto('/mnt/c/Users/lana-/Desktop/all_arcs/arc'+str(arb_num)+'/arc814_'+str(arb_num)+'.fits',overwrite=True)\n",
    "\n",
    "    #green\n",
    "    #want to remove the outliers, which are very small negative numbers\n",
    "    r606 = fits.open('/mnt/c/Users/lana-/Desktop/all_arcs/arc'+str(arb_num)+'/pixsrc_out/arc'+str(arb_num)+'_arc_source_606_0_mps.fits')\n",
    "    r606_data = r606[0].data\n",
    "    header606 = r606[0].header\n",
    "    print(numpy.min(r606_data.flatten()))\n",
    "    print(numpy.max(r606_data.flatten()))\n",
    "    r606_data[numpy.where(r606_data<0.)] = 0.\n",
    "    r606_data[numpy.where(r606_data>125.)] = 0.\n",
    "    arc606_0 = fits.PrimaryHDU(r606_data)\n",
    "    arc606_0.header = header606\n",
    "    arc606_0.writeto('/mnt/c/Users/lana-/Desktop/all_arcs/arc'+str(arb_num)+'/arc606_'+str(arb_num)+'.fits',overwrite=True)\n",
    "\n",
    "    #blue\n",
    "    #want to remove the outliers, which are very small negative numbers\n",
    "    r435 = fits.open('/mnt/c/Users/lana-/Desktop/all_arcs/arc'+str(arb_num)+'/pixsrc_out/arc'+str(arb_num)+'_arc_source_435_0_mps.fits')\n",
    "    r435_data = r435[0].data\n",
    "    header435 = r435[0].header\n",
    "    print(numpy.min(r435_data.flatten()))\n",
    "    print(numpy.max(r435_data.flatten()))\n",
    "    r435_data[numpy.where(r435_data<0.)] = 0.\n",
    "    r435_data[numpy.where(r435_data>125.)] = 0.\n",
    "    arc435_0 = fits.PrimaryHDU(r435_data)\n",
    "    arc435_0.header = header435\n",
    "    arc435_0.writeto('/mnt/c/Users/lana-/Desktop/all_arcs/arc'+str(arb_num)+'/arc435_'+str(arb_num)+'.fits',overwrite=True)\n",
    "\n",
    "    #source reconstructions\n",
    "    aplpy.make_rgb_cube(['/mnt/c/Users/lana-/Desktop/all_arcs/arc'+str(arb_num)+'/arc814_'+str(arb_num)+'.fits','/mnt/c/Users/lana-/Desktop/all_arcs/arc'+str(arb_num)+'/arc606_'+str(arb_num)+'.fits','/mnt/c/Users/lana-/Desktop/all_arcs/arc'+str(arb_num)+'/arc435_'+str(arb_num)+'.fits'],'/mnt/c/Users/lana-/Desktop/rgb_arcs/all_arcs'+str(arb_num)+'_rgb_cube.fits')\n",
    "    aplpy.make_rgb_image('/mnt/c/Users/lana-/Desktop/rgb_arcs/all_arcs'+str(arb_num)+'_rgb_cube.fits','/mnt/c/Users/lana-/Desktop/rgb_arcs/all_arcs'+str(arb_num)+'.png', vmin_r=0.,vmin_g=0.,vmin_b=0.,vmax_r=125.,vmax_g=125.,vmax_b=125.)\n",
    "\n",
    "    #rec source\n",
    "    #takes all images and stores them as image_list\n",
    "    image_path = Path('/mnt/c/Users/lana-/Desktop/rgb_arcs/')\n",
    "    images = list(image_path.glob('*.png'))\n",
    "    image_list_mcmc = []\n",
    "    for file_name in images:\n",
    "        image_list_mcmc.append(imageio.imread(file_name))\n",
    "    print(len(image_list_mcmc))\n",
    "    imageio.mimwrite('/mnt/c/Users/lana-/Desktop/source_gal.gif', image_list_mcmc, fps=0.5)\n",
    "\n",
    "\n",
    "    #the model arc without PSF convolution, which does something but should be somewhat arbitrary if I do not use PSF\n",
    "    aplpy.make_rgb_cube(['/mnt/c/Users/lana-/Desktop/all_arcs/arc'+str(arb_num)+'/pixsrc_out/arc'+str(arb_num)+'_arc_source_814_0_lensedmpsnobo.fits','/mnt/c/Users/lana-/Desktop/all_arcs/arc'+str(arb_num)+'/pixsrc_out/arc'+str(arb_num)+'_arc_source_606_0_lensedmpsnobo.fits','/mnt/c/Users/lana-/Desktop/all_arcs/arc'+str(arb_num)+'/pixsrc_out/arc'+str(arb_num)+'_arc_source_435_0_lensedmpsnobo.fits'],'/mnt/c/Users/lana-/Desktop/rgb_model_arcs/model_arc'+str(arb_num)+'_rgb_cube.fits')\n",
    "    aplpy.make_rgb_image('/mnt/c/Users/lana-/Desktop/rgb_model_arcs/model_arc'+str(arb_num)+'_rgb_cube.fits','/mnt/c/Users/lana-/Desktop/rgb_model_arcs/model_arcs'+str(arb_num)+'.png', vmin_r=0.,vmin_g=0.,vmin_b=0.,vmax_r=125.,vmax_g=125.,vmax_b=125.)\n",
    "\n",
    "    #model arc no PSF\n",
    "    #takes all images and stores them as image_list\n",
    "    image_path = Path('/mnt/c/Users/lana-/Desktop/rgb_model_arcs/')\n",
    "    images = list(image_path.glob('*.png'))\n",
    "    image_list_mcmc = []\n",
    "    for file_name in images:\n",
    "        image_list_mcmc.append(imageio.imread(file_name))\n",
    "    print(len(image_list_mcmc))\n",
    "    imageio.mimwrite('/mnt/c/Users/lana-/Desktop/model_arc_no_PSF.gif', image_list_mcmc, fps=0.5)\n",
    "\n",
    "#just the data image\n",
    "aplpy.make_rgb_cube(['/mnt/c/Users/lana-/Desktop/all_arcs/arc0/pixsrc_out/arc0_arc_source_814_0_data.fits','/mnt/c/Users/lana-/Desktop/all_arcs/arc0/pixsrc_out/arc0_arc_source_606_0_data.fits','/mnt/c/Users/lana-/Desktop/all_arcs/arc0/pixsrc_out/arc0_arc_source_814_0_data.fits'],'/mnt/c/Users/lana-/Desktop/datamask_arc/datamask_arc_rgb_cube.fits')\n",
    "aplpy.make_rgb_image('/mnt/c/Users/lana-/Desktop/datamask_arc/datamask_arc_rgb_cube.fits','/mnt/c/Users/lana-/Desktop/datamask_arc/datamask_arc_rgb.png', vmin_r=0.,vmin_g=0.,vmin_b=0.,vmax_r=255.,vmax_g=255.,vmax_b=255.)\n",
    "#takes all images and stores them as image_list\n",
    "image_path = Path('/mnt/c/Users/lana-/Desktop/datamask_arc/')\n",
    "images = list(image_path.glob('*.png'))\n",
    "image_list_mcmc = []\n",
    "for file_name in images:\n",
    "    image_list_mcmc.append(imageio.imread(file_name))\n",
    "print(len(image_list_mcmc))\n",
    "imageio.mimwrite('/mnt/c/Users/lana-/Desktop/datamask_arc.gif', image_list_mcmc, fps=0.5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#RGB images for the poster, to be turned into gif perhaps\n",
    "\n",
    "#https://aplpy.readthedocs.io/en/stable/rgb.html\n",
    "aplpy.make_rgb_cube(['/mnt/c/Users/lana-/Desktop/all_arcs/arc0/arc814_0.fits','/mnt/c/Users/lana-/Desktop/all_arcs/arc0/arc606_0.fits','/mnt/c/Users/lana-/Desktop/all_arcs/arc0/arc435_0.fits'],'/mnt/c/Users/lana-/Desktop/all_arcs_rgb_cube.fits')\n",
    "aplpy.make_rgb_image('/mnt/c/Users/lana-/Desktop/all_arcs_rgb_cube.fits','/mnt/c/Users/lana-/Desktop/all_arcs.png', vmin_r=0.,vmin_g=0.,vmin_b=0.,vmax_r=150.,vmax_g=150.,vmax_b=150.)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mod_814_data = fits.getdata('/mnt/c/Users/lana-/Desktop/all_arcs/arc0/pixsrc_out/arc0_arc_source_814_0_mps.fits')\n",
    "print(numpy.min(mod_814_data.flatten()))\n",
    "print(numpy.max(mod_814_data.flatten()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mod_814_data = fits.getdata('/mnt/c/Users/lana-/Desktop/all_arcs/arc0/pixsrc_out/arc0_arc_source_814_0_mps.fits')\n",
    "# figure()\n",
    "# hist_814 = hist(mod_814_data.flatten(),bins='auto')\n",
    "# print(numpy.min(mod_814_data.flatten()))\n",
    "# print(numpy.max(mod_814_data.flatten()))\n",
    "# ylim(0,5000)\n",
    "\n",
    "# mod_606_data = fits.getdata('/mnt/c/Users/lana-/Desktop/all_arcs/arc0/pixsrc_out/arc0_arc_source_606_0_mps.fits')\n",
    "# figure()\n",
    "# hist_606 = hist(mod_606_data.flatten(),bins='auto')\n",
    "# print(numpy.min(mod_606_data.flatten()))\n",
    "# print(numpy.max(mod_606_data.flatten()))\n",
    "# ylim(0,500)\n",
    "\n",
    "# mod_435_data = fits.getdata('/mnt/c/Users/lana-/Desktop/all_arcs/arc0/pixsrc_out/arc0_arc_source_435_0_mps.fits')\n",
    "# figure()\n",
    "# hist_435 = hist(mod_435_data.flatten(),bins='auto')\n",
    "# print(numpy.min(mod_435_data.flatten()))\n",
    "# print(numpy.max(mod_435_data.flatten()))\n",
    "# ylim(0,2000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test the Function Run 100 Times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelarc(7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#?colorbar - pass vmin/vmax directly to colorbar next time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "100 TESTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for rangestep in range(6,8):\n",
    "    \n",
    "    print(rangestep)\n",
    "    \n",
    "    modelarc(rangestep)#,vers=\"src\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#takes all images and stores them as image_list\n",
    "\n",
    "image_path = Path('MCMC_Arc_Gif_Colors')\n",
    "images = list(image_path.glob('*.png'))\n",
    "image_list_mcmc = []\n",
    "for file_name in images:\n",
    "    image_list_mcmc.append(imageio.imread(file_name))\n",
    "    \n",
    "print(len(image_list_mcmc))\n",
    "\n",
    "imageio.mimwrite('MCMCGif_Colors.gif', image_list_mcmc, fps=2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PIXEL COUNT AND MAGNIFICATION STATISTICS BEGIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set up an arange array to fit the new sets of pixel counting arrays\n",
    "pixel_count_arrayir = numpy.arange(100)\n",
    "pixel_count_arrayig = numpy.arange(100)\n",
    "pixel_count_arrayib = numpy.arange(100)\n",
    "pixel_count_arraysr = numpy.arange(100)\n",
    "pixel_count_arraysg = numpy.arange(100)\n",
    "pixel_count_arraysb = numpy.arange(100)\n",
    "\n",
    "print(pixel_count_arrayir)\n",
    "print(image_count_array_red)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot source_count_array and image_count_array\n",
    "\n",
    "# from matplotlib.ticker import (MultipleLocator, FormatStrFormatter, AutoMinorLocator)\n",
    "    \n",
    "figure(figsize=(20,10))\n",
    "\n",
    "#image:\n",
    "#dimmest edge\n",
    "fill_between(pixel_count_arrayib,image_count_array_blue,facecolor=\"blue\",color=\"cyan\",alpha=0.5)\n",
    "#mid-brightness\n",
    "fill_between(pixel_count_arrayig,image_count_array_green,facecolor=\"green\",color=\"lime\",alpha=0.5)\n",
    "#brightest/center:\n",
    "fill_between(pixel_count_arrayir,image_count_array_red,facecolor=\"red\",color=\"orange\",alpha=0.75)\n",
    "\n",
    "#source:\n",
    "#dimmest edge\n",
    "fill_between(pixel_count_arraysb,source_count_array_blue,facecolor=\"blue\",color=\"blue\",alpha=0.6)\n",
    "#mid-brightness\n",
    "fill_between(pixel_count_arraysg,source_count_array_green,facecolor=\"green\",color=\"lime\",alpha=0.75)\n",
    "#brightest/center:\n",
    "fill_between(pixel_count_arraysr,source_count_array_red,facecolor=\"red\",color=\"red\",alpha=0.75)\n",
    "\n",
    "#plot formatting\n",
    "xticks(numpy.arange(0,100,10))\n",
    "# xlim(0,100)\n",
    "title(\"PIXEL COUNTS: Red - Bright/Center; Green - Middle Brightness; Blue - Dimmest/Edges\")\n",
    "\n",
    "savefig('PixelCounts_MCMC_Colors',bbox_inches='tight')\n",
    "\n",
    "\n",
    "# figure(figsize=(20,5))\n",
    "# fill_between(pixel_count_array,source_count_array,facecolor=\"lime\",color=\"aqua\",alpha=0.5)\n",
    "# xticks(numpy.arange(0,100,10))\n",
    "# xlim(0,100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figure(figsize=(10,5))\n",
    "#source then image - brightest/center\n",
    "fill_between(pixel_count_arraysr,source_count_array_red,facecolor=\"red\",color=\"red\",alpha=0.5)\n",
    "fill_between(pixel_count_arrayir,image_count_array_red,facecolor=\"red\",color=\"orange\",alpha=0.5)\n",
    "#plot formatting\n",
    "xticks(numpy.arange(0,100,10))\n",
    "title(\"SOURCE VS. IMAGE PIXEL COUNTS: Red - Bright/Center\")\n",
    "savefig('PixelCounts_MCMC_Red',bbox_inches='tight')\n",
    "\n",
    "figure(figsize=(10,5))\n",
    "#source then image - middle brightness\n",
    "fill_between(pixel_count_arraysg,source_count_array_green,facecolor=\"green\",color=\"green\",alpha=0.5)\n",
    "fill_between(pixel_count_arrayig,image_count_array_green,facecolor=\"green\",color=\"lime\",alpha=0.5)\n",
    "#plot formatting\n",
    "xticks(numpy.arange(0,100,10))\n",
    "title(\"SOURCE VS. IMAGE PIXEL COUNTS: Green - Middle Brightness\")\n",
    "savefig('PixelCounts_MCMC_Green',bbox_inches='tight')\n",
    "\n",
    "figure(figsize=(10,5))\n",
    "#source then image - faintest cutoff\n",
    "fill_between(pixel_count_arraysb,source_count_array_blue,facecolor=\"blue\",color=\"blue\",alpha=0.5)\n",
    "fill_between(pixel_count_arrayib,image_count_array_blue,facecolor=\"blue\",color=\"cyan\",alpha=0.5)\n",
    "#plot formatting\n",
    "xticks(numpy.arange(0,100,10))\n",
    "title(\"SOURCE VS. IMAGE PIXEL COUNTS: Blue - Dimmest/Edges\")\n",
    "savefig('PixelCounts_MCMC_Blue',bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#magnification of red zone:\n",
    "mag_red = image_count_array_red/source_count_array_red\n",
    "# print(\"magnification of red zone:\",mag_red)\n",
    "#magnification of green zone:\n",
    "mag_green = image_count_array_green/source_count_array_green\n",
    "# print(\"magnification of green zone:\",mag_green)\n",
    "#magnification of blue zone:\n",
    "mag_blue = image_count_array_blue/source_count_array_blue\n",
    "# print(\"magnification of blue zone:\",mag_blue)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#do this for the run where we use the leftmost image to create the arc\n",
    "\n",
    "#need to calculate mean\n",
    "\n",
    "#add all the elements in each array for each model\n",
    "#red (brightest)\n",
    "count_red_mag = 0\n",
    "for i in range(100):\n",
    "    count_red_mag = count_red_mag + mag_red[i]\n",
    "mean_red_mag = count_red_mag/100\n",
    "print(\"mean_red_mag:\",mean_red_mag)\n",
    "\n",
    "#standard deviation\n",
    "sum_mean_sq_diff_red = 0\n",
    "for i in range(100):\n",
    "    sum_mean_sq_diff_red = sum_mean_sq_diff_red + ((mag_red[i] - mean_red_mag)**2)\n",
    "st_dev_red_mag = numpy.sqrt(sum_mean_sq_diff_red/(100-1))\n",
    "print(\"st_dev_red_mag:\",st_dev_red_mag)\n",
    "\n",
    "#variance\n",
    "var_red_mag = st_dev_red_mag**2\n",
    "print(\"var_red_mag:\",var_red_mag)\n",
    "\n",
    "\n",
    "#green (middle brightness)\n",
    "count_green_mag = 0\n",
    "for i in range(100):\n",
    "    count_green_mag = count_green_mag + mag_green[i]\n",
    "mean_green_mag = count_green_mag/100\n",
    "print(\"mean_green_mag:\",mean_green_mag)\n",
    "\n",
    "#standard deviation\n",
    "sum_mean_sq_diff_green = 0\n",
    "for i in range(100):\n",
    "    sum_mean_sq_diff_green = sum_mean_sq_diff_green + ((mag_green[i] - mean_green_mag)**2)\n",
    "st_dev_green_mag = numpy.sqrt(sum_mean_sq_diff_green/(100-1))\n",
    "print(\"st_dev_green_mag:\",st_dev_green_mag)\n",
    "\n",
    "#variance\n",
    "var_green_mag = st_dev_green_mag**2\n",
    "print(\"var_green_mag:\",var_green_mag)\n",
    "\n",
    "\n",
    "#blue (dimmest)\n",
    "count_blue_mag = 0\n",
    "for i in range(100):\n",
    "    count_blue_mag = count_blue_mag + mag_blue[i]\n",
    "mean_blue_mag = count_blue_mag/100\n",
    "print(\"mean_blue_mag:\",mean_blue_mag)\n",
    "\n",
    "#standard deviation\n",
    "sum_mean_sq_diff_blue = 0\n",
    "for i in range(100):\n",
    "    sum_mean_sq_diff_blue = sum_mean_sq_diff_blue + ((mag_blue[i] - mean_blue_mag)**2)\n",
    "st_dev_blue_mag = numpy.sqrt(sum_mean_sq_diff_blue/(100-1))\n",
    "print(\"st_dev_blue_mag:\",st_dev_blue_mag)\n",
    "\n",
    "#variance\n",
    "var_blue_mag = st_dev_blue_mag**2\n",
    "print(\"var_blue_mag:\",var_blue_mag)\n",
    "\n",
    "\n",
    "#maybe add this to legend in plots\n",
    "#ok setting up arrays to plot as lines\n",
    "#mean arrays\n",
    "mean_line_red = (pixel_count_arrayir*0)+mean_red_mag\n",
    "mean_line_green = (pixel_count_arrayig*0)+mean_green_mag\n",
    "mean_line_blue = (pixel_count_arrayib*0)+mean_blue_mag\n",
    "#standard deviation arrays\n",
    "sigma_red_u = mean_line_red + st_dev_red_mag\n",
    "sigma_red_l = mean_line_red - st_dev_red_mag\n",
    "sigma_green_u = mean_line_green + st_dev_green_mag\n",
    "sigma_green_l = mean_line_green - st_dev_green_mag\n",
    "sigma_blue_u = mean_line_blue + st_dev_blue_mag\n",
    "sigma_blue_l = mean_line_blue - st_dev_blue_mag\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#magnifications!\n",
    "\n",
    "figure(figsize=(10,5))\n",
    "#brightest/center\n",
    "fill_between(pixel_count_arrayir,mag_red,facecolor=\"red\",color=\"orange\",alpha=0.5)\n",
    "#statistics\n",
    "plot(pixel_count_arrayir,mean_line_red,color=\"hotpink\",label=r\"$\\overline{\\mu}$=\"+str(mean_red_mag),alpha=0.75)\n",
    "plot(pixel_count_arrayir,sigma_red_u,color=\"hotpink\",linestyle=\"dashed\",label=r\"$\\sigma$=\"+str(st_dev_red_mag),alpha=0.75)\n",
    "plot(pixel_count_arrayir,sigma_red_l,color=\"hotpink\",linestyle=\"dashed\",alpha=0.75)\n",
    "plot(0,0,label=r\"$\\sigma^2$=\"+str(var_red_mag),alpha=0.000001)\n",
    "#plot formatting\n",
    "xlabel(\"MCMC Run\")\n",
    "ylabel(\"Magnification Factor\")\n",
    "legend(loc='lower right')\n",
    "xticks(numpy.arange(0,100,10))\n",
    "title(\"Magnification of Red Zone - Bright/Center\")\n",
    "savefig('Mag_MCMC_Red',bbox_inches='tight')\n",
    "\n",
    "\n",
    "figure(figsize=(10,5))\n",
    "#middle brightness\n",
    "fill_between(pixel_count_arrayig,mag_green,facecolor=\"green\",color=\"lime\",alpha=0.5)\n",
    "#statistics\n",
    "plot(pixel_count_arrayig,mean_line_green,color=\"green\",label=r\"$\\overline{\\mu}$=\"+str(mean_green_mag),alpha=0.75)\n",
    "plot(pixel_count_arrayig,sigma_green_u,color=\"green\",linestyle=\"dashed\",label=r\"$\\sigma$=\"+str(st_dev_green_mag),alpha=0.75)\n",
    "plot(pixel_count_arrayig,sigma_green_l,color=\"green\",linestyle=\"dashed\",alpha=0.75)\n",
    "plot(0,0,label=r\"$\\sigma^2$=\"+str(var_green_mag),alpha=0.000001)\n",
    "#plot formatting\n",
    "xlabel(\"MCMC Run\")\n",
    "ylabel(\"Magnification Factor\")\n",
    "legend(loc='lower right')\n",
    "xticks(numpy.arange(0,100,10))\n",
    "title(\"Magnification of Green Zone - Middle Brightness\")\n",
    "savefig('Mag_MCMC_Green',bbox_inches='tight')\n",
    "\n",
    "\n",
    "figure(figsize=(10,5))\n",
    "#faintest cutoff\n",
    "fill_between(pixel_count_arraysb,mag_blue,facecolor=\"blue\",color=\"cyan\",alpha=0.5)\n",
    "#statistics\n",
    "plot(pixel_count_arrayib,mean_line_blue,color=\"blue\",label=r\"$\\overline{\\mu}$=\"+str(mean_blue_mag),alpha=0.75)\n",
    "plot(pixel_count_arrayib,sigma_blue_u,color=\"blue\",linestyle=\"dashed\",label=r\"$\\sigma$=\"+str(st_dev_blue_mag),alpha=0.75)\n",
    "plot(pixel_count_arrayib,sigma_blue_l,color=\"blue\",linestyle=\"dashed\",alpha=0.75)\n",
    "plot(0,0,label=r\"$\\sigma^2$=\"+str(var_blue_mag),alpha=0.000001)\n",
    "#plot formatting\n",
    "xlabel(\"MCMC Run\")\n",
    "ylabel(\"Magnification Factor\")\n",
    "legend(loc='lower right')\n",
    "xticks(numpy.arange(0,100,10))\n",
    "title(\"Magnification of Blue Zone - Dimmest/Edges\")\n",
    "savefig('Mag_MCMC_Blue',bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "\n",
    "x_array_count = numpy.arange(1000)/10\n",
    "\n",
    "#red plot!\n",
    "figure(figsize=(7,5))\n",
    "#plot histogram\n",
    "hist(mag_red, bins=18, density=True, color=\"orange\", alpha=0.75, label=\"histogram\")\n",
    "#plot gaussian with same statistics\n",
    "red_mag_gaussian = numpy.exp(-0.5*(((x_array_count-mean_red_mag)**2)/(st_dev_red_mag**2)))*(1/(st_dev_red_mag*numpy.sqrt(2*numpy.pi)))\n",
    "#plot(pixel_count_arrayir, norm.pdf(pixel_count_arrayir, mean_red_mag, st_dev_red_mag), color=\"red\", ls=\"-\")\n",
    "plot(x_array_count, red_mag_gaussian, color=\"red\")\n",
    "#plot formatting\n",
    "legend(loc='upper right')\n",
    "xlabel(\"Magnification Factor\")\n",
    "ylabel(\"Fraction of MCMC Runs\")\n",
    "xlim(15,40)\n",
    "#ylim(0,19)\n",
    "title(\"Magnification of Red Zone - Bright/Center\")\n",
    "savefig('MagDist_MCMC_Red',bbox_inches='tight')\n",
    "\n",
    "\n",
    "#green plot!\n",
    "figure(figsize=(7,5))\n",
    "#plot histogram\n",
    "hist(mag_green, bins=15, density=True, color=\"lime\", alpha=0.75, label=\"histogram\")\n",
    "#plot gaussian with same statistics\n",
    "green_mag_gaussian = numpy.exp(-0.5*(((x_array_count-mean_green_mag)**2)/(st_dev_green_mag**2)))*(1/(st_dev_green_mag*numpy.sqrt(2*numpy.pi)))\n",
    "plot(x_array_count, green_mag_gaussian, color=\"green\")\n",
    "#plot formatting\n",
    "legend(loc='upper right')\n",
    "xlabel(\"Magnification Factor\")\n",
    "ylabel(\"Fraction of MCMC Runs\")\n",
    "xlim(12,23)\n",
    "#ylim(0,19)\n",
    "title(\"Magnification of Green Zone - Bright/Center\")\n",
    "savefig('MagDist_MCMC_Green',bbox_inches='tight')\n",
    "\n",
    "\n",
    "#blue plot!\n",
    "figure(figsize=(7,5))\n",
    "#plot histogram\n",
    "hist(mag_blue, bins=15, density=True, color=\"cyan\", alpha=0.75, label=\"histogram\")\n",
    "#plot gaussian with same statistics\n",
    "blue_mag_gaussian = numpy.exp(-0.5*(((x_array_count-mean_blue_mag)**2)/(st_dev_blue_mag**2)))*(1/(st_dev_blue_mag*numpy.sqrt(2*numpy.pi)))\n",
    "plot(x_array_count, blue_mag_gaussian, color=\"blue\")\n",
    "#plot formatting\n",
    "legend(loc='upper right')\n",
    "xlabel(\"Magnification Factor\")\n",
    "ylabel(\"Fraction of MCMC Runs\")\n",
    "xlim(8,14)\n",
    "#ylim(0,19)\n",
    "title(\"Magnification of Blue Zone - Bright/Center\")\n",
    "savefig('MagDist_MCMC_Blue',bbox_inches='tight')\n",
    "\n",
    "#NEED TO PLOT CAUSTIC TO SEE SOURCE LOCATION VS CAUSTIC\n",
    "#high mag might be fully inside caustic, but low mag might be more skewed/higher variance if crossing caustic and has more differential mag across it bc we're taking the whole elliptical ring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SAME THING BUT FOR LOG_10 OF THE MAGNIFICATIONS TO SEE IF LESS SCATTERED\n",
    "\n",
    "#do this for the run where we use the leftmost image to create the arc\n",
    "\n",
    "log10_mag_red = numpy.log10(mag_red)\n",
    "log10_mag_green = numpy.log10(mag_green)\n",
    "log10_mag_blue = numpy.log10(mag_blue)\n",
    "\n",
    "#need to calculate mean\n",
    "\n",
    "#add all the elements in each array for each model\n",
    "#red (brightest)\n",
    "count_red_log10_mag = 0\n",
    "for i in range(100):\n",
    "    count_red_log10_mag = count_red_log10_mag + log10_mag_red[i]\n",
    "mean_red_log10_mag = count_red_log10_mag/100\n",
    "print(\"mean_red_log10_mag:\",mean_red_log10_mag)\n",
    "\n",
    "#standard deviation\n",
    "sum_mean_sq_diff_log10_red = 0\n",
    "for i in range(100):\n",
    "    sum_mean_sq_diff_log10_red = sum_mean_sq_diff_log10_red + ((log10_mag_red[i] - mean_red_log10_mag)**2)\n",
    "st_dev_red_log10_mag = numpy.sqrt(sum_mean_sq_diff_log10_red/(100-1))\n",
    "print(\"st_dev_red_log10_mag:\",st_dev_red_log10_mag)\n",
    "\n",
    "#variance\n",
    "var_red_log10_mag = st_dev_red_log10_mag**2\n",
    "print(\"var_red_log10_mag:\",var_red_log10_mag)\n",
    "\n",
    "\n",
    "#green (middle brightness)\n",
    "count_green_log10_mag = 0\n",
    "for i in range(100):\n",
    "    count_green_log10_mag = count_green_log10_mag + log10_mag_green[i]\n",
    "mean_green_log10_mag = count_green_log10_mag/100\n",
    "print(\"mean_green_log10_mag:\",mean_green_log10_mag)\n",
    "\n",
    "#standard deviation\n",
    "sum_mean_sq_diff_log10_green = 0\n",
    "for i in range(100):\n",
    "    sum_mean_sq_diff_log10_green = sum_mean_sq_diff_log10_green + ((log10_mag_green[i] - mean_green_log10_mag)**2)\n",
    "st_dev_green_log10_mag = numpy.sqrt(sum_mean_sq_diff_log10_green/(100-1))\n",
    "print(\"st_dev_green_log10_mag:\",st_dev_green_log10_mag)\n",
    "\n",
    "#variance\n",
    "var_green_log10_mag = st_dev_green_log10_mag**2\n",
    "print(\"var_green_log10_mag:\",var_green_log10_mag)\n",
    "\n",
    "\n",
    "#blue (dimmest)\n",
    "count_blue_log10_mag = 0\n",
    "for i in range(100):\n",
    "    count_blue_log10_mag = count_blue_log10_mag + log10_mag_blue[i]\n",
    "mean_blue_log10_mag = count_blue_log10_mag/100\n",
    "print(\"mean_blue_log10_mag:\",mean_blue_log10_mag)\n",
    "\n",
    "#standard deviation\n",
    "sum_mean_sq_diff_log10_blue = 0\n",
    "for i in range(100):\n",
    "    sum_mean_sq_diff_log10_blue = sum_mean_sq_diff_log10_blue + ((log10_mag_blue[i] - mean_blue_log10_mag)**2)\n",
    "st_dev_blue_log10_mag = numpy.sqrt(sum_mean_sq_diff_log10_blue/(100-1))\n",
    "print(\"st_dev_blue_log10_mag:\",st_dev_blue_log10_mag)\n",
    "\n",
    "#variance\n",
    "var_blue_log10_mag = st_dev_blue_log10_mag**2\n",
    "print(\"var_blue_log10_mag:\",var_blue_log10_mag)\n",
    "\n",
    "\n",
    "#maybe add this to legend in plots\n",
    "#ok setting up arrays to plot as lines\n",
    "#mean arrays\n",
    "mean_line_log10_red = (pixel_count_arrayir*0)+mean_red_log10_mag\n",
    "mean_line_log10_green = (pixel_count_arrayig*0)+mean_green_log10_mag\n",
    "mean_line_log10_blue = (pixel_count_arrayib*0)+mean_blue_log10_mag\n",
    "#standard deviation arrays\n",
    "sigma_log10_red_u = mean_line_log10_red + st_dev_red_log10_mag\n",
    "sigma_log10_red_l = mean_line_log10_red - st_dev_red_log10_mag\n",
    "sigma_log10_green_u = mean_line_log10_green + st_dev_green_log10_mag\n",
    "sigma_log10_green_l = mean_line_log10_green - st_dev_green_log10_mag\n",
    "sigma_log10_blue_u = mean_line_log10_blue + st_dev_blue_log10_mag\n",
    "sigma_log10_blue_l = mean_line_log10_blue - st_dev_blue_log10_mag\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#LOG 10 OF THE magnifications!\n",
    "\n",
    "figure(figsize=(10,5))\n",
    "#brightest/center\n",
    "fill_between(pixel_count_arrayir,log10_mag_red,facecolor=\"red\",color=\"orange\",alpha=0.5)\n",
    "#statistics\n",
    "plot(pixel_count_arrayir,mean_line_log10_red,color=\"hotpink\",label=r\"$\\mu$=\"+str(mean_red_log10_mag),alpha=0.75)\n",
    "plot(pixel_count_arrayir,sigma_log10_red_u,color=\"hotpink\",linestyle=\"dashed\",label=r\"$\\sigma$=\"+str(st_dev_red_log10_mag),alpha=0.75)\n",
    "plot(pixel_count_arrayir,sigma_log10_red_l,color=\"hotpink\",linestyle=\"dashed\",alpha=0.75)\n",
    "plot(0,0,label=r\"$\\sigma^2$=\"+str(var_red_mag),alpha=0.000001)\n",
    "#plot formatting\n",
    "xlabel(\"MCMC Run\")\n",
    "ylabel(r\"log$_{10}$Magnification Factor\")\n",
    "legend(loc='lower right')\n",
    "xticks(numpy.arange(0,100,10))\n",
    "title(r\"log$_{10}$Magnification of Red Zone - Bright/Center\")\n",
    "savefig('log10_Mag_MCMC_Red',bbox_inches='tight')\n",
    "\n",
    "\n",
    "figure(figsize=(10,5))\n",
    "#middle brightness\n",
    "fill_between(pixel_count_arrayig,log10_mag_green,facecolor=\"green\",color=\"lime\",alpha=0.5)\n",
    "#statistics\n",
    "plot(pixel_count_arrayig,mean_line_log10_green,color=\"green\",label=r\"$\\mu$=\"+str(mean_green_log10_mag),alpha=0.75)\n",
    "plot(pixel_count_arrayig,sigma_log10_green_u,color=\"green\",linestyle=\"dashed\",label=r\"$\\sigma$=\"+str(st_dev_green_log10_mag),alpha=0.75)\n",
    "plot(pixel_count_arrayig,sigma_log10_green_l,color=\"green\",linestyle=\"dashed\",alpha=0.75)\n",
    "plot(0,0,label=r\"$\\sigma^2$=\"+str(var_green_log10_mag),alpha=0.000001)\n",
    "#plot formatting\n",
    "xlabel(\"MCMC Run\")\n",
    "ylabel(r\"log$_{10}$Magnification Factor\")\n",
    "legend(loc='lower right')\n",
    "xticks(numpy.arange(0,100,10))\n",
    "title(r\"log$_{10}$Magnification of Green Zone - Middle Brightness\")\n",
    "savefig('log10_Mag_MCMC_Green',bbox_inches='tight')\n",
    "\n",
    "\n",
    "figure(figsize=(10,5))\n",
    "#faintest cutoff\n",
    "fill_between(pixel_count_arraysb,log10_mag_blue,facecolor=\"blue\",color=\"cyan\",alpha=0.5)\n",
    "#statistics\n",
    "plot(pixel_count_arrayib,mean_line_log10_blue,color=\"blue\",label=r\"$\\mu$=\"+str(mean_blue_log10_mag),alpha=0.75)\n",
    "plot(pixel_count_arrayib,sigma_log10_blue_u,color=\"blue\",linestyle=\"dashed\",label=r\"$\\sigma$=\"+str(st_dev_blue_log10_mag),alpha=0.75)\n",
    "plot(pixel_count_arrayib,sigma_log10_blue_l,color=\"blue\",linestyle=\"dashed\",alpha=0.75)\n",
    "plot(0,0,label=r\"$\\sigma^2$=\"+str(var_blue_log10_mag),alpha=0.000001)\n",
    "#plot formatting\n",
    "xlabel(\"MCMC Run\")\n",
    "ylabel(r\"log$_{10}$Magnification Factor\")\n",
    "legend(loc='lower right')\n",
    "xticks(numpy.arange(0,100,10))\n",
    "title(r\"log$_{10}$Magnification of Blue Zone - Dimmest/Edges\")\n",
    "savefig('log10_Mag_MCMC_Blue',bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "\n",
    "x_array_count = numpy.arange(100000)/1000\n",
    "\n",
    "#red plot!\n",
    "figure(figsize=(7,5))\n",
    "#plot histogram\n",
    "hist(log10_mag_red, bins=10, density=True, color=\"orange\", alpha=0.75)#, label=\"histogram\")\n",
    "#plot gaussian with same statistics\n",
    "red_log10_mag_gaussian = numpy.exp(-0.5*(((x_array_count-mean_red_log10_mag)**2)/(st_dev_red_log10_mag**2)))*(1/(st_dev_red_log10_mag*numpy.sqrt(2*numpy.pi)))\n",
    "#plot(pixel_count_arrayir, norm.pdf(pixel_count_arrayir, mean_red_mag, st_dev_red_mag), color=\"red\", ls=\"-\")\n",
    "plot(x_array_count, red_log10_mag_gaussian, color=\"red\")\n",
    "#plot formatting\n",
    "#legend(loc='upper right')\n",
    "xlabel(r\"log$_{10}$Magnification Factor\")\n",
    "ylabel(\"Fraction of MCMC Runs\")\n",
    "xlim(1,2)\n",
    "#ylim(0,19)\n",
    "title(r\"log$_{10}$Magnification of Red Zone - Bright/Center\")\n",
    "savefig('log10_MagDist_MCMC_Red',bbox_inches='tight')\n",
    "\n",
    "\n",
    "#green plot!\n",
    "figure(figsize=(7,5))\n",
    "#plot histogram\n",
    "hist(log10_mag_green, bins=10, density=True, color=\"lime\", alpha=0.75)#, label=\"histogram\")\n",
    "#plot gaussian with same statistics\n",
    "green_log10_mag_gaussian = numpy.exp(-0.5*(((x_array_count-mean_green_log10_mag)**2)/(st_dev_green_log10_mag**2)))*(1/(st_dev_green_log10_mag*numpy.sqrt(2*numpy.pi)))\n",
    "plot(x_array_count, green_log10_mag_gaussian, color=\"green\")\n",
    "#plot formatting\n",
    "#legend(loc='upper right')\n",
    "xlabel(r\"log$_{10}$Magnification Factor\")\n",
    "ylabel(\"Fraction of MCMC Runs\")\n",
    "xlim(1,1.5)\n",
    "#ylim(0,19)\n",
    "title(r\"log$_{10}$Magnification of Green Zone - Bright/Center\")\n",
    "savefig('log10_MagDist_MCMC_Green',bbox_inches='tight')\n",
    "\n",
    "\n",
    "#blue plot!\n",
    "figure(figsize=(7,5))\n",
    "#plot histogram\n",
    "hist(log10_mag_blue, bins=10, density=True, color=\"cyan\", alpha=0.75)#, label=\"histogram\")\n",
    "#plot gaussian with same statistics\n",
    "blue_log10_mag_gaussian = numpy.exp(-0.5*(((x_array_count-mean_blue_log10_mag)**2)/(st_dev_blue_log10_mag**2)))*(1/(st_dev_blue_log10_mag*numpy.sqrt(2*numpy.pi)))\n",
    "plot(x_array_count, blue_log10_mag_gaussian, color=\"blue\")\n",
    "#plot formatting\n",
    "#legend(loc='upper right')\n",
    "xlabel(r\"log$_{10}$Magnification Factor\")\n",
    "ylabel(\"Fraction of MCMC Runs\")\n",
    "xlim(0.8,1.2)\n",
    "#ylim(0,19)\n",
    "title(r\"log$_{10}$Magnification of Blue Zone - Bright/Center\")\n",
    "savefig('log10_MagDist_MCMC_Blue',bbox_inches='tight')\n",
    "\n",
    "#NEED TO PLOT CAUSTIC TO SEE SOURCE LOCATION VS CAUSTIC\n",
    "#high mag might be fully inside caustic, but low mag might be more skewed/higher variance if crossing caustic and has more differential mag across it bc we're taking the whole elliptical ring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
